setGPU: Setting GPU to: 0
reading /eos/home-k/kiwoznia/dev/autoencoder_for_anomaly/convolutional_VAE/results/run_101/qcd_sqrtshatTeV_13TeV_PU40_ALL_parts
reading  /eos/home-k/kiwoznia/dev/autoencoder_for_anomaly/convolutional_VAE/results/run_101/qcd_sqrtshatTeV_13TeV_PU40_ALL_parts
num files in dir: 26
168377 events passed mass cut at 1100.0
168376 events passed mass cut at 1100.0
168376 events passed mass cut at 1100.0
168376 events passed mass cut at 1100.0
211320 events passed mass cut at 1100.0
211320 events passed mass cut at 1100.0
211320 events passed mass cut at 1100.0
211320 events passed mass cut at 1100.0
211320 events passed mass cut at 1100.0
211320 events passed mass cut at 1100.0
211320 events passed mass cut at 1100.0
211319 events passed mass cut at 1100.0
211320 events passed mass cut at 1100.0
211320 events passed mass cut at 1100.0
211320 events passed mass cut at 1100.0
211320 events passed mass cut at 1100.0
211320 events passed mass cut at 1100.0
211319 events passed mass cut at 1100.0
211320 events passed mass cut at 1100.0
211320 events passed mass cut at 1100.0
211320 events passed mass cut at 1100.0
211320 events passed mass cut at 1100.0
211320 events passed mass cut at 1100.0
211320 events passed mass cut at 1100.0
211320 events passed mass cut at 1100.0
211319 events passed mass cut at 1100.0

num files read in dir  /eos/home-k/kiwoznia/dev/autoencoder_for_anomaly/convolutional_VAE/results/run_101/qcd_sqrtshatTeV_13TeV_PU40_ALL_parts :  26

num events read in dir  5322542
reading /eos/home-k/kiwoznia/dev/autoencoder_for_anomaly/convolutional_VAE/results/run_101/RSGraviton_WW_NARROW_13TeV_PU40_2.5TeV_parts
reading  /eos/home-k/kiwoznia/dev/autoencoder_for_anomaly/convolutional_VAE/results/run_101/RSGraviton_WW_NARROW_13TeV_PU40_2.5TeV_parts
num files in dir: 2
256253 events passed mass cut at 1100.0
256252 events passed mass cut at 1100.0

num files read in dir  /eos/home-k/kiwoznia/dev/autoencoder_for_anomaly/convolutional_VAE/results/run_101/RSGraviton_WW_NARROW_13TeV_PU40_2.5TeV_parts :  2

num events read in dir  512505
reading /eos/home-k/kiwoznia/dev/autoencoder_for_anomaly/convolutional_VAE/results/run_101/RSGraviton_WW_NARROW_13TeV_PU40_3.5TeV_parts
reading  /eos/home-k/kiwoznia/dev/autoencoder_for_anomaly/convolutional_VAE/results/run_101/RSGraviton_WW_NARROW_13TeV_PU40_3.5TeV_parts
num files in dir: 2
257745 events passed mass cut at 1100.0
257744 events passed mass cut at 1100.0

num files read in dir  /eos/home-k/kiwoznia/dev/autoencoder_for_anomaly/convolutional_VAE/results/run_101/RSGraviton_WW_NARROW_13TeV_PU40_3.5TeV_parts :  2

num events read in dir  515489
['mJJ', 'j1Pt', 'j1Eta', 'j1Phi', 'j1M', 'j1E', 'j2Pt', 'j2M', 'j2E', 'DeltaEtaJJ', 'DeltaPhiJJ', 'j1TotalLoss', 'j2TotalLoss', 'j2RecoLoss', 'j2KlLoss', 'j1RecoLoss', 'j1KlLoss']
writing analysis results to  /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101
WARNING: Logging before flag parsing goes to stderr.
W0911 21:34:19.506309 139979516168000 deprecation.py:506] From /cvmfs/sft.cern.ch/lcg/views/LCG_96bpython3/x86_64-centos7-gcc9-opt/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0911 21:34:19.621293 139979516168000 deprecation.py:323] From /eos/home-k/kiwoznia/dev/data_driven_anomaly_hunting/dadrah/selection/quantile_regression.py:14: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
Model: "model"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 1)]               0         
_________________________________________________________________
dense (Dense)                (None, 70)                140       
_________________________________________________________________
dense_1 (Dense)              (None, 70)                4970      
_________________________________________________________________
dense_2 (Dense)              (None, 70)                4970      
_________________________________________________________________
dense_3 (Dense)              (None, 70)                4970      
_________________________________________________________________
dense_4 (Dense)              (None, 1)                 71        
=================================================================
Total params: 15,121
Trainable params: 15,121
Non-trainable params: 0
_________________________________________________________________
Train on 1277409 samples, validate on 319353 samples
Epoch 1/100
2020-09-11 21:34:20.006374: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2020-09-11 21:34:20.027321: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz
2020-09-11 21:34:20.034786: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1f713ab0 executing computations on platform Host. Devices:
2020-09-11 21:34:20.034832: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2020-09-11 21:34:20.099840: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
1277409/1277409 - 43s - loss: 9.9876e-04 - val_loss: 9.7885e-04
Epoch 2/100
1277409/1277409 - 42s - loss: 9.5193e-04 - val_loss: 9.5524e-04
Epoch 3/100
1277409/1277409 - 41s - loss: 9.4459e-04 - val_loss: 9.2484e-04
Epoch 4/100

Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
1277409/1277409 - 43s - loss: 9.3809e-04 - val_loss: 9.3405e-04
Epoch 5/100
1277409/1277409 - 42s - loss: 9.2115e-04 - val_loss: 9.3878e-04
Epoch 6/100
1277409/1277409 - 42s - loss: 9.2091e-04 - val_loss: 9.0984e-04
Epoch 7/100

Epoch 00007: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
1277409/1277409 - 42s - loss: 9.2084e-04 - val_loss: 9.1113e-04
Epoch 8/100
1277409/1277409 - 42s - loss: 9.1707e-04 - val_loss: 9.0910e-04
Epoch 9/100
1277409/1277409 - 43s - loss: 9.1706e-04 - val_loss: 9.0929e-04
Epoch 10/100

Epoch 00010: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
1277409/1277409 - 43s - loss: 9.1703e-04 - val_loss: 9.0969e-04
Epoch 11/100
1277409/1277409 - 41s - loss: 9.1635e-04 - val_loss: 9.0890e-04
Epoch 12/100
1277409/1277409 - 43s - loss: 9.1633e-04 - val_loss: 9.0883e-04
Epoch 13/100

Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
1277409/1277409 - 43s - loss: 9.1633e-04 - val_loss: 9.0880e-04
Epoch 14/100
1277409/1277409 - 43s - loss: 9.1618e-04 - val_loss: 9.0885e-04
Epoch 15/100
1277409/1277409 - 42s - loss: 9.1617e-04 - val_loss: 9.0888e-04
Epoch 16/100

Epoch 00016: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
1277409/1277409 - 42s - loss: 9.1618e-04 - val_loss: 9.0884e-04
Epoch 17/100
1277409/1277409 - 40s - loss: 9.1612e-04 - val_loss: 9.0880e-04
Epoch 18/100
1277409/1277409 - 43s - loss: 9.1613e-04 - val_loss: 9.0883e-04
Epoch 19/100

Epoch 00019: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.
1277409/1277409 - 41s - loss: 9.1613e-04 - val_loss: 9.0883e-04
Epoch 20/100
1277409/1277409 - 42s - loss: 9.1612e-04 - val_loss: 9.0883e-04
Epoch 21/100
1277409/1277409 - 42s - loss: 9.1612e-04 - val_loss: 9.0882e-04
Epoch 22/100

Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.
1277409/1277409 - 43s - loss: 9.1612e-04 - val_loss: 9.0882e-04
Epoch 23/100
1277409/1277409 - 42s - loss: 9.1612e-04 - val_loss: 9.0882e-04
Epoch 00023: early stopping
saving model  QRmodel_train_sz30pc_qnt1_20200911
min 1100.0001220703125, max 7338.603515625
TH1D::Sumw2:0: RuntimeWarning: Sum of squares of weights structure already created
Info in <TCanvas::Print>: jpg file /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/fig/QCD_training_set:_BG_like_vs_SIG_like_mjj_distribution_and_their_ratio_qnt_1.jpg has been created
min 1100.0001220703125, max 6713.01171875
TH1D::Sumw2:0: RuntimeWarning: Sum of squares of weights structure already created
Info in <TCanvas::Print>: jpg file /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/fig/QCD_test_set:_BG_like_vs_SIG_like_mjj_distribution_and_ratio_qnt_1.jpg has been created
+---------------+-------------+
|     Sample    | Eff VAE [%] |
+---------------+-------------+
| qcdSigAllReco |     1.00    |
| GtoWW25naReco |     1.38    |
| GtoWW35naReco |     1.07    |
+---------------+-------------+
min 1100.037841796875, max 6329.51171875
TH1D::Sumw2:0: RuntimeWarning: Sum of squares of weights structure already created
Info in <TCanvas::Print>: jpg file /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/fig/GtoWW25naReco:_BG_like_vs_SIG_like_mjj_distribution_and_ratio_qnt_1.jpg has been created
min 1100.159423828125, max 6971.1318359375
TH1D::Sumw2:0: RuntimeWarning: Sum of squares of weights structure already created
Info in <TCanvas::Print>: jpg file /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/fig/GtoWW35naReco:_BG_like_vs_SIG_like_mjj_distribution_and_ratio_qnt_1.jpg has been created
writing results for QCD signalregion all samples reco to /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/selections/minRecoKL_loss/q1/qcd_sqrtshatTeV_13TeV_PU40_ALL_parts/qcd_sqrtshatTeV_13TeV_PU40_ALL_reco.h5
written data sample to /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/selections/minRecoKL_loss/q1/qcd_sqrtshatTeV_13TeV_PU40_ALL_parts/qcd_sqrtshatTeV_13TeV_PU40_ALL_reco.h5
writing results for $G(2.5 TeV)\to WW$ narrow reco to /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/selections/minRecoKL_loss/q1/RSGraviton_WW_NARROW_13TeV_PU40_2.5TeV_parts/RSGraviton_WW_NARROW_13TeV_PU40_2.5TeV_reco.h5
written data sample to /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/selections/minRecoKL_loss/q1/RSGraviton_WW_NARROW_13TeV_PU40_2.5TeV_parts/RSGraviton_WW_NARROW_13TeV_PU40_2.5TeV_reco.h5
writing results for $G(3.5 TeV)\to WW$ narrow reco to /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/selections/minRecoKL_loss/q1/RSGraviton_WW_NARROW_13TeV_PU40_3.5TeV_parts/RSGraviton_WW_NARROW_13TeV_PU40_3.5TeV_reco.h5
written data sample to /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/selections/minRecoKL_loss/q1/RSGraviton_WW_NARROW_13TeV_PU40_3.5TeV_parts/RSGraviton_WW_NARROW_13TeV_PU40_3.5TeV_reco.h5
writing analysis results to  /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101
Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 1)]               0         
_________________________________________________________________
dense_5 (Dense)              (None, 70)                140       
_________________________________________________________________
dense_6 (Dense)              (None, 70)                4970      
_________________________________________________________________
dense_7 (Dense)              (None, 70)                4970      
_________________________________________________________________
dense_8 (Dense)              (None, 70)                4970      
_________________________________________________________________
dense_9 (Dense)              (None, 1)                 71        
=================================================================
Total params: 15,121
Trainable params: 15,121
Non-trainable params: 0
_________________________________________________________________
Train on 1277409 samples, validate on 319353 samples
Epoch 1/100
1277409/1277409 - 45s - loss: 0.0033 - val_loss: 0.0032
Epoch 2/100
1277409/1277409 - 43s - loss: 0.0032 - val_loss: 0.0032
Epoch 3/100
1277409/1277409 - 44s - loss: 0.0032 - val_loss: 0.0032
Epoch 4/100

Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
1277409/1277409 - 44s - loss: 0.0032 - val_loss: 0.0032
Epoch 5/100
1277409/1277409 - 44s - loss: 0.0032 - val_loss: 0.0032
Epoch 6/100
1277409/1277409 - 43s - loss: 0.0032 - val_loss: 0.0032
Epoch 7/100

Epoch 00007: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
1277409/1277409 - 42s - loss: 0.0032 - val_loss: 0.0032
Epoch 8/100
1277409/1277409 - 44s - loss: 0.0032 - val_loss: 0.0032
Epoch 9/100
1277409/1277409 - 44s - loss: 0.0032 - val_loss: 0.0032
Epoch 10/100

Epoch 00010: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
1277409/1277409 - 43s - loss: 0.0032 - val_loss: 0.0032
Epoch 11/100
1277409/1277409 - 42s - loss: 0.0032 - val_loss: 0.0032
Epoch 12/100
1277409/1277409 - 43s - loss: 0.0032 - val_loss: 0.0032
Epoch 13/100

Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
1277409/1277409 - 43s - loss: 0.0032 - val_loss: 0.0032
Epoch 14/100
1277409/1277409 - 44s - loss: 0.0032 - val_loss: 0.0032
Epoch 15/100
1277409/1277409 - 44s - loss: 0.0032 - val_loss: 0.0032
Epoch 16/100

Epoch 00016: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
1277409/1277409 - 44s - loss: 0.0032 - val_loss: 0.0032
Epoch 17/100
1277409/1277409 - 42s - loss: 0.0032 - val_loss: 0.0032
Epoch 18/100
1277409/1277409 - 44s - loss: 0.0032 - val_loss: 0.0032
Epoch 19/100

Epoch 00019: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.
1277409/1277409 - 44s - loss: 0.0032 - val_loss: 0.0032
Epoch 20/100
1277409/1277409 - 44s - loss: 0.0032 - val_loss: 0.0032
Epoch 21/100
1277409/1277409 - 43s - loss: 0.0032 - val_loss: 0.0032
Epoch 22/100

Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.
1277409/1277409 - 44s - loss: 0.0032 - val_loss: 0.0032
Epoch 23/100
1277409/1277409 - 44s - loss: 0.0032 - val_loss: 0.0032
Epoch 24/100
1277409/1277409 - 42s - loss: 0.0032 - val_loss: 0.0032
Epoch 25/100

Epoch 00025: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-09.
1277409/1277409 - 44s - loss: 0.0032 - val_loss: 0.0032
Epoch 26/100
1277409/1277409 - 43s - loss: 0.0032 - val_loss: 0.0032
Epoch 27/100
1277409/1277409 - 43s - loss: 0.0032 - val_loss: 0.0032
Epoch 28/100

Epoch 00028: ReduceLROnPlateau reducing learning rate to 5.1200004236307e-10.
1277409/1277409 - 43s - loss: 0.0032 - val_loss: 0.0032
Epoch 29/100
1277409/1277409 - 43s - loss: 0.0032 - val_loss: 0.0032
Epoch 30/100
1277409/1277409 - 43s - loss: 0.0032 - val_loss: 0.0032
Epoch 31/100

Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.0240001069306004e-10.
1277409/1277409 - 41s - loss: 0.0032 - val_loss: 0.0032
Epoch 32/100
1277409/1277409 - 43s - loss: 0.0032 - val_loss: 0.0032
Epoch 33/100
1277409/1277409 - 43s - loss: 0.0032 - val_loss: 0.0032
Epoch 34/100

Epoch 00034: ReduceLROnPlateau reducing learning rate to 2.0480002416167767e-11.
1277409/1277409 - 43s - loss: 0.0032 - val_loss: 0.0032
Epoch 35/100
1277409/1277409 - 42s - loss: 0.0032 - val_loss: 0.0032
Epoch 36/100
1277409/1277409 - 43s - loss: 0.0032 - val_loss: 0.0032
Epoch 37/100

Epoch 00037: ReduceLROnPlateau reducing learning rate to 4.096000622011431e-12.
1277409/1277409 - 43s - loss: 0.0032 - val_loss: 0.0032
Epoch 38/100
1277409/1277409 - 44s - loss: 0.0032 - val_loss: 0.0032
Epoch 39/100
1277409/1277409 - 43s - loss: 0.0032 - val_loss: 0.0032
Epoch 40/100

Epoch 00040: ReduceLROnPlateau reducing learning rate to 8.192000897078167e-13.
1277409/1277409 - 42s - loss: 0.0032 - val_loss: 0.0032
Epoch 41/100
1277409/1277409 - 43s - loss: 0.0032 - val_loss: 0.0032
Epoch 42/100
1277409/1277409 - 44s - loss: 0.0032 - val_loss: 0.0032
Epoch 43/100

Epoch 00043: ReduceLROnPlateau reducing learning rate to 1.6384001360475466e-13.
1277409/1277409 - 44s - loss: 0.0032 - val_loss: 0.0032
Epoch 44/100
1277409/1277409 - 40s - loss: 0.0032 - val_loss: 0.0032
Epoch 45/100
1277409/1277409 - 42s - loss: 0.0032 - val_loss: 0.0032
Epoch 46/100

Epoch 00046: ReduceLROnPlateau reducing learning rate to 3.2768002178849846e-14.
1277409/1277409 - 41s - loss: 0.0032 - val_loss: 0.0032
Epoch 47/100
1277409/1277409 - 42s - loss: 0.0032 - val_loss: 0.0032
Epoch 48/100
1277409/1277409 - 43s - loss: 0.0032 - val_loss: 0.0032
Epoch 49/100

Epoch 00049: ReduceLROnPlateau reducing learning rate to 6.553600300244697e-15.
1277409/1277409 - 44s - loss: 0.0032 - val_loss: 0.0032
Epoch 00049: early stopping
saving model  QRmodel_train_sz30pc_qnt5_20200911
min 1100.0001220703125, max 7338.603515625
TH1D::Sumw2:0: RuntimeWarning: Sum of squares of weights structure already created
Info in <TCanvas::Print>: jpg file /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/fig/QCD_training_set:_BG_like_vs_SIG_like_mjj_distribution_and_their_ratio_qnt_5.jpg has been created
min 1100.0001220703125, max 6713.01171875
TH1D::Sumw2:0: RuntimeWarning: Sum of squares of weights structure already created
Info in <TCanvas::Print>: jpg file /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/fig/QCD_test_set:_BG_like_vs_SIG_like_mjj_distribution_and_ratio_qnt_5.jpg has been created
+---------------+-------------+
|     Sample    | Eff VAE [%] |
+---------------+-------------+
| qcdSigAllReco |     5.02    |
| GtoWW25naReco |     8.68    |
| GtoWW35naReco |     9.75    |
+---------------+-------------+
min 1100.037841796875, max 6329.51171875
TH1D::Sumw2:0: RuntimeWarning: Sum of squares of weights structure already created
Info in <TCanvas::Print>: jpg file /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/fig/GtoWW25naReco:_BG_like_vs_SIG_like_mjj_distribution_and_ratio_qnt_5.jpg has been created
min 1100.159423828125, max 6971.1318359375
TH1D::Sumw2:0: RuntimeWarning: Sum of squares of weights structure already created
Info in <TCanvas::Print>: jpg file /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/fig/GtoWW35naReco:_BG_like_vs_SIG_like_mjj_distribution_and_ratio_qnt_5.jpg has been created
writing results for QCD signalregion all samples reco to /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/selections/minRecoKL_loss/q5/qcd_sqrtshatTeV_13TeV_PU40_ALL_parts/qcd_sqrtshatTeV_13TeV_PU40_ALL_reco.h5
written data sample to /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/selections/minRecoKL_loss/q5/qcd_sqrtshatTeV_13TeV_PU40_ALL_parts/qcd_sqrtshatTeV_13TeV_PU40_ALL_reco.h5
writing results for $G(2.5 TeV)\to WW$ narrow reco to /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/selections/minRecoKL_loss/q5/RSGraviton_WW_NARROW_13TeV_PU40_2.5TeV_parts/RSGraviton_WW_NARROW_13TeV_PU40_2.5TeV_reco.h5
written data sample to /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/selections/minRecoKL_loss/q5/RSGraviton_WW_NARROW_13TeV_PU40_2.5TeV_parts/RSGraviton_WW_NARROW_13TeV_PU40_2.5TeV_reco.h5
writing results for $G(3.5 TeV)\to WW$ narrow reco to /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/selections/minRecoKL_loss/q5/RSGraviton_WW_NARROW_13TeV_PU40_3.5TeV_parts/RSGraviton_WW_NARROW_13TeV_PU40_3.5TeV_reco.h5
written data sample to /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/selections/minRecoKL_loss/q5/RSGraviton_WW_NARROW_13TeV_PU40_3.5TeV_parts/RSGraviton_WW_NARROW_13TeV_PU40_3.5TeV_reco.h5
writing analysis results to  /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101
Model: "model_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_3 (InputLayer)         [(None, 1)]               0         
_________________________________________________________________
dense_10 (Dense)             (None, 70)                140       
_________________________________________________________________
dense_11 (Dense)             (None, 70)                4970      
_________________________________________________________________
dense_12 (Dense)             (None, 70)                4970      
_________________________________________________________________
dense_13 (Dense)             (None, 70)                4970      
_________________________________________________________________
dense_14 (Dense)             (None, 1)                 71        
=================================================================
Total params: 15,121
Trainable params: 15,121
Non-trainable params: 0
_________________________________________________________________
Train on 1277409 samples, validate on 319353 samples
Epoch 1/100
1277409/1277409 - 45s - loss: 0.0052 - val_loss: 0.0055
Epoch 2/100
1277409/1277409 - 45s - loss: 0.0052 - val_loss: 0.0052
Epoch 3/100
1277409/1277409 - 45s - loss: 0.0051 - val_loss: 0.0056
Epoch 4/100
1277409/1277409 - 45s - loss: 0.0051 - val_loss: 0.0051
Epoch 5/100

Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
1277409/1277409 - 45s - loss: 0.0051 - val_loss: 0.0051
Epoch 6/100
1277409/1277409 - 45s - loss: 0.0051 - val_loss: 0.0051
Epoch 7/100
1277409/1277409 - 44s - loss: 0.0051 - val_loss: 0.0051
Epoch 8/100

Epoch 00008: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
1277409/1277409 - 43s - loss: 0.0051 - val_loss: 0.0051
Epoch 9/100
1277409/1277409 - 42s - loss: 0.0051 - val_loss: 0.0051
Epoch 10/100
1277409/1277409 - 44s - loss: 0.0051 - val_loss: 0.0051
Epoch 11/100

Epoch 00011: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
1277409/1277409 - 45s - loss: 0.0051 - val_loss: 0.0051
Epoch 12/100
1277409/1277409 - 42s - loss: 0.0051 - val_loss: 0.0051
Epoch 13/100
1277409/1277409 - 43s - loss: 0.0051 - val_loss: 0.0051
Epoch 14/100

Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
1277409/1277409 - 41s - loss: 0.0051 - val_loss: 0.0051
Epoch 15/100
1277409/1277409 - 41s - loss: 0.0051 - val_loss: 0.0051
Epoch 16/100
1277409/1277409 - 43s - loss: 0.0051 - val_loss: 0.0051
Epoch 17/100

Epoch 00017: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
1277409/1277409 - 44s - loss: 0.0051 - val_loss: 0.0051
Epoch 18/100
1277409/1277409 - 43s - loss: 0.0051 - val_loss: 0.0051
Epoch 19/100
1277409/1277409 - 44s - loss: 0.0051 - val_loss: 0.0051
Epoch 20/100

Epoch 00020: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.
1277409/1277409 - 41s - loss: 0.0051 - val_loss: 0.0051
Epoch 21/100
1277409/1277409 - 41s - loss: 0.0051 - val_loss: 0.0051
Epoch 22/100
1277409/1277409 - 43s - loss: 0.0051 - val_loss: 0.0051
Epoch 23/100

Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.
1277409/1277409 - 44s - loss: 0.0051 - val_loss: 0.0051
Epoch 24/100
1277409/1277409 - 43s - loss: 0.0051 - val_loss: 0.0051
Epoch 25/100
1277409/1277409 - 43s - loss: 0.0051 - val_loss: 0.0051
Epoch 26/100

Epoch 00026: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-09.
1277409/1277409 - 42s - loss: 0.0051 - val_loss: 0.0051
Epoch 27/100
1277409/1277409 - 43s - loss: 0.0051 - val_loss: 0.0051
Epoch 28/100
1277409/1277409 - 42s - loss: 0.0051 - val_loss: 0.0051
Epoch 29/100

Epoch 00029: ReduceLROnPlateau reducing learning rate to 5.1200004236307e-10.
1277409/1277409 - 43s - loss: 0.0051 - val_loss: 0.0051
Epoch 30/100
1277409/1277409 - 44s - loss: 0.0051 - val_loss: 0.0051
Epoch 31/100
1277409/1277409 - 44s - loss: 0.0051 - val_loss: 0.0051
Epoch 32/100

Epoch 00032: ReduceLROnPlateau reducing learning rate to 1.0240001069306004e-10.
1277409/1277409 - 45s - loss: 0.0051 - val_loss: 0.0051
Epoch 33/100
1277409/1277409 - 40s - loss: 0.0051 - val_loss: 0.0051
Epoch 34/100
1277409/1277409 - 42s - loss: 0.0051 - val_loss: 0.0051
Epoch 35/100

Epoch 00035: ReduceLROnPlateau reducing learning rate to 2.0480002416167767e-11.
1277409/1277409 - 42s - loss: 0.0051 - val_loss: 0.0051
Epoch 36/100
1277409/1277409 - 43s - loss: 0.0051 - val_loss: 0.0051
Epoch 37/100
1277409/1277409 - 43s - loss: 0.0051 - val_loss: 0.0051
Epoch 38/100

Epoch 00038: ReduceLROnPlateau reducing learning rate to 4.096000622011431e-12.
1277409/1277409 - 43s - loss: 0.0051 - val_loss: 0.0051
Epoch 39/100
1277409/1277409 - 41s - loss: 0.0051 - val_loss: 0.0051
Epoch 00039: early stopping
saving model  QRmodel_train_sz30pc_qnt10_20200911
min 1100.0001220703125, max 7338.603515625
TH1D::Sumw2:0: RuntimeWarning: Sum of squares of weights structure already created
Info in <TCanvas::Print>: jpg file /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/fig/QCD_training_set:_BG_like_vs_SIG_like_mjj_distribution_and_their_ratio_qnt_10.jpg has been created
min 1100.0001220703125, max 6713.01171875
TH1D::Sumw2:0: RuntimeWarning: Sum of squares of weights structure already created
Info in <TCanvas::Print>: jpg file /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/fig/QCD_test_set:_BG_like_vs_SIG_like_mjj_distribution_and_ratio_qnt_10.jpg has been created
+---------------+-------------+
|     Sample    | Eff VAE [%] |
+---------------+-------------+
| qcdSigAllReco |    10.04    |
| GtoWW25naReco |    18.60    |
| GtoWW35naReco |    19.90    |
+---------------+-------------+
min 1100.037841796875, max 6329.51171875
TH1D::Sumw2:0: RuntimeWarning: Sum of squares of weights structure already created
Info in <TCanvas::Print>: jpg file /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/fig/GtoWW25naReco:_BG_like_vs_SIG_like_mjj_distribution_and_ratio_qnt_10.jpg has been created
min 1100.159423828125, max 6971.1318359375
TH1D::Sumw2:0: RuntimeWarning: Sum of squares of weights structure already created
Info in <TCanvas::Print>: jpg file /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/fig/GtoWW35naReco:_BG_like_vs_SIG_like_mjj_distribution_and_ratio_qnt_10.jpg has been created
writing results for QCD signalregion all samples reco to /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/selections/minRecoKL_loss/q10/qcd_sqrtshatTeV_13TeV_PU40_ALL_parts/qcd_sqrtshatTeV_13TeV_PU40_ALL_reco.h5
written data sample to /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/selections/minRecoKL_loss/q10/qcd_sqrtshatTeV_13TeV_PU40_ALL_parts/qcd_sqrtshatTeV_13TeV_PU40_ALL_reco.h5
writing results for $G(2.5 TeV)\to WW$ narrow reco to /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/selections/minRecoKL_loss/q10/RSGraviton_WW_NARROW_13TeV_PU40_2.5TeV_parts/RSGraviton_WW_NARROW_13TeV_PU40_2.5TeV_reco.h5
written data sample to /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/selections/minRecoKL_loss/q10/RSGraviton_WW_NARROW_13TeV_PU40_2.5TeV_parts/RSGraviton_WW_NARROW_13TeV_PU40_2.5TeV_reco.h5
writing results for $G(3.5 TeV)\to WW$ narrow reco to /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/selections/minRecoKL_loss/q10/RSGraviton_WW_NARROW_13TeV_PU40_3.5TeV_parts/RSGraviton_WW_NARROW_13TeV_PU40_3.5TeV_reco.h5
written data sample to /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/selections/minRecoKL_loss/q10/RSGraviton_WW_NARROW_13TeV_PU40_3.5TeV_parts/RSGraviton_WW_NARROW_13TeV_PU40_3.5TeV_reco.h5
writing analysis results to  /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101
Model: "model_3"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_4 (InputLayer)         [(None, 1)]               0         
_________________________________________________________________
dense_15 (Dense)             (None, 70)                140       
_________________________________________________________________
dense_16 (Dense)             (None, 70)                4970      
_________________________________________________________________
dense_17 (Dense)             (None, 70)                4970      
_________________________________________________________________
dense_18 (Dense)             (None, 70)                4970      
_________________________________________________________________
dense_19 (Dense)             (None, 1)                 71        
=================================================================
Total params: 15,121
Trainable params: 15,121
Non-trainable params: 0
_________________________________________________________________
Train on 1277409 samples, validate on 319353 samples
Epoch 1/100
1277409/1277409 - 46s - loss: 0.0090 - val_loss: 0.0089
Epoch 2/100
1277409/1277409 - 42s - loss: 0.0090 - val_loss: 0.0090
Epoch 3/100
1277409/1277409 - 42s - loss: 0.0089 - val_loss: 0.0089
Epoch 4/100

Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
1277409/1277409 - 45s - loss: 0.0089 - val_loss: 0.0089
Epoch 5/100
1277409/1277409 - 45s - loss: 0.0089 - val_loss: 0.0089
Epoch 6/100
1277409/1277409 - 45s - loss: 0.0089 - val_loss: 0.0089
Epoch 7/100

Epoch 00007: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
1277409/1277409 - 45s - loss: 0.0089 - val_loss: 0.0089
Epoch 8/100
1277409/1277409 - 43s - loss: 0.0089 - val_loss: 0.0089
Epoch 9/100
1277409/1277409 - 45s - loss: 0.0089 - val_loss: 0.0089
Epoch 10/100

Epoch 00010: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
1277409/1277409 - 46s - loss: 0.0089 - val_loss: 0.0089
Epoch 11/100
1277409/1277409 - 45s - loss: 0.0089 - val_loss: 0.0089
Epoch 12/100
1277409/1277409 - 45s - loss: 0.0089 - val_loss: 0.0089
Epoch 13/100

Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
1277409/1277409 - 48s - loss: 0.0089 - val_loss: 0.0089
Epoch 14/100
1277409/1277409 - 47s - loss: 0.0089 - val_loss: 0.0089
Epoch 15/100
1277409/1277409 - 48s - loss: 0.0089 - val_loss: 0.0089
Epoch 16/100

Epoch 00016: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
1277409/1277409 - 48s - loss: 0.0089 - val_loss: 0.0089
Epoch 17/100
1277409/1277409 - 47s - loss: 0.0089 - val_loss: 0.0089
Epoch 18/100
1277409/1277409 - 48s - loss: 0.0089 - val_loss: 0.0089
Epoch 19/100

Epoch 00019: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.
1277409/1277409 - 49s - loss: 0.0089 - val_loss: 0.0089
Epoch 20/100
1277409/1277409 - 47s - loss: 0.0089 - val_loss: 0.0089
Epoch 21/100
1277409/1277409 - 47s - loss: 0.0089 - val_loss: 0.0089
Epoch 00021: early stopping
saving model  QRmodel_train_sz30pc_qnt30_20200911
min 1100.0001220703125, max 7338.603515625
TH1D::Sumw2:0: RuntimeWarning: Sum of squares of weights structure already created
Info in <TCanvas::Print>: jpg file /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/fig/QCD_training_set:_BG_like_vs_SIG_like_mjj_distribution_and_their_ratio_qnt_30.jpg has been created
min 1100.0001220703125, max 6713.01171875
TH1D::Sumw2:0: RuntimeWarning: Sum of squares of weights structure already created
Info in <TCanvas::Print>: jpg file /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/fig/QCD_test_set:_BG_like_vs_SIG_like_mjj_distribution_and_ratio_qnt_30.jpg has been created
+---------------+-------------+
|     Sample    | Eff VAE [%] |
+---------------+-------------+
| qcdSigAllReco |    30.04    |
| GtoWW25naReco |    53.21    |
| GtoWW35naReco |    55.14    |
+---------------+-------------+
min 1100.037841796875, max 6329.51171875
TH1D::Sumw2:0: RuntimeWarning: Sum of squares of weights structure already created
Info in <TCanvas::Print>: jpg file /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/fig/GtoWW25naReco:_BG_like_vs_SIG_like_mjj_distribution_and_ratio_qnt_30.jpg has been created
min 1100.159423828125, max 6971.1318359375
TH1D::Sumw2:0: RuntimeWarning: Sum of squares of weights structure already created
Info in <TCanvas::Print>: jpg file /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/fig/GtoWW35naReco:_BG_like_vs_SIG_like_mjj_distribution_and_ratio_qnt_30.jpg has been created
writing results for QCD signalregion all samples reco to /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/selections/minRecoKL_loss/q30/qcd_sqrtshatTeV_13TeV_PU40_ALL_parts/qcd_sqrtshatTeV_13TeV_PU40_ALL_reco.h5
written data sample to /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/selections/minRecoKL_loss/q30/qcd_sqrtshatTeV_13TeV_PU40_ALL_parts/qcd_sqrtshatTeV_13TeV_PU40_ALL_reco.h5
writing results for $G(2.5 TeV)\to WW$ narrow reco to /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/selections/minRecoKL_loss/q30/RSGraviton_WW_NARROW_13TeV_PU40_2.5TeV_parts/RSGraviton_WW_NARROW_13TeV_PU40_2.5TeV_reco.h5
written data sample to /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/selections/minRecoKL_loss/q30/RSGraviton_WW_NARROW_13TeV_PU40_2.5TeV_parts/RSGraviton_WW_NARROW_13TeV_PU40_2.5TeV_reco.h5
writing results for $G(3.5 TeV)\to WW$ narrow reco to /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/selections/minRecoKL_loss/q30/RSGraviton_WW_NARROW_13TeV_PU40_3.5TeV_parts/RSGraviton_WW_NARROW_13TeV_PU40_3.5TeV_reco.h5
written data sample to /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/selections/minRecoKL_loss/q30/RSGraviton_WW_NARROW_13TeV_PU40_3.5TeV_parts/RSGraviton_WW_NARROW_13TeV_PU40_3.5TeV_reco.h5
writing analysis results to  /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101
Model: "model_4"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_5 (InputLayer)         [(None, 1)]               0         
_________________________________________________________________
dense_20 (Dense)             (None, 70)                140       
_________________________________________________________________
dense_21 (Dense)             (None, 70)                4970      
_________________________________________________________________
dense_22 (Dense)             (None, 70)                4970      
_________________________________________________________________
dense_23 (Dense)             (None, 70)                4970      
_________________________________________________________________
dense_24 (Dense)             (None, 1)                 71        
=================================================================
Total params: 15,121
Trainable params: 15,121
Non-trainable params: 0
_________________________________________________________________
Train on 1277409 samples, validate on 319353 samples
Epoch 1/100
1277409/1277409 - 51s - loss: 0.0094 - val_loss: 0.0094
Epoch 2/100
1277409/1277409 - 51s - loss: 0.0094 - val_loss: 0.0093
Epoch 3/100
1277409/1277409 - 50s - loss: 0.0094 - val_loss: 0.0093
Epoch 4/100
1277409/1277409 - 52s - loss: 0.0094 - val_loss: 0.0093
Epoch 5/100

Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
1277409/1277409 - 50s - loss: 0.0094 - val_loss: 0.0094
Epoch 6/100
1277409/1277409 - 51s - loss: 0.0093 - val_loss: 0.0093
Epoch 7/100
1277409/1277409 - 50s - loss: 0.0093 - val_loss: 0.0093
Epoch 8/100

Epoch 00008: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
1277409/1277409 - 52s - loss: 0.0093 - val_loss: 0.0093
Epoch 9/100
1277409/1277409 - 50s - loss: 0.0093 - val_loss: 0.0093
Epoch 10/100
1277409/1277409 - 51s - loss: 0.0093 - val_loss: 0.0093
Epoch 11/100

Epoch 00011: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
1277409/1277409 - 50s - loss: 0.0093 - val_loss: 0.0093
Epoch 12/100
1277409/1277409 - 51s - loss: 0.0093 - val_loss: 0.0093
Epoch 13/100
1277409/1277409 - 50s - loss: 0.0093 - val_loss: 0.0093
Epoch 14/100

Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
1277409/1277409 - 51s - loss: 0.0093 - val_loss: 0.0093
Epoch 15/100
1277409/1277409 - 51s - loss: 0.0093 - val_loss: 0.0093
Epoch 16/100
1277409/1277409 - 50s - loss: 0.0093 - val_loss: 0.0093
Epoch 17/100

Epoch 00017: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
1277409/1277409 - 51s - loss: 0.0093 - val_loss: 0.0093
Epoch 18/100
1277409/1277409 - 50s - loss: 0.0093 - val_loss: 0.0093
Epoch 19/100
1277409/1277409 - 51s - loss: 0.0093 - val_loss: 0.0093
Epoch 20/100

Epoch 00020: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.
1277409/1277409 - 51s - loss: 0.0093 - val_loss: 0.0093
Epoch 21/100
1277409/1277409 - 50s - loss: 0.0093 - val_loss: 0.0093
Epoch 22/100
1277409/1277409 - 51s - loss: 0.0093 - val_loss: 0.0093
Epoch 23/100

Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.
1277409/1277409 - 50s - loss: 0.0093 - val_loss: 0.0093
Epoch 00023: early stopping
saving model  QRmodel_train_sz30pc_qnt50_20200911
min 1100.0001220703125, max 7338.603515625
TH1D::Sumw2:0: RuntimeWarning: Sum of squares of weights structure already created
Info in <TCanvas::Print>: jpg file /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/fig/QCD_training_set:_BG_like_vs_SIG_like_mjj_distribution_and_their_ratio_qnt_50.jpg has been created
min 1100.0001220703125, max 6713.01171875
TH1D::Sumw2:0: RuntimeWarning: Sum of squares of weights structure already created
Info in <TCanvas::Print>: jpg file /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/fig/QCD_test_set:_BG_like_vs_SIG_like_mjj_distribution_and_ratio_qnt_50.jpg has been created
+---------------+-------------+
|     Sample    | Eff VAE [%] |
+---------------+-------------+
| qcdSigAllReco |    50.03    |
| GtoWW25naReco |    76.80    |
| GtoWW35naReco |    78.83    |
+---------------+-------------+
min 1100.037841796875, max 6329.51171875
TH1D::Sumw2:0: RuntimeWarning: Sum of squares of weights structure already created
Info in <TCanvas::Print>: jpg file /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/fig/GtoWW25naReco:_BG_like_vs_SIG_like_mjj_distribution_and_ratio_qnt_50.jpg has been created
min 1100.159423828125, max 6971.1318359375
TH1D::Sumw2:0: RuntimeWarning: Sum of squares of weights structure already created
Info in <TCanvas::Print>: jpg file /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/fig/GtoWW35naReco:_BG_like_vs_SIG_like_mjj_distribution_and_ratio_qnt_50.jpg has been created
writing results for QCD signalregion all samples reco to /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/selections/minRecoKL_loss/q50/qcd_sqrtshatTeV_13TeV_PU40_ALL_parts/qcd_sqrtshatTeV_13TeV_PU40_ALL_reco.h5
written data sample to /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/selections/minRecoKL_loss/q50/qcd_sqrtshatTeV_13TeV_PU40_ALL_parts/qcd_sqrtshatTeV_13TeV_PU40_ALL_reco.h5
writing results for $G(2.5 TeV)\to WW$ narrow reco to /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/selections/minRecoKL_loss/q50/RSGraviton_WW_NARROW_13TeV_PU40_2.5TeV_parts/RSGraviton_WW_NARROW_13TeV_PU40_2.5TeV_reco.h5
written data sample to /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/selections/minRecoKL_loss/q50/RSGraviton_WW_NARROW_13TeV_PU40_2.5TeV_parts/RSGraviton_WW_NARROW_13TeV_PU40_2.5TeV_reco.h5
writing results for $G(3.5 TeV)\to WW$ narrow reco to /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/selections/minRecoKL_loss/q50/RSGraviton_WW_NARROW_13TeV_PU40_3.5TeV_parts/RSGraviton_WW_NARROW_13TeV_PU40_3.5TeV_reco.h5
written data sample to /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/selections/minRecoKL_loss/q50/RSGraviton_WW_NARROW_13TeV_PU40_3.5TeV_parts/RSGraviton_WW_NARROW_13TeV_PU40_3.5TeV_reco.h5
writing analysis results to  /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101
Model: "model_5"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_6 (InputLayer)         [(None, 1)]               0         
_________________________________________________________________
dense_25 (Dense)             (None, 70)                140       
_________________________________________________________________
dense_26 (Dense)             (None, 70)                4970      
_________________________________________________________________
dense_27 (Dense)             (None, 70)                4970      
_________________________________________________________________
dense_28 (Dense)             (None, 70)                4970      
_________________________________________________________________
dense_29 (Dense)             (None, 1)                 71        
=================================================================
Total params: 15,121
Trainable params: 15,121
Non-trainable params: 0
_________________________________________________________________
Train on 1277409 samples, validate on 319353 samples
Epoch 1/100
1277409/1277409 - 50s - loss: 0.0075 - val_loss: 0.0076
Epoch 2/100
1277409/1277409 - 50s - loss: 0.0075 - val_loss: 0.0075
Epoch 3/100
1277409/1277409 - 49s - loss: 0.0075 - val_loss: 0.0075
Epoch 4/100
1277409/1277409 - 51s - loss: 0.0075 - val_loss: 0.0074
Epoch 5/100

Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
1277409/1277409 - 51s - loss: 0.0075 - val_loss: 0.0075
Epoch 6/100
1277409/1277409 - 49s - loss: 0.0074 - val_loss: 0.0074
Epoch 7/100
1277409/1277409 - 50s - loss: 0.0074 - val_loss: 0.0074
Epoch 8/100

Epoch 00008: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
1277409/1277409 - 49s - loss: 0.0074 - val_loss: 0.0074
Epoch 9/100
1277409/1277409 - 50s - loss: 0.0074 - val_loss: 0.0074
Epoch 10/100
1277409/1277409 - 50s - loss: 0.0074 - val_loss: 0.0074
Epoch 11/100

Epoch 00011: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
1277409/1277409 - 49s - loss: 0.0074 - val_loss: 0.0074
Epoch 12/100
1277409/1277409 - 50s - loss: 0.0074 - val_loss: 0.0074
Epoch 13/100
1277409/1277409 - 51s - loss: 0.0074 - val_loss: 0.0074
Epoch 14/100

Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
1277409/1277409 - 49s - loss: 0.0074 - val_loss: 0.0074
Epoch 15/100
1277409/1277409 - 50s - loss: 0.0074 - val_loss: 0.0074
Epoch 16/100
1277409/1277409 - 49s - loss: 0.0074 - val_loss: 0.0074
Epoch 17/100

Epoch 00017: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
1277409/1277409 - 50s - loss: 0.0074 - val_loss: 0.0074
Epoch 18/100
1277409/1277409 - 49s - loss: 0.0074 - val_loss: 0.0074
Epoch 19/100
1277409/1277409 - 50s - loss: 0.0074 - val_loss: 0.0074
Epoch 20/100

Epoch 00020: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.
1277409/1277409 - 50s - loss: 0.0074 - val_loss: 0.0074
Epoch 21/100
1277409/1277409 - 49s - loss: 0.0074 - val_loss: 0.0074
Epoch 22/100
1277409/1277409 - 50s - loss: 0.0074 - val_loss: 0.0074
Epoch 23/100

Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.
1277409/1277409 - 49s - loss: 0.0074 - val_loss: 0.0074
Epoch 24/100
1277409/1277409 - 50s - loss: 0.0074 - val_loss: 0.0074
Epoch 25/100
1277409/1277409 - 50s - loss: 0.0074 - val_loss: 0.0074
Epoch 26/100

Epoch 00026: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-09.
1277409/1277409 - 48s - loss: 0.0074 - val_loss: 0.0074
Epoch 27/100
1277409/1277409 - 50s - loss: 0.0074 - val_loss: 0.0074
Epoch 28/100
1277409/1277409 - 49s - loss: 0.0074 - val_loss: 0.0074
Epoch 00028: early stopping
saving model  QRmodel_train_sz30pc_qnt70_20200912
min 1100.0001220703125, max 7338.603515625
TH1D::Sumw2:0: RuntimeWarning: Sum of squares of weights structure already created
Info in <TCanvas::Print>: jpg file /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/fig/QCD_training_set:_BG_like_vs_SIG_like_mjj_distribution_and_their_ratio_qnt_70.jpg has been created
min 1100.0001220703125, max 6713.01171875
TH1D::Sumw2:0: RuntimeWarning: Sum of squares of weights structure already created
Info in <TCanvas::Print>: jpg file /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/fig/QCD_test_set:_BG_like_vs_SIG_like_mjj_distribution_and_ratio_qnt_70.jpg has been created
+---------------+-------------+
|     Sample    | Eff VAE [%] |
+---------------+-------------+
| qcdSigAllReco |    70.01    |
| GtoWW25naReco |    91.50    |
| GtoWW35naReco |    92.70    |
+---------------+-------------+
min 1100.037841796875, max 6329.51171875
TH1D::Sumw2:0: RuntimeWarning: Sum of squares of weights structure already created
Info in <TCanvas::Print>: jpg file /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/fig/GtoWW25naReco:_BG_like_vs_SIG_like_mjj_distribution_and_ratio_qnt_70.jpg has been created
min 1100.159423828125, max 6971.1318359375
TH1D::Sumw2:0: RuntimeWarning: Sum of squares of weights structure already created
Info in <TCanvas::Print>: jpg file /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/fig/GtoWW35naReco:_BG_like_vs_SIG_like_mjj_distribution_and_ratio_qnt_70.jpg has been created
writing results for QCD signalregion all samples reco to /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/selections/minRecoKL_loss/q70/qcd_sqrtshatTeV_13TeV_PU40_ALL_parts/qcd_sqrtshatTeV_13TeV_PU40_ALL_reco.h5
written data sample to /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/selections/minRecoKL_loss/q70/qcd_sqrtshatTeV_13TeV_PU40_ALL_parts/qcd_sqrtshatTeV_13TeV_PU40_ALL_reco.h5
writing results for $G(2.5 TeV)\to WW$ narrow reco to /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/selections/minRecoKL_loss/q70/RSGraviton_WW_NARROW_13TeV_PU40_2.5TeV_parts/RSGraviton_WW_NARROW_13TeV_PU40_2.5TeV_reco.h5
written data sample to /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/selections/minRecoKL_loss/q70/RSGraviton_WW_NARROW_13TeV_PU40_2.5TeV_parts/RSGraviton_WW_NARROW_13TeV_PU40_2.5TeV_reco.h5
writing results for $G(3.5 TeV)\to WW$ narrow reco to /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/selections/minRecoKL_loss/q70/RSGraviton_WW_NARROW_13TeV_PU40_3.5TeV_parts/RSGraviton_WW_NARROW_13TeV_PU40_3.5TeV_reco.h5
written data sample to /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/selections/minRecoKL_loss/q70/RSGraviton_WW_NARROW_13TeV_PU40_3.5TeV_parts/RSGraviton_WW_NARROW_13TeV_PU40_3.5TeV_reco.h5
writing analysis results to  /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101
Model: "model_6"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_7 (InputLayer)         [(None, 1)]               0         
_________________________________________________________________
dense_30 (Dense)             (None, 70)                140       
_________________________________________________________________
dense_31 (Dense)             (None, 70)                4970      
_________________________________________________________________
dense_32 (Dense)             (None, 70)                4970      
_________________________________________________________________
dense_33 (Dense)             (None, 70)                4970      
_________________________________________________________________
dense_34 (Dense)             (None, 1)                 71        
=================================================================
Total params: 15,121
Trainable params: 15,121
Non-trainable params: 0
_________________________________________________________________
Train on 1277409 samples, validate on 319353 samples
Epoch 1/100
1277409/1277409 - 50s - loss: 0.0034 - val_loss: 0.0034
Epoch 2/100
1277409/1277409 - 48s - loss: 0.0034 - val_loss: 0.0034
Epoch 3/100
1277409/1277409 - 49s - loss: 0.0034 - val_loss: 0.0034
Epoch 4/100

Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
1277409/1277409 - 50s - loss: 0.0034 - val_loss: 0.0034
Epoch 5/100
1277409/1277409 - 49s - loss: 0.0034 - val_loss: 0.0034
Epoch 6/100
1277409/1277409 - 46s - loss: 0.0034 - val_loss: 0.0034
Epoch 7/100

Epoch 00007: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
1277409/1277409 - 48s - loss: 0.0034 - val_loss: 0.0034
Epoch 8/100
1277409/1277409 - 49s - loss: 0.0034 - val_loss: 0.0034
Epoch 9/100
1277409/1277409 - 49s - loss: 0.0034 - val_loss: 0.0034
Epoch 10/100

Epoch 00010: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
1277409/1277409 - 50s - loss: 0.0034 - val_loss: 0.0034
Epoch 11/100
1277409/1277409 - 49s - loss: 0.0034 - val_loss: 0.0034
Epoch 12/100
1277409/1277409 - 48s - loss: 0.0034 - val_loss: 0.0034
Epoch 13/100

Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
1277409/1277409 - 48s - loss: 0.0034 - val_loss: 0.0034
Epoch 14/100
1277409/1277409 - 50s - loss: 0.0034 - val_loss: 0.0034
Epoch 15/100
1277409/1277409 - 48s - loss: 0.0034 - val_loss: 0.0034
Epoch 16/100

Epoch 00016: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
1277409/1277409 - 49s - loss: 0.0034 - val_loss: 0.0034
Epoch 17/100
1277409/1277409 - 48s - loss: 0.0034 - val_loss: 0.0034
Epoch 18/100
1277409/1277409 - 49s - loss: 0.0034 - val_loss: 0.0034
Epoch 19/100

Epoch 00019: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.
1277409/1277409 - 49s - loss: 0.0034 - val_loss: 0.0034
Epoch 20/100
1277409/1277409 - 48s - loss: 0.0034 - val_loss: 0.0034
Epoch 21/100
1277409/1277409 - 49s - loss: 0.0034 - val_loss: 0.0034
Epoch 22/100

Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.
1277409/1277409 - 49s - loss: 0.0034 - val_loss: 0.0034
Epoch 23/100
1277409/1277409 - 49s - loss: 0.0034 - val_loss: 0.0034
Epoch 24/100
1277409/1277409 - 49s - loss: 0.0034 - val_loss: 0.0034
Epoch 25/100

Epoch 00025: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-09.
1277409/1277409 - 48s - loss: 0.0034 - val_loss: 0.0034
Epoch 26/100
1277409/1277409 - 50s - loss: 0.0034 - val_loss: 0.0034
Epoch 27/100
1277409/1277409 - 48s - loss: 0.0034 - val_loss: 0.0034
Epoch 00027: early stopping
saving model  QRmodel_train_sz30pc_qnt90_20200912
min 1100.0001220703125, max 7338.603515625
TH1D::Sumw2:0: RuntimeWarning: Sum of squares of weights structure already created
Info in <TCanvas::Print>: jpg file /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/fig/QCD_training_set:_BG_like_vs_SIG_like_mjj_distribution_and_their_ratio_qnt_90.jpg has been created
min 1100.0001220703125, max 6713.01171875
TH1D::Sumw2:0: RuntimeWarning: Sum of squares of weights structure already created
Info in <TCanvas::Print>: jpg file /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/fig/QCD_test_set:_BG_like_vs_SIG_like_mjj_distribution_and_ratio_qnt_90.jpg has been created
+---------------+-------------+
|     Sample    | Eff VAE [%] |
+---------------+-------------+
| qcdSigAllReco |    90.01    |
| GtoWW25naReco |    98.75    |
| GtoWW35naReco |    98.95    |
+---------------+-------------+
min 1100.037841796875, max 6329.51171875
TH1D::Sumw2:0: RuntimeWarning: Sum of squares of weights structure already created
Info in <TCanvas::Print>: jpg file /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/fig/GtoWW25naReco:_BG_like_vs_SIG_like_mjj_distribution_and_ratio_qnt_90.jpg has been created
min 1100.159423828125, max 6971.1318359375
TH1D::Sumw2:0: RuntimeWarning: Sum of squares of weights structure already created
Info in <TCanvas::Print>: jpg file /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/fig/GtoWW35naReco:_BG_like_vs_SIG_like_mjj_distribution_and_ratio_qnt_90.jpg has been created
writing results for QCD signalregion all samples reco to /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/selections/minRecoKL_loss/q90/qcd_sqrtshatTeV_13TeV_PU40_ALL_parts/qcd_sqrtshatTeV_13TeV_PU40_ALL_reco.h5
written data sample to /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/selections/minRecoKL_loss/q90/qcd_sqrtshatTeV_13TeV_PU40_ALL_parts/qcd_sqrtshatTeV_13TeV_PU40_ALL_reco.h5
writing results for $G(2.5 TeV)\to WW$ narrow reco to /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/selections/minRecoKL_loss/q90/RSGraviton_WW_NARROW_13TeV_PU40_2.5TeV_parts/RSGraviton_WW_NARROW_13TeV_PU40_2.5TeV_reco.h5
written data sample to /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/selections/minRecoKL_loss/q90/RSGraviton_WW_NARROW_13TeV_PU40_2.5TeV_parts/RSGraviton_WW_NARROW_13TeV_PU40_2.5TeV_reco.h5
writing results for $G(3.5 TeV)\to WW$ narrow reco to /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/selections/minRecoKL_loss/q90/RSGraviton_WW_NARROW_13TeV_PU40_3.5TeV_parts/RSGraviton_WW_NARROW_13TeV_PU40_3.5TeV_reco.h5
written data sample to /eos/home-k/kiwoznia/data/VAE_results/bump_hunt_results/run_101/selections/minRecoKL_loss/q90/RSGraviton_WW_NARROW_13TeV_PU40_3.5TeV_parts/RSGraviton_WW_NARROW_13TeV_PU40_3.5TeV_reco.h5
