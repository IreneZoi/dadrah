setGPU: Setting GPU to: 1

**********************************************************************
			 TRAINING RUN 
Parameters(run_n_vae=113, run_n_qr=4, qcd_sample_id='qcdSigReco', qcd_ext_sample_id='qcdSigExtReco', qcd_train_sample_id='qcdSigAllTrainReco', qcd_test_sample_id='qcdSigAllTestReco', sig_sample_id=None, strategy_id='rk5_05', epochs=100, read_n=None, poly_qr=True)
**********************************************************************
reading samples from /eos/user/k/kiwoznia/data/VAE_results/events/run_113
[DataReader] read_jet_features_from_dir(): reading all events from /eos/user/k/kiwoznia/data/VAE_results/events/run_113/qcd_sqrtshatTeV_13TeV_PU40_NEW_ALL_Train_signalregion_parts
1917939 events read in 1 files in dir /eos/user/k/kiwoznia/data/VAE_results/events/run_113/qcd_sqrtshatTeV_13TeV_PU40_NEW_ALL_Train_signalregion_parts
[DataReader] read_jet_features_from_dir(): reading all events from /eos/user/k/kiwoznia/data/VAE_results/events/run_113/qcd_sqrtshatTeV_13TeV_PU40_NEW_ALL_Test_signalregion_parts
7671759 events read in 1 files in dir /eos/user/k/kiwoznia/data/VAE_results/events/run_113/qcd_sqrtshatTeV_13TeV_PU40_NEW_ALL_Test_signalregion_parts
[DataReader] read_jet_features_from_dir(): reading all events from /eos/user/k/kiwoznia/data/VAE_results/events/run_113/RSGraviton_WW_NARROW_13TeV_PU40_3.5TeV_NEW_parts
531825 events read in 2 files in dir /eos/user/k/kiwoznia/data/VAE_results/events/run_113/RSGraviton_WW_NARROW_13TeV_PU40_3.5TeV_NEW_parts
training on 1535249 events, validating on 383813

training <class 'dadrah.selection.discriminator.QRDiscriminatorPoly_KerasAPI'> QR for quantile 0.1
Model: "functional_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 1)]          0                                            
__________________________________________________________________________________________________
Std_Normalize (StdNormalization (None, 1)            0           input_1[0][0]                    
__________________________________________________________________________________________________
lambda (Lambda)                 (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 3)            0           lambda[0][0]                     
                                                                 lambda_1[0][0]                   
                                                                 Std_Normalize[0][0]              
__________________________________________________________________________________________________
dense (Dense)                   (None, 1)            4           concatenate[0][0]                
==================================================================================================
Total params: 4
Trainable params: 4
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100
5998/5998 - 4s - loss: 0.0450 - val_loss: 0.0237
Epoch 2/100
5998/5998 - 4s - loss: 0.0239 - val_loss: 0.0237
Epoch 3/100
5998/5998 - 4s - loss: 0.0240 - val_loss: 0.0238
Epoch 4/100

Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
5998/5998 - 4s - loss: 0.0239 - val_loss: 0.0243
Epoch 5/100
5998/5998 - 4s - loss: 0.0238 - val_loss: 0.0237
Epoch 6/100
5998/5998 - 4s - loss: 0.0238 - val_loss: 0.0237
Epoch 7/100

Epoch 00007: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
5998/5998 - 4s - loss: 0.0238 - val_loss: 0.0237
Epoch 8/100
5998/5998 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 9/100
5998/5998 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 10/100

Epoch 00010: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
5998/5998 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 11/100
5998/5998 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 12/100
5998/5998 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 13/100

Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
5998/5998 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 14/100
5998/5998 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 15/100
5998/5998 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 16/100

Epoch 00016: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
5998/5998 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 17/100
5998/5998 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 18/100
5998/5998 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 19/100

Epoch 00019: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.
5998/5998 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 20/100
5998/5998 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 21/100
5998/5998 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 22/100

Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.
5998/5998 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 23/100
5998/5998 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 24/100
5998/5998 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 25/100

Epoch 00025: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-09.
5998/5998 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 26/100
5998/5998 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 27/100
5998/5998 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 28/100

Epoch 00028: ReduceLROnPlateau reducing learning rate to 5.1200004236307e-10.
5998/5998 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 00028: early stopping
saving model QRmodel_run_4_vae_run_113_qnt_10_GtoWW35naReco_sigx_100_loss_rk5_05_20220318.h5 to /eos/home-k/kiwoznia/data/QR_models/vae_run_113/qr_run_4
predicting qcdSigAllTestReco
predicting GtoWW35naReco
training on 1535249 events, validating on 383813

training <class 'dadrah.selection.discriminator.QRDiscriminatorPoly_KerasAPI'> QR for quantile 0.3
Model: "functional_3"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            [(None, 1)]          0                                            
__________________________________________________________________________________________________
Std_Normalize (StdNormalization (None, 1)            0           input_2[0][0]                    
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
lambda_3 (Lambda)               (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 3)            0           lambda_2[0][0]                   
                                                                 lambda_3[0][0]                   
                                                                 Std_Normalize[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            4           concatenate_1[0][0]              
==================================================================================================
Total params: 4
Trainable params: 4
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100
5998/5998 - 4s - loss: 0.1446 - val_loss: 0.0470
Epoch 2/100
5998/5998 - 4s - loss: 0.0470 - val_loss: 0.0467
Epoch 3/100
5998/5998 - 4s - loss: 0.0470 - val_loss: 0.0470
Epoch 4/100
5998/5998 - 4s - loss: 0.0470 - val_loss: 0.0498
Epoch 5/100

Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
5998/5998 - 4s - loss: 0.0470 - val_loss: 0.0479
Epoch 6/100
5998/5998 - 4s - loss: 0.0468 - val_loss: 0.0466
Epoch 7/100
5998/5998 - 4s - loss: 0.0468 - val_loss: 0.0467
Epoch 8/100

Epoch 00008: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
5998/5998 - 4s - loss: 0.0468 - val_loss: 0.0467
Epoch 9/100
5998/5998 - 4s - loss: 0.0467 - val_loss: 0.0467
Epoch 10/100
5998/5998 - 4s - loss: 0.0467 - val_loss: 0.0467
Epoch 11/100

Epoch 00011: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
5998/5998 - 4s - loss: 0.0467 - val_loss: 0.0466
Epoch 12/100
5998/5998 - 4s - loss: 0.0467 - val_loss: 0.0466
Epoch 13/100
5998/5998 - 4s - loss: 0.0467 - val_loss: 0.0466
Epoch 14/100

Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
5998/5998 - 4s - loss: 0.0467 - val_loss: 0.0466
Epoch 15/100
5998/5998 - 4s - loss: 0.0467 - val_loss: 0.0466
Epoch 16/100
5998/5998 - 4s - loss: 0.0467 - val_loss: 0.0466
Epoch 17/100

Epoch 00017: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
5998/5998 - 4s - loss: 0.0467 - val_loss: 0.0466
Epoch 18/100
5998/5998 - 4s - loss: 0.0467 - val_loss: 0.0466
Epoch 19/100
5998/5998 - 4s - loss: 0.0467 - val_loss: 0.0466
Epoch 20/100

Epoch 00020: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.
5998/5998 - 4s - loss: 0.0467 - val_loss: 0.0466
Epoch 21/100
5998/5998 - 4s - loss: 0.0467 - val_loss: 0.0466
Epoch 22/100
5998/5998 - 4s - loss: 0.0467 - val_loss: 0.0466
Epoch 23/100

Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.
5998/5998 - 4s - loss: 0.0467 - val_loss: 0.0466
Epoch 24/100
5998/5998 - 4s - loss: 0.0467 - val_loss: 0.0466
Epoch 25/100
5998/5998 - 4s - loss: 0.0467 - val_loss: 0.0466
Epoch 26/100

Epoch 00026: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-09.
5998/5998 - 4s - loss: 0.0467 - val_loss: 0.0466
Epoch 27/100
5998/5998 - 4s - loss: 0.0467 - val_loss: 0.0466
Epoch 00027: early stopping
saving model QRmodel_run_4_vae_run_113_qnt_30_GtoWW35naReco_sigx_100_loss_rk5_05_20220318.h5 to /eos/home-k/kiwoznia/data/QR_models/vae_run_113/qr_run_4
predicting qcdSigAllTestReco
predicting GtoWW35naReco
training on 1535249 events, validating on 383813

training <class 'dadrah.selection.discriminator.QRDiscriminatorPoly_KerasAPI'> QR for quantile 0.5
Model: "functional_5"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_3 (InputLayer)            [(None, 1)]          0                                            
__________________________________________________________________________________________________
Std_Normalize (StdNormalization (None, 1)            0           input_3[0][0]                    
__________________________________________________________________________________________________
lambda_4 (Lambda)               (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
lambda_5 (Lambda)               (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 3)            0           lambda_4[0][0]                   
                                                                 lambda_5[0][0]                   
                                                                 Std_Normalize[0][0]              
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            4           concatenate_2[0][0]              
==================================================================================================
Total params: 4
Trainable params: 4
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100
5998/5998 - 4s - loss: 0.2715 - val_loss: 0.0540
Epoch 2/100
5998/5998 - 4s - loss: 0.0543 - val_loss: 0.0540
Epoch 3/100
5998/5998 - 4s - loss: 0.0543 - val_loss: 0.0540
Epoch 4/100

Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
5998/5998 - 4s - loss: 0.0543 - val_loss: 0.0540
Epoch 5/100
5998/5998 - 4s - loss: 0.0541 - val_loss: 0.0540
Epoch 6/100
5998/5998 - 4s - loss: 0.0541 - val_loss: 0.0539
Epoch 7/100

Epoch 00007: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
5998/5998 - 4s - loss: 0.0541 - val_loss: 0.0540
Epoch 8/100
5998/5998 - 4s - loss: 0.0540 - val_loss: 0.0539
Epoch 9/100
5998/5998 - 4s - loss: 0.0540 - val_loss: 0.0539
Epoch 10/100

Epoch 00010: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
5998/5998 - 4s - loss: 0.0540 - val_loss: 0.0539
Epoch 11/100
5998/5998 - 4s - loss: 0.0540 - val_loss: 0.0539
Epoch 12/100
5998/5998 - 4s - loss: 0.0540 - val_loss: 0.0539
Epoch 13/100

Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
5998/5998 - 4s - loss: 0.0540 - val_loss: 0.0539
Epoch 14/100
5998/5998 - 4s - loss: 0.0540 - val_loss: 0.0539
Epoch 15/100
5998/5998 - 4s - loss: 0.0540 - val_loss: 0.0539
Epoch 16/100

Epoch 00016: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
5998/5998 - 4s - loss: 0.0540 - val_loss: 0.0539
Epoch 17/100
5998/5998 - 4s - loss: 0.0540 - val_loss: 0.0539
Epoch 18/100
5998/5998 - 4s - loss: 0.0540 - val_loss: 0.0539
Epoch 19/100

Epoch 00019: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.
5998/5998 - 4s - loss: 0.0540 - val_loss: 0.0539
Epoch 00019: early stopping
saving model QRmodel_run_4_vae_run_113_qnt_50_GtoWW35naReco_sigx_100_loss_rk5_05_20220318.h5 to /eos/home-k/kiwoznia/data/QR_models/vae_run_113/qr_run_4
predicting qcdSigAllTestReco
predicting GtoWW35naReco
training on 1535249 events, validating on 383813

training <class 'dadrah.selection.discriminator.QRDiscriminatorPoly_KerasAPI'> QR for quantile 0.7
Model: "functional_7"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_4 (InputLayer)            [(None, 1)]          0                                            
__________________________________________________________________________________________________
Std_Normalize (StdNormalization (None, 1)            0           input_4[0][0]                    
__________________________________________________________________________________________________
lambda_6 (Lambda)               (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
lambda_7 (Lambda)               (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 3)            0           lambda_6[0][0]                   
                                                                 lambda_7[0][0]                   
                                                                 Std_Normalize[0][0]              
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 1)            4           concatenate_3[0][0]              
==================================================================================================
Total params: 4
Trainable params: 4
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100
5998/5998 - 4s - loss: 0.2682 - val_loss: 0.0480
Epoch 2/100
5998/5998 - 4s - loss: 0.0482 - val_loss: 0.0481
Epoch 3/100
5998/5998 - 4s - loss: 0.0482 - val_loss: 0.0484
Epoch 4/100
5998/5998 - 4s - loss: 0.0482 - val_loss: 0.0478
Epoch 5/100
5998/5998 - 4s - loss: 0.0482 - val_loss: 0.0479
Epoch 6/100
5998/5998 - 4s - loss: 0.0482 - val_loss: 0.0480
Epoch 7/100

Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
5998/5998 - 4s - loss: 0.0482 - val_loss: 0.0479
Epoch 8/100
5998/5998 - 4s - loss: 0.0480 - val_loss: 0.0479
Epoch 9/100
5998/5998 - 4s - loss: 0.0480 - val_loss: 0.0479
Epoch 10/100

Epoch 00010: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
5998/5998 - 4s - loss: 0.0480 - val_loss: 0.0479
Epoch 11/100
5998/5998 - 4s - loss: 0.0479 - val_loss: 0.0479
Epoch 12/100
5998/5998 - 4s - loss: 0.0479 - val_loss: 0.0478
Epoch 13/100

Epoch 00013: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
5998/5998 - 4s - loss: 0.0479 - val_loss: 0.0478
Epoch 14/100
5998/5998 - 4s - loss: 0.0479 - val_loss: 0.0478
Epoch 15/100
5998/5998 - 4s - loss: 0.0479 - val_loss: 0.0478
Epoch 16/100

Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
5998/5998 - 4s - loss: 0.0479 - val_loss: 0.0478
Epoch 17/100
5998/5998 - 4s - loss: 0.0479 - val_loss: 0.0478
Epoch 18/100
5998/5998 - 4s - loss: 0.0479 - val_loss: 0.0478
Epoch 19/100

Epoch 00019: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
5998/5998 - 4s - loss: 0.0479 - val_loss: 0.0478
Epoch 20/100
5998/5998 - 4s - loss: 0.0479 - val_loss: 0.0478
Epoch 21/100
5998/5998 - 4s - loss: 0.0479 - val_loss: 0.0478
Epoch 22/100

Epoch 00022: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.
5998/5998 - 4s - loss: 0.0479 - val_loss: 0.0478
Epoch 00022: early stopping
saving model QRmodel_run_4_vae_run_113_qnt_70_GtoWW35naReco_sigx_100_loss_rk5_05_20220318.h5 to /eos/home-k/kiwoznia/data/QR_models/vae_run_113/qr_run_4
predicting qcdSigAllTestReco
predicting GtoWW35naReco
training on 1535249 events, validating on 383813

training <class 'dadrah.selection.discriminator.QRDiscriminatorPoly_KerasAPI'> QR for quantile 0.9
Model: "functional_9"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_5 (InputLayer)            [(None, 1)]          0                                            
__________________________________________________________________________________________________
Std_Normalize (StdNormalization (None, 1)            0           input_5[0][0]                    
__________________________________________________________________________________________________
lambda_8 (Lambda)               (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
lambda_9 (Lambda)               (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 3)            0           lambda_8[0][0]                   
                                                                 lambda_9[0][0]                   
                                                                 Std_Normalize[0][0]              
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 1)            4           concatenate_4[0][0]              
==================================================================================================
Total params: 4
Trainable params: 4
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100
5998/5998 - 4s - loss: 0.2502 - val_loss: 0.0254
Epoch 2/100
5998/5998 - 4s - loss: 0.0255 - val_loss: 0.0253
Epoch 3/100
5998/5998 - 4s - loss: 0.0255 - val_loss: 0.0253
Epoch 4/100

Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
5998/5998 - 4s - loss: 0.0255 - val_loss: 0.0261
Epoch 5/100
5998/5998 - 4s - loss: 0.0254 - val_loss: 0.0253
Epoch 6/100
5998/5998 - 4s - loss: 0.0254 - val_loss: 0.0254
Epoch 7/100

Epoch 00007: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
5998/5998 - 4s - loss: 0.0254 - val_loss: 0.0253
Epoch 8/100
5998/5998 - 4s - loss: 0.0254 - val_loss: 0.0253
Epoch 9/100
5998/5998 - 4s - loss: 0.0254 - val_loss: 0.0253
Epoch 10/100

Epoch 00010: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
5998/5998 - 4s - loss: 0.0254 - val_loss: 0.0253
Epoch 11/100
5998/5998 - 4s - loss: 0.0254 - val_loss: 0.0253
Epoch 12/100
5998/5998 - 4s - loss: 0.0254 - val_loss: 0.0253
Epoch 13/100

Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
5998/5998 - 4s - loss: 0.0254 - val_loss: 0.0253
Epoch 14/100
5998/5998 - 4s - loss: 0.0254 - val_loss: 0.0253
Epoch 15/100
5998/5998 - 4s - loss: 0.0254 - val_loss: 0.0253
Epoch 16/100

Epoch 00016: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
5998/5998 - 4s - loss: 0.0254 - val_loss: 0.0253
Epoch 17/100
5998/5998 - 4s - loss: 0.0254 - val_loss: 0.0253
Epoch 18/100
5998/5998 - 4s - loss: 0.0254 - val_loss: 0.0253
Epoch 19/100

Epoch 00019: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.
5998/5998 - 4s - loss: 0.0254 - val_loss: 0.0253
Epoch 20/100
5998/5998 - 4s - loss: 0.0254 - val_loss: 0.0253
Epoch 21/100
5998/5998 - 4s - loss: 0.0254 - val_loss: 0.0253
Epoch 22/100

Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.
5998/5998 - 4s - loss: 0.0254 - val_loss: 0.0253
Epoch 23/100
5998/5998 - 4s - loss: 0.0254 - val_loss: 0.0253
Epoch 24/100
5998/5998 - 4s - loss: 0.0254 - val_loss: 0.0253
Epoch 25/100

Epoch 00025: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-09.
5998/5998 - 4s - loss: 0.0254 - val_loss: 0.0253
Epoch 26/100
5998/5998 - 4s - loss: 0.0254 - val_loss: 0.0253
Epoch 00026: early stopping
saving model QRmodel_run_4_vae_run_113_qnt_90_GtoWW35naReco_sigx_100_loss_rk5_05_20220318.h5 to /eos/home-k/kiwoznia/data/QR_models/vae_run_113/qr_run_4
predicting qcdSigAllTestReco
predicting GtoWW35naReco
training on 1535249 events, validating on 383813

training <class 'dadrah.selection.discriminator.QRDiscriminatorPoly_KerasAPI'> QR for quantile 0.99
Model: "functional_11"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_6 (InputLayer)            [(None, 1)]          0                                            
__________________________________________________________________________________________________
Std_Normalize (StdNormalization (None, 1)            0           input_6[0][0]                    
__________________________________________________________________________________________________
lambda_10 (Lambda)              (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
lambda_11 (Lambda)              (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 3)            0           lambda_10[0][0]                  
                                                                 lambda_11[0][0]                  
                                                                 Std_Normalize[0][0]              
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 1)            4           concatenate_5[0][0]              
==================================================================================================
Total params: 4
Trainable params: 4
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100
5998/5998 - 4s - loss: 0.1667 - val_loss: 0.0162
Epoch 2/100
5998/5998 - 4s - loss: 0.0128 - val_loss: 0.0093
Epoch 3/100
5998/5998 - 4s - loss: 0.0062 - val_loss: 0.0043
Epoch 4/100
5998/5998 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 5/100
5998/5998 - 4s - loss: 0.0044 - val_loss: 0.0043
Epoch 6/100

Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
5998/5998 - 4s - loss: 0.0044 - val_loss: 0.0043
Epoch 7/100
5998/5998 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 8/100
5998/5998 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 9/100

Epoch 00009: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
5998/5998 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 10/100
5998/5998 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 11/100
5998/5998 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 12/100

Epoch 00012: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
5998/5998 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 13/100
5998/5998 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 14/100
5998/5998 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 15/100

Epoch 00015: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
5998/5998 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 16/100
5998/5998 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 17/100
5998/5998 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 18/100

Epoch 00018: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
5998/5998 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 19/100
5998/5998 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 20/100
5998/5998 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 00020: early stopping
saving model QRmodel_run_4_vae_run_113_qnt_99_GtoWW35naReco_sigx_100_loss_rk5_05_20220318.h5 to /eos/home-k/kiwoznia/data/QR_models/vae_run_113/qr_run_4
predicting qcdSigAllTestReco
predicting GtoWW35naReco
writing selections to  /eos/user/k/kiwoznia/data/QR_results/events/vae_run_113/qr_run_4/sig_GtoWW35naReco/xsec_100/loss_rk5_05
written data sample to /eos/user/k/kiwoznia/data/QR_results/events/vae_run_113/qr_run_4/sig_GtoWW35naReco/xsec_100/loss_rk5_05/qcd_sqrtshatTeV_13TeV_PU40_NEW_ALL_Test_reco.h5
written data sample to /eos/user/k/kiwoznia/data/QR_results/events/vae_run_113/qr_run_4/sig_GtoWW35naReco/xsec_100/loss_rk5_05/RSGraviton_WW_NARROW_13TeV_PU40_3.5TeV_reco.h5
loaded model  <tensorflow.python.keras.engine.functional.Functional object at 0x7fbef585eba8>
loaded model  <tensorflow.python.keras.engine.functional.Functional object at 0x7fbef59142e8>
loaded model  <tensorflow.python.keras.engine.functional.Functional object at 0x7fbefa61e630>
loaded model  <tensorflow.python.keras.engine.functional.Functional object at 0x7fbef59219b0>
loaded model  <tensorflow.python.keras.engine.functional.Functional object at 0x7fbefa55ada0>
loaded model  <tensorflow.python.keras.engine.functional.Functional object at 0x7fbef5896a58>
findfont: Font family ['cursive'] not found. Falling back to DejaVu Sans.
'texgyreheros-regular.otf' can not be subsetted into a Type 3 font. The entire font will be embedded in the output.
training on 1535069 events, validating on 383768

training <class 'dadrah.selection.discriminator.QRDiscriminatorPoly_KerasAPI'> QR for quantile 0.1
Model: "functional_13"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_7 (InputLayer)            [(None, 1)]          0                                            
__________________________________________________________________________________________________
Std_Normalize (StdNormalization (None, 1)            0           input_7[0][0]                    
__________________________________________________________________________________________________
lambda_12 (Lambda)              (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
lambda_13 (Lambda)              (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 3)            0           lambda_12[0][0]                  
                                                                 lambda_13[0][0]                  
                                                                 Std_Normalize[0][0]              
__________________________________________________________________________________________________
dense_6 (Dense)                 (None, 1)            4           concatenate_6[0][0]              
==================================================================================================
Total params: 4
Trainable params: 4
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100
5997/5997 - 4s - loss: 0.0440 - val_loss: 0.0241
Epoch 2/100
5997/5997 - 4s - loss: 0.0239 - val_loss: 0.0241
Epoch 3/100
5997/5997 - 4s - loss: 0.0239 - val_loss: 0.0238
Epoch 4/100
5997/5997 - 4s - loss: 0.0239 - val_loss: 0.0238
Epoch 5/100
5997/5997 - 4s - loss: 0.0239 - val_loss: 0.0237
Epoch 6/100
5997/5997 - 4s - loss: 0.0239 - val_loss: 0.0237
Epoch 7/100
5997/5997 - 4s - loss: 0.0239 - val_loss: 0.0238
Epoch 8/100

Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
5997/5997 - 4s - loss: 0.0239 - val_loss: 0.0237
Epoch 9/100
5997/5997 - 4s - loss: 0.0237 - val_loss: 0.0238
Epoch 10/100
5997/5997 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 11/100

Epoch 00011: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
5997/5997 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 12/100
5997/5997 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 13/100
5997/5997 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 14/100

Epoch 00014: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
5997/5997 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 15/100
5997/5997 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 16/100
5997/5997 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 17/100

Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
5997/5997 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 18/100
5997/5997 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 19/100
5997/5997 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 20/100

Epoch 00020: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
5997/5997 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 21/100
5997/5997 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 22/100
5997/5997 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 23/100

Epoch 00023: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.
5997/5997 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 24/100
5997/5997 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 25/100
5997/5997 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 26/100

Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.
5997/5997 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 27/100
5997/5997 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 28/100
5997/5997 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 00028: early stopping
saving model QRmodel_run_4_vae_run_113_qnt_10_GtoWW35naReco_sigx_80_loss_rk5_05_20220318.h5 to /eos/home-k/kiwoznia/data/QR_models/vae_run_113/qr_run_4
predicting qcdSigAllTestReco
predicting GtoWW35naReco
training on 1535069 events, validating on 383768

training <class 'dadrah.selection.discriminator.QRDiscriminatorPoly_KerasAPI'> QR for quantile 0.3
Model: "functional_15"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_8 (InputLayer)            [(None, 1)]          0                                            
__________________________________________________________________________________________________
Std_Normalize (StdNormalization (None, 1)            0           input_8[0][0]                    
__________________________________________________________________________________________________
lambda_14 (Lambda)              (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
lambda_15 (Lambda)              (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 3)            0           lambda_14[0][0]                  
                                                                 lambda_15[0][0]                  
                                                                 Std_Normalize[0][0]              
__________________________________________________________________________________________________
dense_7 (Dense)                 (None, 1)            4           concatenate_7[0][0]              
==================================================================================================
Total params: 4
Trainable params: 4
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100
5997/5997 - 4s - loss: 0.2380 - val_loss: 0.0471
Epoch 2/100
5997/5997 - 4s - loss: 0.0470 - val_loss: 0.0472
Epoch 3/100
5997/5997 - 4s - loss: 0.0469 - val_loss: 0.0467
Epoch 4/100
5997/5997 - 4s - loss: 0.0470 - val_loss: 0.0474
Epoch 5/100
5997/5997 - 4s - loss: 0.0470 - val_loss: 0.0472
Epoch 6/100

Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
5997/5997 - 4s - loss: 0.0470 - val_loss: 0.0469
Epoch 7/100
5997/5997 - 4s - loss: 0.0467 - val_loss: 0.0468
Epoch 8/100
5997/5997 - 4s - loss: 0.0467 - val_loss: 0.0468
Epoch 9/100

Epoch 00009: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
5997/5997 - 4s - loss: 0.0468 - val_loss: 0.0467
Epoch 10/100
5997/5997 - 4s - loss: 0.0467 - val_loss: 0.0467
Epoch 11/100
5997/5997 - 4s - loss: 0.0467 - val_loss: 0.0467
Epoch 12/100

Epoch 00012: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
5997/5997 - 4s - loss: 0.0467 - val_loss: 0.0467
Epoch 13/100
5997/5997 - 4s - loss: 0.0467 - val_loss: 0.0467
Epoch 14/100
5997/5997 - 4s - loss: 0.0467 - val_loss: 0.0467
Epoch 15/100

Epoch 00015: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
5997/5997 - 4s - loss: 0.0467 - val_loss: 0.0467
Epoch 16/100
5997/5997 - 4s - loss: 0.0467 - val_loss: 0.0467
Epoch 17/100
5997/5997 - 4s - loss: 0.0467 - val_loss: 0.0467
Epoch 18/100

Epoch 00018: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
5997/5997 - 4s - loss: 0.0467 - val_loss: 0.0467
Epoch 19/100
5997/5997 - 4s - loss: 0.0467 - val_loss: 0.0467
Epoch 20/100
5997/5997 - 4s - loss: 0.0467 - val_loss: 0.0467
Epoch 21/100

Epoch 00021: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.
5997/5997 - 4s - loss: 0.0467 - val_loss: 0.0467
Epoch 22/100
5997/5997 - 4s - loss: 0.0467 - val_loss: 0.0467
Epoch 23/100
5997/5997 - 4s - loss: 0.0467 - val_loss: 0.0467
Epoch 24/100

Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.
5997/5997 - 4s - loss: 0.0467 - val_loss: 0.0467
Epoch 25/100
5997/5997 - 4s - loss: 0.0467 - val_loss: 0.0467
Epoch 26/100
5997/5997 - 4s - loss: 0.0467 - val_loss: 0.0467
Epoch 27/100

Epoch 00027: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-09.
5997/5997 - 4s - loss: 0.0467 - val_loss: 0.0467
Epoch 00027: early stopping
saving model QRmodel_run_4_vae_run_113_qnt_30_GtoWW35naReco_sigx_80_loss_rk5_05_20220318.h5 to /eos/home-k/kiwoznia/data/QR_models/vae_run_113/qr_run_4
predicting qcdSigAllTestReco
predicting GtoWW35naReco
training on 1535069 events, validating on 383768

training <class 'dadrah.selection.discriminator.QRDiscriminatorPoly_KerasAPI'> QR for quantile 0.5
Model: "functional_17"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_9 (InputLayer)            [(None, 1)]          0                                            
__________________________________________________________________________________________________
Std_Normalize (StdNormalization (None, 1)            0           input_9[0][0]                    
__________________________________________________________________________________________________
lambda_16 (Lambda)              (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
lambda_17 (Lambda)              (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 3)            0           lambda_16[0][0]                  
                                                                 lambda_17[0][0]                  
                                                                 Std_Normalize[0][0]              
__________________________________________________________________________________________________
dense_8 (Dense)                 (None, 1)            4           concatenate_8[0][0]              
==================================================================================================
Total params: 4
Trainable params: 4
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100
5997/5997 - 4s - loss: 0.2359 - val_loss: 0.0556
Epoch 2/100
5997/5997 - 4s - loss: 0.0543 - val_loss: 0.0543
Epoch 3/100
5997/5997 - 4s - loss: 0.0542 - val_loss: 0.0540
Epoch 4/100
5997/5997 - 4s - loss: 0.0542 - val_loss: 0.0540
Epoch 5/100
5997/5997 - 4s - loss: 0.0543 - val_loss: 0.0541
Epoch 6/100

Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
5997/5997 - 4s - loss: 0.0542 - val_loss: 0.0541
Epoch 7/100
5997/5997 - 4s - loss: 0.0540 - val_loss: 0.0540
Epoch 8/100
5997/5997 - 4s - loss: 0.0540 - val_loss: 0.0541
Epoch 9/100

Epoch 00009: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
5997/5997 - 4s - loss: 0.0540 - val_loss: 0.0540
Epoch 10/100
5997/5997 - 4s - loss: 0.0540 - val_loss: 0.0540
Epoch 11/100
5997/5997 - 4s - loss: 0.0540 - val_loss: 0.0540
Epoch 12/100

Epoch 00012: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
5997/5997 - 4s - loss: 0.0540 - val_loss: 0.0540
Epoch 13/100
5997/5997 - 4s - loss: 0.0540 - val_loss: 0.0540
Epoch 14/100
5997/5997 - 4s - loss: 0.0540 - val_loss: 0.0540
Epoch 15/100

Epoch 00015: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
5997/5997 - 4s - loss: 0.0540 - val_loss: 0.0540
Epoch 16/100
5997/5997 - 4s - loss: 0.0540 - val_loss: 0.0540
Epoch 17/100
5997/5997 - 4s - loss: 0.0540 - val_loss: 0.0540
Epoch 18/100

Epoch 00018: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
5997/5997 - 4s - loss: 0.0540 - val_loss: 0.0540
Epoch 19/100
5997/5997 - 4s - loss: 0.0540 - val_loss: 0.0540
Epoch 20/100
5997/5997 - 4s - loss: 0.0540 - val_loss: 0.0540
Epoch 21/100

Epoch 00021: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.
5997/5997 - 4s - loss: 0.0540 - val_loss: 0.0540
Epoch 22/100
5997/5997 - 4s - loss: 0.0540 - val_loss: 0.0540
Epoch 23/100
5997/5997 - 4s - loss: 0.0540 - val_loss: 0.0540
Epoch 24/100

Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.
5997/5997 - 4s - loss: 0.0540 - val_loss: 0.0540
Epoch 25/100
5997/5997 - 4s - loss: 0.0540 - val_loss: 0.0540
Epoch 26/100
5997/5997 - 4s - loss: 0.0540 - val_loss: 0.0540
Epoch 27/100

Epoch 00027: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-09.
5997/5997 - 4s - loss: 0.0540 - val_loss: 0.0540
Epoch 28/100
5997/5997 - 4s - loss: 0.0540 - val_loss: 0.0540
Epoch 29/100
5997/5997 - 4s - loss: 0.0540 - val_loss: 0.0540
Epoch 30/100

Epoch 00030: ReduceLROnPlateau reducing learning rate to 5.1200004236307e-10.
5997/5997 - 4s - loss: 0.0540 - val_loss: 0.0540
Epoch 00030: early stopping
saving model QRmodel_run_4_vae_run_113_qnt_50_GtoWW35naReco_sigx_80_loss_rk5_05_20220318.h5 to /eos/home-k/kiwoznia/data/QR_models/vae_run_113/qr_run_4
predicting qcdSigAllTestReco
predicting GtoWW35naReco
training on 1535069 events, validating on 383768

training <class 'dadrah.selection.discriminator.QRDiscriminatorPoly_KerasAPI'> QR for quantile 0.7
Model: "functional_19"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_10 (InputLayer)           [(None, 1)]          0                                            
__________________________________________________________________________________________________
Std_Normalize (StdNormalization (None, 1)            0           input_10[0][0]                   
__________________________________________________________________________________________________
lambda_18 (Lambda)              (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
lambda_19 (Lambda)              (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 3)            0           lambda_18[0][0]                  
                                                                 lambda_19[0][0]                  
                                                                 Std_Normalize[0][0]              
__________________________________________________________________________________________________
dense_9 (Dense)                 (None, 1)            4           concatenate_9[0][0]              
==================================================================================================
Total params: 4
Trainable params: 4
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100
5997/5997 - 4s - loss: 0.2101 - val_loss: 0.0481
Epoch 2/100
5997/5997 - 4s - loss: 0.0481 - val_loss: 0.0480
Epoch 3/100
5997/5997 - 4s - loss: 0.0481 - val_loss: 0.0480
Epoch 4/100
5997/5997 - 4s - loss: 0.0481 - val_loss: 0.0480
Epoch 5/100

Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
5997/5997 - 4s - loss: 0.0481 - val_loss: 0.0487
Epoch 6/100
5997/5997 - 4s - loss: 0.0479 - val_loss: 0.0480
Epoch 7/100
5997/5997 - 4s - loss: 0.0479 - val_loss: 0.0481
Epoch 8/100

Epoch 00008: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
5997/5997 - 4s - loss: 0.0479 - val_loss: 0.0480
Epoch 9/100
5997/5997 - 4s - loss: 0.0479 - val_loss: 0.0480
Epoch 10/100
5997/5997 - 4s - loss: 0.0479 - val_loss: 0.0479
Epoch 11/100

Epoch 00011: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
5997/5997 - 4s - loss: 0.0479 - val_loss: 0.0480
Epoch 12/100
5997/5997 - 4s - loss: 0.0479 - val_loss: 0.0480
Epoch 13/100
5997/5997 - 4s - loss: 0.0479 - val_loss: 0.0480
Epoch 14/100

Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
5997/5997 - 4s - loss: 0.0479 - val_loss: 0.0479
Epoch 15/100
5997/5997 - 4s - loss: 0.0479 - val_loss: 0.0479
Epoch 16/100
5997/5997 - 4s - loss: 0.0479 - val_loss: 0.0479
Epoch 17/100

Epoch 00017: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
5997/5997 - 4s - loss: 0.0479 - val_loss: 0.0479
Epoch 18/100
5997/5997 - 4s - loss: 0.0479 - val_loss: 0.0479
Epoch 19/100
5997/5997 - 4s - loss: 0.0479 - val_loss: 0.0479
Epoch 20/100

Epoch 00020: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.
5997/5997 - 4s - loss: 0.0479 - val_loss: 0.0479
Epoch 21/100
5997/5997 - 4s - loss: 0.0479 - val_loss: 0.0479
Epoch 22/100
5997/5997 - 4s - loss: 0.0479 - val_loss: 0.0479
Epoch 23/100

Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.
5997/5997 - 4s - loss: 0.0479 - val_loss: 0.0479
Epoch 24/100
5997/5997 - 4s - loss: 0.0479 - val_loss: 0.0479
Epoch 25/100
5997/5997 - 4s - loss: 0.0479 - val_loss: 0.0479
Epoch 26/100

Epoch 00026: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-09.
5997/5997 - 4s - loss: 0.0479 - val_loss: 0.0479
Epoch 27/100
5997/5997 - 4s - loss: 0.0479 - val_loss: 0.0479
Epoch 28/100
5997/5997 - 4s - loss: 0.0479 - val_loss: 0.0479
Epoch 29/100

Epoch 00029: ReduceLROnPlateau reducing learning rate to 5.1200004236307e-10.
5997/5997 - 4s - loss: 0.0479 - val_loss: 0.0479
Epoch 30/100
5997/5997 - 4s - loss: 0.0479 - val_loss: 0.0479
Epoch 31/100
5997/5997 - 4s - loss: 0.0479 - val_loss: 0.0479
Epoch 00031: early stopping
saving model QRmodel_run_4_vae_run_113_qnt_70_GtoWW35naReco_sigx_80_loss_rk5_05_20220318.h5 to /eos/home-k/kiwoznia/data/QR_models/vae_run_113/qr_run_4
predicting qcdSigAllTestReco
predicting GtoWW35naReco
training on 1535069 events, validating on 383768

training <class 'dadrah.selection.discriminator.QRDiscriminatorPoly_KerasAPI'> QR for quantile 0.9
Model: "functional_21"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_11 (InputLayer)           [(None, 1)]          0                                            
__________________________________________________________________________________________________
Std_Normalize (StdNormalization (None, 1)            0           input_11[0][0]                   
__________________________________________________________________________________________________
lambda_20 (Lambda)              (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
lambda_21 (Lambda)              (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 3)            0           lambda_20[0][0]                  
                                                                 lambda_21[0][0]                  
                                                                 Std_Normalize[0][0]              
__________________________________________________________________________________________________
dense_10 (Dense)                (None, 1)            4           concatenate_10[0][0]             
==================================================================================================
Total params: 4
Trainable params: 4
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100
5997/5997 - 4s - loss: 0.4296 - val_loss: 0.0255
Epoch 2/100
5997/5997 - 4s - loss: 0.0255 - val_loss: 0.0255
Epoch 3/100
5997/5997 - 4s - loss: 0.0255 - val_loss: 0.0254
Epoch 4/100
5997/5997 - 4s - loss: 0.0255 - val_loss: 0.0254
Epoch 5/100
5997/5997 - 4s - loss: 0.0255 - val_loss: 0.0254
Epoch 6/100

Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
5997/5997 - 4s - loss: 0.0255 - val_loss: 0.0254
Epoch 7/100
5997/5997 - 4s - loss: 0.0253 - val_loss: 0.0254
Epoch 8/100
5997/5997 - 4s - loss: 0.0253 - val_loss: 0.0254
Epoch 9/100

Epoch 00009: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
5997/5997 - 4s - loss: 0.0253 - val_loss: 0.0254
Epoch 10/100
5997/5997 - 4s - loss: 0.0253 - val_loss: 0.0254
Epoch 11/100
5997/5997 - 4s - loss: 0.0253 - val_loss: 0.0254
Epoch 12/100

Epoch 00012: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
5997/5997 - 4s - loss: 0.0253 - val_loss: 0.0254
Epoch 13/100
5997/5997 - 4s - loss: 0.0253 - val_loss: 0.0254
Epoch 14/100
5997/5997 - 4s - loss: 0.0253 - val_loss: 0.0254
Epoch 15/100

Epoch 00015: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
5997/5997 - 4s - loss: 0.0253 - val_loss: 0.0254
Epoch 16/100
5997/5997 - 4s - loss: 0.0253 - val_loss: 0.0254
Epoch 17/100
5997/5997 - 4s - loss: 0.0253 - val_loss: 0.0254
Epoch 18/100

Epoch 00018: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
5997/5997 - 4s - loss: 0.0253 - val_loss: 0.0254
Epoch 19/100
5997/5997 - 4s - loss: 0.0253 - val_loss: 0.0254
Epoch 20/100
5997/5997 - 4s - loss: 0.0253 - val_loss: 0.0254
Epoch 21/100

Epoch 00021: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.
5997/5997 - 4s - loss: 0.0253 - val_loss: 0.0254
Epoch 22/100
5997/5997 - 4s - loss: 0.0253 - val_loss: 0.0254
Epoch 23/100
5997/5997 - 4s - loss: 0.0253 - val_loss: 0.0254
Epoch 24/100

Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.
5997/5997 - 4s - loss: 0.0253 - val_loss: 0.0254
Epoch 25/100
5997/5997 - 4s - loss: 0.0253 - val_loss: 0.0254
Epoch 26/100
5997/5997 - 4s - loss: 0.0253 - val_loss: 0.0254
Epoch 27/100

Epoch 00027: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-09.
5997/5997 - 4s - loss: 0.0253 - val_loss: 0.0254
Epoch 28/100
5997/5997 - 4s - loss: 0.0253 - val_loss: 0.0254
Epoch 00028: early stopping
saving model QRmodel_run_4_vae_run_113_qnt_90_GtoWW35naReco_sigx_80_loss_rk5_05_20220318.h5 to /eos/home-k/kiwoznia/data/QR_models/vae_run_113/qr_run_4
predicting qcdSigAllTestReco
predicting GtoWW35naReco
training on 1535069 events, validating on 383768

training <class 'dadrah.selection.discriminator.QRDiscriminatorPoly_KerasAPI'> QR for quantile 0.99
Model: "functional_23"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_12 (InputLayer)           [(None, 1)]          0                                            
__________________________________________________________________________________________________
Std_Normalize (StdNormalization (None, 1)            0           input_12[0][0]                   
__________________________________________________________________________________________________
lambda_22 (Lambda)              (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
lambda_23 (Lambda)              (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
concatenate_11 (Concatenate)    (None, 3)            0           lambda_22[0][0]                  
                                                                 lambda_23[0][0]                  
                                                                 Std_Normalize[0][0]              
__________________________________________________________________________________________________
dense_11 (Dense)                (None, 1)            4           concatenate_11[0][0]             
==================================================================================================
Total params: 4
Trainable params: 4
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100
5997/5997 - 4s - loss: 0.2517 - val_loss: 0.0078
Epoch 2/100
5997/5997 - 4s - loss: 0.0055 - val_loss: 0.0045
Epoch 3/100
5997/5997 - 4s - loss: 0.0043 - val_loss: 0.0045
Epoch 4/100
5997/5997 - 4s - loss: 0.0044 - val_loss: 0.0043
Epoch 5/100
5997/5997 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 6/100
5997/5997 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 7/100

Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
5997/5997 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 8/100
5997/5997 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 9/100
5997/5997 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 10/100

Epoch 00010: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
5997/5997 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 11/100
5997/5997 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 12/100
5997/5997 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 13/100

Epoch 00013: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
5997/5997 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 14/100
5997/5997 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 15/100
5997/5997 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 16/100

Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
5997/5997 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 17/100
5997/5997 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 18/100
5997/5997 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 19/100

Epoch 00019: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
5997/5997 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 20/100
5997/5997 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 21/100
5997/5997 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 22/100

Epoch 00022: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.
5997/5997 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 23/100
5997/5997 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 24/100
5997/5997 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 25/100

Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.
5997/5997 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 26/100
5997/5997 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 27/100
5997/5997 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 28/100

Epoch 00028: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-09.
5997/5997 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 29/100
5997/5997 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 30/100
5997/5997 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 31/100

Epoch 00031: ReduceLROnPlateau reducing learning rate to 5.1200004236307e-10.
5997/5997 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 32/100
5997/5997 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 33/100
5997/5997 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 34/100

Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.0240001069306004e-10.
5997/5997 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 35/100
5997/5997 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 36/100
5997/5997 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 37/100

Epoch 00037: ReduceLROnPlateau reducing learning rate to 2.0480002416167767e-11.
5997/5997 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 38/100
5997/5997 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 39/100
5997/5997 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 40/100

Epoch 00040: ReduceLROnPlateau reducing learning rate to 4.096000622011431e-12.
5997/5997 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 41/100
5997/5997 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 42/100
5997/5997 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 43/100

Epoch 00043: ReduceLROnPlateau reducing learning rate to 8.192000897078167e-13.
5997/5997 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 00043: early stopping
saving model QRmodel_run_4_vae_run_113_qnt_99_GtoWW35naReco_sigx_80_loss_rk5_05_20220318.h5 to /eos/home-k/kiwoznia/data/QR_models/vae_run_113/qr_run_4
predicting qcdSigAllTestReco
predicting GtoWW35naReco
writing selections to  /eos/user/k/kiwoznia/data/QR_results/events/vae_run_113/qr_run_4/sig_GtoWW35naReco/xsec_80/loss_rk5_05
written data sample to /eos/user/k/kiwoznia/data/QR_results/events/vae_run_113/qr_run_4/sig_GtoWW35naReco/xsec_80/loss_rk5_05/qcd_sqrtshatTeV_13TeV_PU40_NEW_ALL_Test_reco.h5
written data sample to /eos/user/k/kiwoznia/data/QR_results/events/vae_run_113/qr_run_4/sig_GtoWW35naReco/xsec_80/loss_rk5_05/RSGraviton_WW_NARROW_13TeV_PU40_3.5TeV_reco.h5
loaded model  <tensorflow.python.keras.engine.functional.Functional object at 0x7fbef5944d68>
loaded model  <tensorflow.python.keras.engine.functional.Functional object at 0x7fbdea3e36d8>
loaded model  <tensorflow.python.keras.engine.functional.Functional object at 0x7fbdea3accc0>
loaded model  <tensorflow.python.keras.engine.functional.Functional object at 0x7fbefa5f3320>
loaded model  <tensorflow.python.keras.engine.functional.Functional object at 0x7fbefd43c4e0>
loaded model  <tensorflow.python.keras.engine.functional.Functional object at 0x7fbefa5f05f8>
'texgyreheros-regular.otf' can not be subsetted into a Type 3 font. The entire font will be embedded in the output.
training on 1534889 events, validating on 383723

training <class 'dadrah.selection.discriminator.QRDiscriminatorPoly_KerasAPI'> QR for quantile 0.1
Model: "functional_25"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_13 (InputLayer)           [(None, 1)]          0                                            
__________________________________________________________________________________________________
Std_Normalize (StdNormalization (None, 1)            0           input_13[0][0]                   
__________________________________________________________________________________________________
lambda_24 (Lambda)              (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
lambda_25 (Lambda)              (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
concatenate_12 (Concatenate)    (None, 3)            0           lambda_24[0][0]                  
                                                                 lambda_25[0][0]                  
                                                                 Std_Normalize[0][0]              
__________________________________________________________________________________________________
dense_12 (Dense)                (None, 1)            4           concatenate_12[0][0]             
==================================================================================================
Total params: 4
Trainable params: 4
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100
5996/5996 - 4s - loss: 0.2365 - val_loss: 0.0237
Epoch 2/100
5996/5996 - 4s - loss: 0.0239 - val_loss: 0.0237
Epoch 3/100
5996/5996 - 4s - loss: 0.0240 - val_loss: 0.0237
Epoch 4/100

Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
5996/5996 - 4s - loss: 0.0239 - val_loss: 0.0237
Epoch 5/100
5996/5996 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 6/100
5996/5996 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 7/100

Epoch 00007: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
5996/5996 - 4s - loss: 0.0237 - val_loss: 0.0239
Epoch 8/100
5996/5996 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 9/100
5996/5996 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 10/100

Epoch 00010: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
5996/5996 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 11/100
5996/5996 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 12/100
5996/5996 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 13/100

Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
5996/5996 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 14/100
5996/5996 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 15/100
5996/5996 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 16/100

Epoch 00016: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
5996/5996 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 17/100
5996/5996 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 18/100
5996/5996 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 19/100

Epoch 00019: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.
5996/5996 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 20/100
5996/5996 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 21/100
5996/5996 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 22/100

Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.
5996/5996 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 23/100
5996/5996 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 24/100
5996/5996 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 00024: early stopping
saving model QRmodel_run_4_vae_run_113_qnt_10_GtoWW35naReco_sigx_60_loss_rk5_05_20220318.h5 to /eos/home-k/kiwoznia/data/QR_models/vae_run_113/qr_run_4
predicting qcdSigAllTestReco
predicting GtoWW35naReco
training on 1534889 events, validating on 383723

training <class 'dadrah.selection.discriminator.QRDiscriminatorPoly_KerasAPI'> QR for quantile 0.3
Model: "functional_27"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_14 (InputLayer)           [(None, 1)]          0                                            
__________________________________________________________________________________________________
Std_Normalize (StdNormalization (None, 1)            0           input_14[0][0]                   
__________________________________________________________________________________________________
lambda_26 (Lambda)              (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
lambda_27 (Lambda)              (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
concatenate_13 (Concatenate)    (None, 3)            0           lambda_26[0][0]                  
                                                                 lambda_27[0][0]                  
                                                                 Std_Normalize[0][0]              
__________________________________________________________________________________________________
dense_13 (Dense)                (None, 1)            4           concatenate_13[0][0]             
==================================================================================================
Total params: 4
Trainable params: 4
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100
5996/5996 - 4s - loss: 0.1092 - val_loss: 0.0471
Epoch 2/100
5996/5996 - 4s - loss: 0.0470 - val_loss: 0.0467
Epoch 3/100
5996/5996 - 4s - loss: 0.0470 - val_loss: 0.0470
Epoch 4/100
5996/5996 - 4s - loss: 0.0470 - val_loss: 0.0467
Epoch 5/100

Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
5996/5996 - 4s - loss: 0.0470 - val_loss: 0.0466
Epoch 6/100
5996/5996 - 4s - loss: 0.0467 - val_loss: 0.0467
Epoch 7/100
5996/5996 - 4s - loss: 0.0467 - val_loss: 0.0466
Epoch 8/100

Epoch 00008: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
5996/5996 - 4s - loss: 0.0467 - val_loss: 0.0467
Epoch 9/100
5996/5996 - 4s - loss: 0.0467 - val_loss: 0.0466
Epoch 10/100
5996/5996 - 4s - loss: 0.0467 - val_loss: 0.0466
Epoch 11/100

Epoch 00011: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
5996/5996 - 4s - loss: 0.0467 - val_loss: 0.0466
Epoch 12/100
5996/5996 - 4s - loss: 0.0467 - val_loss: 0.0466
Epoch 13/100
5996/5996 - 4s - loss: 0.0467 - val_loss: 0.0466
Epoch 14/100

Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
5996/5996 - 4s - loss: 0.0467 - val_loss: 0.0466
Epoch 15/100
5996/5996 - 4s - loss: 0.0467 - val_loss: 0.0466
Epoch 16/100
5996/5996 - 4s - loss: 0.0467 - val_loss: 0.0466
Epoch 17/100

Epoch 00017: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
5996/5996 - 4s - loss: 0.0467 - val_loss: 0.0466
Epoch 18/100
5996/5996 - 4s - loss: 0.0467 - val_loss: 0.0466
Epoch 19/100
5996/5996 - 4s - loss: 0.0467 - val_loss: 0.0466
Epoch 20/100

Epoch 00020: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.
5996/5996 - 4s - loss: 0.0467 - val_loss: 0.0466
Epoch 21/100
5996/5996 - 4s - loss: 0.0467 - val_loss: 0.0466
Epoch 22/100
5996/5996 - 4s - loss: 0.0467 - val_loss: 0.0466
Epoch 23/100

Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.
5996/5996 - 4s - loss: 0.0467 - val_loss: 0.0466
Epoch 24/100
5996/5996 - 4s - loss: 0.0467 - val_loss: 0.0466
Epoch 25/100
5996/5996 - 4s - loss: 0.0467 - val_loss: 0.0466
Epoch 26/100

Epoch 00026: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-09.
5996/5996 - 4s - loss: 0.0467 - val_loss: 0.0466
Epoch 27/100
5996/5996 - 4s - loss: 0.0467 - val_loss: 0.0466
Epoch 28/100
5996/5996 - 4s - loss: 0.0467 - val_loss: 0.0466
Epoch 29/100

Epoch 00029: ReduceLROnPlateau reducing learning rate to 5.1200004236307e-10.
5996/5996 - 4s - loss: 0.0467 - val_loss: 0.0466
Epoch 30/100
5996/5996 - 4s - loss: 0.0467 - val_loss: 0.0466
Epoch 00030: early stopping
saving model QRmodel_run_4_vae_run_113_qnt_30_GtoWW35naReco_sigx_60_loss_rk5_05_20220318.h5 to /eos/home-k/kiwoznia/data/QR_models/vae_run_113/qr_run_4
predicting qcdSigAllTestReco
predicting GtoWW35naReco
training on 1534889 events, validating on 383723

training <class 'dadrah.selection.discriminator.QRDiscriminatorPoly_KerasAPI'> QR for quantile 0.5
Model: "functional_29"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_15 (InputLayer)           [(None, 1)]          0                                            
__________________________________________________________________________________________________
Std_Normalize (StdNormalization (None, 1)            0           input_15[0][0]                   
__________________________________________________________________________________________________
lambda_28 (Lambda)              (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
lambda_29 (Lambda)              (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
concatenate_14 (Concatenate)    (None, 3)            0           lambda_28[0][0]                  
                                                                 lambda_29[0][0]                  
                                                                 Std_Normalize[0][0]              
__________________________________________________________________________________________________
dense_14 (Dense)                (None, 1)            4           concatenate_14[0][0]             
==================================================================================================
Total params: 4
Trainable params: 4
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100
5996/5996 - 4s - loss: 0.1877 - val_loss: 0.0541
Epoch 2/100
5996/5996 - 4s - loss: 0.0542 - val_loss: 0.0539
Epoch 3/100
5996/5996 - 4s - loss: 0.0542 - val_loss: 0.0542
Epoch 4/100
5996/5996 - 4s - loss: 0.0543 - val_loss: 0.0539
Epoch 5/100

Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
5996/5996 - 4s - loss: 0.0542 - val_loss: 0.0546
Epoch 6/100
5996/5996 - 4s - loss: 0.0540 - val_loss: 0.0539
Epoch 7/100
5996/5996 - 4s - loss: 0.0540 - val_loss: 0.0539
Epoch 8/100

Epoch 00008: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
5996/5996 - 4s - loss: 0.0540 - val_loss: 0.0539
Epoch 9/100
5996/5996 - 4s - loss: 0.0540 - val_loss: 0.0539
Epoch 10/100
5996/5996 - 4s - loss: 0.0540 - val_loss: 0.0539
Epoch 11/100

Epoch 00011: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
5996/5996 - 4s - loss: 0.0540 - val_loss: 0.0539
Epoch 12/100
5996/5996 - 4s - loss: 0.0540 - val_loss: 0.0539
Epoch 13/100
5996/5996 - 4s - loss: 0.0540 - val_loss: 0.0539
Epoch 14/100

Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
5996/5996 - 5s - loss: 0.0540 - val_loss: 0.0539
Epoch 15/100
5996/5996 - 4s - loss: 0.0540 - val_loss: 0.0539
Epoch 16/100
5996/5996 - 4s - loss: 0.0540 - val_loss: 0.0539
Epoch 17/100

Epoch 00017: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
5996/5996 - 4s - loss: 0.0540 - val_loss: 0.0539
Epoch 18/100
5996/5996 - 4s - loss: 0.0540 - val_loss: 0.0539
Epoch 19/100
5996/5996 - 4s - loss: 0.0540 - val_loss: 0.0539
Epoch 20/100

Epoch 00020: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.
5996/5996 - 5s - loss: 0.0540 - val_loss: 0.0539
Epoch 21/100
5996/5996 - 5s - loss: 0.0540 - val_loss: 0.0539
Epoch 22/100
5996/5996 - 5s - loss: 0.0540 - val_loss: 0.0539
Epoch 23/100

Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.
5996/5996 - 5s - loss: 0.0540 - val_loss: 0.0539
Epoch 24/100
5996/5996 - 5s - loss: 0.0540 - val_loss: 0.0539
Epoch 25/100
5996/5996 - 5s - loss: 0.0540 - val_loss: 0.0539
Epoch 26/100

Epoch 00026: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-09.
5996/5996 - 4s - loss: 0.0540 - val_loss: 0.0539
Epoch 27/100
5996/5996 - 4s - loss: 0.0540 - val_loss: 0.0539
Epoch 28/100
5996/5996 - 4s - loss: 0.0540 - val_loss: 0.0539
Epoch 29/100

Epoch 00029: ReduceLROnPlateau reducing learning rate to 5.1200004236307e-10.
5996/5996 - 4s - loss: 0.0540 - val_loss: 0.0539
Epoch 00029: early stopping
saving model QRmodel_run_4_vae_run_113_qnt_50_GtoWW35naReco_sigx_60_loss_rk5_05_20220318.h5 to /eos/home-k/kiwoznia/data/QR_models/vae_run_113/qr_run_4
predicting qcdSigAllTestReco
predicting GtoWW35naReco
training on 1534889 events, validating on 383723

training <class 'dadrah.selection.discriminator.QRDiscriminatorPoly_KerasAPI'> QR for quantile 0.7
Model: "functional_31"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_16 (InputLayer)           [(None, 1)]          0                                            
__________________________________________________________________________________________________
Std_Normalize (StdNormalization (None, 1)            0           input_16[0][0]                   
__________________________________________________________________________________________________
lambda_30 (Lambda)              (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
lambda_31 (Lambda)              (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
concatenate_15 (Concatenate)    (None, 3)            0           lambda_30[0][0]                  
                                                                 lambda_31[0][0]                  
                                                                 Std_Normalize[0][0]              
__________________________________________________________________________________________________
dense_15 (Dense)                (None, 1)            4           concatenate_15[0][0]             
==================================================================================================
Total params: 4
Trainable params: 4
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100
5996/5996 - 4s - loss: 0.2444 - val_loss: 0.0482
Epoch 2/100
5996/5996 - 4s - loss: 0.0481 - val_loss: 0.0478
Epoch 3/100
5996/5996 - 4s - loss: 0.0482 - val_loss: 0.0478
Epoch 4/100
5996/5996 - 4s - loss: 0.0482 - val_loss: 0.0489
Epoch 5/100

Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
5996/5996 - 4s - loss: 0.0481 - val_loss: 0.0477
Epoch 6/100
5996/5996 - 4s - loss: 0.0479 - val_loss: 0.0478
Epoch 7/100
5996/5996 - 4s - loss: 0.0479 - val_loss: 0.0479
Epoch 8/100

Epoch 00008: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
5996/5996 - 4s - loss: 0.0479 - val_loss: 0.0478
Epoch 9/100
5996/5996 - 4s - loss: 0.0479 - val_loss: 0.0477
Epoch 10/100
5996/5996 - 4s - loss: 0.0479 - val_loss: 0.0477
Epoch 11/100

Epoch 00011: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
5996/5996 - 4s - loss: 0.0479 - val_loss: 0.0477
Epoch 12/100
5996/5996 - 4s - loss: 0.0479 - val_loss: 0.0477
Epoch 13/100
5996/5996 - 4s - loss: 0.0479 - val_loss: 0.0477
Epoch 14/100

Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
5996/5996 - 4s - loss: 0.0479 - val_loss: 0.0477
Epoch 15/100
5996/5996 - 4s - loss: 0.0479 - val_loss: 0.0477
Epoch 16/100
5996/5996 - 4s - loss: 0.0479 - val_loss: 0.0477
Epoch 17/100

Epoch 00017: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
5996/5996 - 4s - loss: 0.0479 - val_loss: 0.0477
Epoch 18/100
5996/5996 - 4s - loss: 0.0479 - val_loss: 0.0477
Epoch 19/100
5996/5996 - 4s - loss: 0.0479 - val_loss: 0.0477
Epoch 20/100

Epoch 00020: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.
5996/5996 - 4s - loss: 0.0479 - val_loss: 0.0477
Epoch 21/100
5996/5996 - 4s - loss: 0.0479 - val_loss: 0.0477
Epoch 22/100
5996/5996 - 4s - loss: 0.0479 - val_loss: 0.0477
Epoch 23/100

Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.
5996/5996 - 4s - loss: 0.0479 - val_loss: 0.0477
Epoch 24/100
5996/5996 - 4s - loss: 0.0479 - val_loss: 0.0477
Epoch 25/100
5996/5996 - 4s - loss: 0.0479 - val_loss: 0.0477
Epoch 26/100

Epoch 00026: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-09.
5996/5996 - 4s - loss: 0.0479 - val_loss: 0.0477
Epoch 00026: early stopping
saving model QRmodel_run_4_vae_run_113_qnt_70_GtoWW35naReco_sigx_60_loss_rk5_05_20220318.h5 to /eos/home-k/kiwoznia/data/QR_models/vae_run_113/qr_run_4
predicting qcdSigAllTestReco
predicting GtoWW35naReco
training on 1534889 events, validating on 383723

training <class 'dadrah.selection.discriminator.QRDiscriminatorPoly_KerasAPI'> QR for quantile 0.9
Model: "functional_33"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_17 (InputLayer)           [(None, 1)]          0                                            
__________________________________________________________________________________________________
Std_Normalize (StdNormalization (None, 1)            0           input_17[0][0]                   
__________________________________________________________________________________________________
lambda_32 (Lambda)              (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
lambda_33 (Lambda)              (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
concatenate_16 (Concatenate)    (None, 3)            0           lambda_32[0][0]                  
                                                                 lambda_33[0][0]                  
                                                                 Std_Normalize[0][0]              
__________________________________________________________________________________________________
dense_16 (Dense)                (None, 1)            4           concatenate_16[0][0]             
==================================================================================================
Total params: 4
Trainable params: 4
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100
5996/5996 - 4s - loss: 0.2285 - val_loss: 0.0253
Epoch 2/100
5996/5996 - 4s - loss: 0.0255 - val_loss: 0.0254
Epoch 3/100
5996/5996 - 4s - loss: 0.0255 - val_loss: 0.0252
Epoch 4/100

Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
5996/5996 - 4s - loss: 0.0255 - val_loss: 0.0253
Epoch 5/100
5996/5996 - 4s - loss: 0.0254 - val_loss: 0.0252
Epoch 6/100
5996/5996 - 4s - loss: 0.0254 - val_loss: 0.0252
Epoch 7/100

Epoch 00007: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
5996/5996 - 4s - loss: 0.0254 - val_loss: 0.0253
Epoch 8/100
5996/5996 - 4s - loss: 0.0253 - val_loss: 0.0252
Epoch 9/100
5996/5996 - 4s - loss: 0.0253 - val_loss: 0.0252
Epoch 10/100

Epoch 00010: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
5996/5996 - 4s - loss: 0.0253 - val_loss: 0.0252
Epoch 11/100
5996/5996 - 4s - loss: 0.0253 - val_loss: 0.0252
Epoch 12/100
5996/5996 - 4s - loss: 0.0253 - val_loss: 0.0252
Epoch 13/100

Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
5996/5996 - 4s - loss: 0.0253 - val_loss: 0.0252
Epoch 14/100
5996/5996 - 4s - loss: 0.0253 - val_loss: 0.0252
Epoch 15/100
5996/5996 - 4s - loss: 0.0253 - val_loss: 0.0252
Epoch 16/100

Epoch 00016: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
5996/5996 - 4s - loss: 0.0253 - val_loss: 0.0252
Epoch 17/100
5996/5996 - 4s - loss: 0.0253 - val_loss: 0.0252
Epoch 18/100
5996/5996 - 4s - loss: 0.0253 - val_loss: 0.0252
Epoch 19/100

Epoch 00019: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.
5996/5996 - 4s - loss: 0.0253 - val_loss: 0.0252
Epoch 20/100
5996/5996 - 4s - loss: 0.0253 - val_loss: 0.0252
Epoch 21/100
5996/5996 - 4s - loss: 0.0253 - val_loss: 0.0252
Epoch 22/100

Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.
5996/5996 - 4s - loss: 0.0253 - val_loss: 0.0252
Epoch 23/100
5996/5996 - 4s - loss: 0.0253 - val_loss: 0.0252
Epoch 00023: early stopping
saving model QRmodel_run_4_vae_run_113_qnt_90_GtoWW35naReco_sigx_60_loss_rk5_05_20220318.h5 to /eos/home-k/kiwoznia/data/QR_models/vae_run_113/qr_run_4
predicting qcdSigAllTestReco
predicting GtoWW35naReco
training on 1534889 events, validating on 383723

training <class 'dadrah.selection.discriminator.QRDiscriminatorPoly_KerasAPI'> QR for quantile 0.99
Model: "functional_35"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_18 (InputLayer)           [(None, 1)]          0                                            
__________________________________________________________________________________________________
Std_Normalize (StdNormalization (None, 1)            0           input_18[0][0]                   
__________________________________________________________________________________________________
lambda_34 (Lambda)              (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
lambda_35 (Lambda)              (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
concatenate_17 (Concatenate)    (None, 3)            0           lambda_34[0][0]                  
                                                                 lambda_35[0][0]                  
                                                                 Std_Normalize[0][0]              
__________________________________________________________________________________________________
dense_17 (Dense)                (None, 1)            4           concatenate_17[0][0]             
==================================================================================================
Total params: 4
Trainable params: 4
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100
5996/5996 - 4s - loss: 0.4773 - val_loss: 0.0055
Epoch 2/100
5996/5996 - 4s - loss: 0.0046 - val_loss: 0.0043
Epoch 3/100
5996/5996 - 4s - loss: 0.0044 - val_loss: 0.0043
Epoch 4/100
5996/5996 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 5/100

Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
5996/5996 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 6/100
5996/5996 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 7/100
5996/5996 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 8/100

Epoch 00008: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
5996/5996 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 9/100
5996/5996 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 10/100
5996/5996 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 11/100

Epoch 00011: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
5996/5996 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 12/100
5996/5996 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 13/100
5996/5996 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 14/100

Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
5996/5996 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 15/100
5996/5996 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 16/100
5996/5996 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 17/100

Epoch 00017: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
5996/5996 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 18/100
5996/5996 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 19/100
5996/5996 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 00019: early stopping
saving model QRmodel_run_4_vae_run_113_qnt_99_GtoWW35naReco_sigx_60_loss_rk5_05_20220318.h5 to /eos/home-k/kiwoznia/data/QR_models/vae_run_113/qr_run_4
predicting qcdSigAllTestReco
predicting GtoWW35naReco
writing selections to  /eos/user/k/kiwoznia/data/QR_results/events/vae_run_113/qr_run_4/sig_GtoWW35naReco/xsec_60/loss_rk5_05
written data sample to /eos/user/k/kiwoznia/data/QR_results/events/vae_run_113/qr_run_4/sig_GtoWW35naReco/xsec_60/loss_rk5_05/qcd_sqrtshatTeV_13TeV_PU40_NEW_ALL_Test_reco.h5
written data sample to /eos/user/k/kiwoznia/data/QR_results/events/vae_run_113/qr_run_4/sig_GtoWW35naReco/xsec_60/loss_rk5_05/RSGraviton_WW_NARROW_13TeV_PU40_3.5TeV_reco.h5
loaded model  <tensorflow.python.keras.engine.functional.Functional object at 0x7fbeec3e6668>
loaded model  <tensorflow.python.keras.engine.functional.Functional object at 0x7fbea81cf1d0>
loaded model  <tensorflow.python.keras.engine.functional.Functional object at 0x7fbefa5ab6a0>
loaded model  <tensorflow.python.keras.engine.functional.Functional object at 0x7fbea81b7048>
loaded model  <tensorflow.python.keras.engine.functional.Functional object at 0x7fbea81c80b8>
loaded model  <tensorflow.python.keras.engine.functional.Functional object at 0x7fbea804e780>
'texgyreheros-regular.otf' can not be subsetted into a Type 3 font. The entire font will be embedded in the output.
training on 1534710 events, validating on 383678

training <class 'dadrah.selection.discriminator.QRDiscriminatorPoly_KerasAPI'> QR for quantile 0.1
Model: "functional_37"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_19 (InputLayer)           [(None, 1)]          0                                            
__________________________________________________________________________________________________
Std_Normalize (StdNormalization (None, 1)            0           input_19[0][0]                   
__________________________________________________________________________________________________
lambda_36 (Lambda)              (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
lambda_37 (Lambda)              (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
concatenate_18 (Concatenate)    (None, 3)            0           lambda_36[0][0]                  
                                                                 lambda_37[0][0]                  
                                                                 Std_Normalize[0][0]              
__________________________________________________________________________________________________
dense_18 (Dense)                (None, 1)            4           concatenate_18[0][0]             
==================================================================================================
Total params: 4
Trainable params: 4
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100
5995/5995 - 4s - loss: 0.0577 - val_loss: 0.0237
Epoch 2/100
5995/5995 - 4s - loss: 0.0239 - val_loss: 0.0238
Epoch 3/100
5995/5995 - 4s - loss: 0.0239 - val_loss: 0.0240
Epoch 4/100

Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
5995/5995 - 4s - loss: 0.0239 - val_loss: 0.0248
Epoch 5/100
5995/5995 - 4s - loss: 0.0237 - val_loss: 0.0236
Epoch 6/100
5995/5995 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 7/100

Epoch 00007: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
5995/5995 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 8/100
5995/5995 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 9/100
5995/5995 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 10/100

Epoch 00010: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
5995/5995 - 4s - loss: 0.0237 - val_loss: 0.0236
Epoch 11/100
5995/5995 - 4s - loss: 0.0237 - val_loss: 0.0236
Epoch 12/100
5995/5995 - 4s - loss: 0.0237 - val_loss: 0.0236
Epoch 13/100

Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
5995/5995 - 4s - loss: 0.0237 - val_loss: 0.0236
Epoch 14/100
5995/5995 - 4s - loss: 0.0237 - val_loss: 0.0236
Epoch 15/100
5995/5995 - 4s - loss: 0.0237 - val_loss: 0.0236
Epoch 16/100

Epoch 00016: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
5995/5995 - 4s - loss: 0.0237 - val_loss: 0.0236
Epoch 17/100
5995/5995 - 4s - loss: 0.0237 - val_loss: 0.0236
Epoch 18/100
5995/5995 - 4s - loss: 0.0237 - val_loss: 0.0236
Epoch 19/100

Epoch 00019: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.
5995/5995 - 4s - loss: 0.0237 - val_loss: 0.0236
Epoch 20/100
5995/5995 - 4s - loss: 0.0237 - val_loss: 0.0236
Epoch 21/100
5995/5995 - 4s - loss: 0.0237 - val_loss: 0.0236
Epoch 22/100

Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.
5995/5995 - 4s - loss: 0.0237 - val_loss: 0.0236
Epoch 00022: early stopping
saving model QRmodel_run_4_vae_run_113_qnt_10_GtoWW35naReco_sigx_40_loss_rk5_05_20220318.h5 to /eos/home-k/kiwoznia/data/QR_models/vae_run_113/qr_run_4
predicting qcdSigAllTestReco
predicting GtoWW35naReco
training on 1534710 events, validating on 383678

training <class 'dadrah.selection.discriminator.QRDiscriminatorPoly_KerasAPI'> QR for quantile 0.3
Model: "functional_39"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_20 (InputLayer)           [(None, 1)]          0                                            
__________________________________________________________________________________________________
Std_Normalize (StdNormalization (None, 1)            0           input_20[0][0]                   
__________________________________________________________________________________________________
lambda_38 (Lambda)              (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
lambda_39 (Lambda)              (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
concatenate_19 (Concatenate)    (None, 3)            0           lambda_38[0][0]                  
                                                                 lambda_39[0][0]                  
                                                                 Std_Normalize[0][0]              
__________________________________________________________________________________________________
dense_19 (Dense)                (None, 1)            4           concatenate_19[0][0]             
==================================================================================================
Total params: 4
Trainable params: 4
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100
5995/5995 - 4s - loss: 0.3213 - val_loss: 0.0468
Epoch 2/100
5995/5995 - 4s - loss: 0.0469 - val_loss: 0.0467
Epoch 3/100
5995/5995 - 4s - loss: 0.0469 - val_loss: 0.0468
Epoch 4/100

Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
5995/5995 - 4s - loss: 0.0469 - val_loss: 0.0476
Epoch 5/100
5995/5995 - 4s - loss: 0.0467 - val_loss: 0.0466
Epoch 6/100
5995/5995 - 4s - loss: 0.0467 - val_loss: 0.0469
Epoch 7/100
5995/5995 - 4s - loss: 0.0467 - val_loss: 0.0467
Epoch 8/100

Epoch 00008: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
5995/5995 - 4s - loss: 0.0467 - val_loss: 0.0467
Epoch 9/100
5995/5995 - 4s - loss: 0.0467 - val_loss: 0.0466
Epoch 10/100
5995/5995 - 4s - loss: 0.0467 - val_loss: 0.0466
Epoch 11/100

Epoch 00011: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
5995/5995 - 4s - loss: 0.0466 - val_loss: 0.0467
Epoch 12/100
5995/5995 - 4s - loss: 0.0466 - val_loss: 0.0466
Epoch 13/100
5995/5995 - 4s - loss: 0.0466 - val_loss: 0.0467
Epoch 14/100

Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
5995/5995 - 4s - loss: 0.0466 - val_loss: 0.0466
Epoch 15/100
5995/5995 - 4s - loss: 0.0466 - val_loss: 0.0466
Epoch 16/100
5995/5995 - 4s - loss: 0.0466 - val_loss: 0.0466
Epoch 17/100

Epoch 00017: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
5995/5995 - 4s - loss: 0.0466 - val_loss: 0.0466
Epoch 18/100
5995/5995 - 4s - loss: 0.0466 - val_loss: 0.0466
Epoch 19/100
5995/5995 - 4s - loss: 0.0466 - val_loss: 0.0466
Epoch 20/100

Epoch 00020: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.
5995/5995 - 4s - loss: 0.0466 - val_loss: 0.0466
Epoch 21/100
5995/5995 - 4s - loss: 0.0466 - val_loss: 0.0466
Epoch 22/100
5995/5995 - 4s - loss: 0.0466 - val_loss: 0.0466
Epoch 00022: early stopping
saving model QRmodel_run_4_vae_run_113_qnt_30_GtoWW35naReco_sigx_40_loss_rk5_05_20220318.h5 to /eos/home-k/kiwoznia/data/QR_models/vae_run_113/qr_run_4
predicting qcdSigAllTestReco
predicting GtoWW35naReco
training on 1534710 events, validating on 383678

training <class 'dadrah.selection.discriminator.QRDiscriminatorPoly_KerasAPI'> QR for quantile 0.5
Model: "functional_41"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_21 (InputLayer)           [(None, 1)]          0                                            
__________________________________________________________________________________________________
Std_Normalize (StdNormalization (None, 1)            0           input_21[0][0]                   
__________________________________________________________________________________________________
lambda_40 (Lambda)              (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
lambda_41 (Lambda)              (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
concatenate_20 (Concatenate)    (None, 3)            0           lambda_40[0][0]                  
                                                                 lambda_41[0][0]                  
                                                                 Std_Normalize[0][0]              
__________________________________________________________________________________________________
dense_20 (Dense)                (None, 1)            4           concatenate_20[0][0]             
==================================================================================================
Total params: 4
Trainable params: 4
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100
5995/5995 - 4s - loss: 0.2977 - val_loss: 0.0540
Epoch 2/100
5995/5995 - 4s - loss: 0.0542 - val_loss: 0.0540
Epoch 3/100
5995/5995 - 4s - loss: 0.0542 - val_loss: 0.0540
Epoch 4/100

Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
5995/5995 - 4s - loss: 0.0542 - val_loss: 0.0540
Epoch 5/100
5995/5995 - 4s - loss: 0.0540 - val_loss: 0.0540
Epoch 6/100
5995/5995 - 4s - loss: 0.0540 - val_loss: 0.0539
Epoch 7/100

Epoch 00007: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
5995/5995 - 4s - loss: 0.0540 - val_loss: 0.0539
Epoch 8/100
5995/5995 - 4s - loss: 0.0539 - val_loss: 0.0539
Epoch 9/100
5995/5995 - 4s - loss: 0.0539 - val_loss: 0.0539
Epoch 10/100

Epoch 00010: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
5995/5995 - 4s - loss: 0.0539 - val_loss: 0.0539
Epoch 11/100
5995/5995 - 4s - loss: 0.0539 - val_loss: 0.0539
Epoch 12/100
5995/5995 - 4s - loss: 0.0539 - val_loss: 0.0539
Epoch 13/100

Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
5995/5995 - 4s - loss: 0.0539 - val_loss: 0.0539
Epoch 14/100
5995/5995 - 4s - loss: 0.0539 - val_loss: 0.0539
Epoch 15/100
5995/5995 - 4s - loss: 0.0539 - val_loss: 0.0539
Epoch 16/100

Epoch 00016: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
5995/5995 - 4s - loss: 0.0539 - val_loss: 0.0539
Epoch 17/100
5995/5995 - 4s - loss: 0.0539 - val_loss: 0.0539
Epoch 18/100
5995/5995 - 4s - loss: 0.0539 - val_loss: 0.0539
Epoch 19/100

Epoch 00019: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.
5995/5995 - 4s - loss: 0.0539 - val_loss: 0.0539
Epoch 20/100
5995/5995 - 4s - loss: 0.0539 - val_loss: 0.0539
Epoch 21/100
5995/5995 - 4s - loss: 0.0539 - val_loss: 0.0539
Epoch 22/100

Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.
5995/5995 - 4s - loss: 0.0539 - val_loss: 0.0539
Epoch 23/100
5995/5995 - 4s - loss: 0.0539 - val_loss: 0.0539
Epoch 24/100
5995/5995 - 4s - loss: 0.0539 - val_loss: 0.0539
Epoch 25/100

Epoch 00025: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-09.
5995/5995 - 4s - loss: 0.0539 - val_loss: 0.0539
Epoch 26/100
5995/5995 - 4s - loss: 0.0539 - val_loss: 0.0539
Epoch 00026: early stopping
saving model QRmodel_run_4_vae_run_113_qnt_50_GtoWW35naReco_sigx_40_loss_rk5_05_20220318.h5 to /eos/home-k/kiwoznia/data/QR_models/vae_run_113/qr_run_4
predicting qcdSigAllTestReco
predicting GtoWW35naReco
training on 1534710 events, validating on 383678

training <class 'dadrah.selection.discriminator.QRDiscriminatorPoly_KerasAPI'> QR for quantile 0.7
Model: "functional_43"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_22 (InputLayer)           [(None, 1)]          0                                            
__________________________________________________________________________________________________
Std_Normalize (StdNormalization (None, 1)            0           input_22[0][0]                   
__________________________________________________________________________________________________
lambda_42 (Lambda)              (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
lambda_43 (Lambda)              (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
concatenate_21 (Concatenate)    (None, 3)            0           lambda_42[0][0]                  
                                                                 lambda_43[0][0]                  
                                                                 Std_Normalize[0][0]              
__________________________________________________________________________________________________
dense_21 (Dense)                (None, 1)            4           concatenate_21[0][0]             
==================================================================================================
Total params: 4
Trainable params: 4
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100
5995/5995 - 4s - loss: 0.2596 - val_loss: 0.0479
Epoch 2/100
5995/5995 - 4s - loss: 0.0481 - val_loss: 0.0478
Epoch 3/100
5995/5995 - 4s - loss: 0.0481 - val_loss: 0.0479
Epoch 4/100

Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
5995/5995 - 4s - loss: 0.0481 - val_loss: 0.0478
Epoch 5/100
5995/5995 - 4s - loss: 0.0479 - val_loss: 0.0479
Epoch 6/100
5995/5995 - 4s - loss: 0.0479 - val_loss: 0.0478
Epoch 7/100

Epoch 00007: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
5995/5995 - 4s - loss: 0.0479 - val_loss: 0.0478
Epoch 8/100
5995/5995 - 4s - loss: 0.0478 - val_loss: 0.0478
Epoch 9/100
5995/5995 - 4s - loss: 0.0478 - val_loss: 0.0478
Epoch 10/100

Epoch 00010: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
5995/5995 - 4s - loss: 0.0478 - val_loss: 0.0478
Epoch 11/100
5995/5995 - 4s - loss: 0.0478 - val_loss: 0.0478
Epoch 12/100
5995/5995 - 4s - loss: 0.0478 - val_loss: 0.0478
Epoch 13/100

Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
5995/5995 - 4s - loss: 0.0478 - val_loss: 0.0478
Epoch 14/100
5995/5995 - 4s - loss: 0.0478 - val_loss: 0.0478
Epoch 15/100
5995/5995 - 4s - loss: 0.0478 - val_loss: 0.0478
Epoch 16/100

Epoch 00016: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
5995/5995 - 4s - loss: 0.0478 - val_loss: 0.0478
Epoch 17/100
5995/5995 - 4s - loss: 0.0478 - val_loss: 0.0478
Epoch 18/100
5995/5995 - 4s - loss: 0.0478 - val_loss: 0.0478
Epoch 00018: early stopping
saving model QRmodel_run_4_vae_run_113_qnt_70_GtoWW35naReco_sigx_40_loss_rk5_05_20220318.h5 to /eos/home-k/kiwoznia/data/QR_models/vae_run_113/qr_run_4
predicting qcdSigAllTestReco
predicting GtoWW35naReco
training on 1534710 events, validating on 383678

training <class 'dadrah.selection.discriminator.QRDiscriminatorPoly_KerasAPI'> QR for quantile 0.9
Model: "functional_45"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_23 (InputLayer)           [(None, 1)]          0                                            
__________________________________________________________________________________________________
Std_Normalize (StdNormalization (None, 1)            0           input_23[0][0]                   
__________________________________________________________________________________________________
lambda_44 (Lambda)              (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
lambda_45 (Lambda)              (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
concatenate_22 (Concatenate)    (None, 3)            0           lambda_44[0][0]                  
                                                                 lambda_45[0][0]                  
                                                                 Std_Normalize[0][0]              
__________________________________________________________________________________________________
dense_22 (Dense)                (None, 1)            4           concatenate_22[0][0]             
==================================================================================================
Total params: 4
Trainable params: 4
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100
5995/5995 - 4s - loss: 0.3504 - val_loss: 0.0253
Epoch 2/100
5995/5995 - 4s - loss: 0.0255 - val_loss: 0.0253
Epoch 3/100
5995/5995 - 4s - loss: 0.0255 - val_loss: 0.0256
Epoch 4/100

Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
5995/5995 - 4s - loss: 0.0255 - val_loss: 0.0255
Epoch 5/100
5995/5995 - 4s - loss: 0.0253 - val_loss: 0.0254
Epoch 6/100
5995/5995 - 4s - loss: 0.0253 - val_loss: 0.0253
Epoch 7/100

Epoch 00007: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
5995/5995 - 4s - loss: 0.0253 - val_loss: 0.0253
Epoch 8/100
5995/5995 - 4s - loss: 0.0253 - val_loss: 0.0253
Epoch 9/100
5995/5995 - 4s - loss: 0.0253 - val_loss: 0.0253
Epoch 10/100

Epoch 00010: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
5995/5995 - 4s - loss: 0.0253 - val_loss: 0.0253
Epoch 11/100
5995/5995 - 4s - loss: 0.0253 - val_loss: 0.0253
Epoch 12/100
5995/5995 - 4s - loss: 0.0253 - val_loss: 0.0253
Epoch 13/100

Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
5995/5995 - 4s - loss: 0.0253 - val_loss: 0.0253
Epoch 14/100
5995/5995 - 4s - loss: 0.0253 - val_loss: 0.0253
Epoch 15/100
5995/5995 - 4s - loss: 0.0253 - val_loss: 0.0253
Epoch 16/100

Epoch 00016: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
5995/5995 - 4s - loss: 0.0253 - val_loss: 0.0253
Epoch 17/100
5995/5995 - 4s - loss: 0.0253 - val_loss: 0.0253
Epoch 18/100
5995/5995 - 4s - loss: 0.0253 - val_loss: 0.0253
Epoch 19/100

Epoch 00019: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.
5995/5995 - 4s - loss: 0.0253 - val_loss: 0.0253
Epoch 20/100
5995/5995 - 4s - loss: 0.0253 - val_loss: 0.0253
Epoch 21/100
5995/5995 - 4s - loss: 0.0253 - val_loss: 0.0253
Epoch 22/100

Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.
5995/5995 - 4s - loss: 0.0253 - val_loss: 0.0253
Epoch 23/100
5995/5995 - 4s - loss: 0.0253 - val_loss: 0.0253
Epoch 00023: early stopping
saving model QRmodel_run_4_vae_run_113_qnt_90_GtoWW35naReco_sigx_40_loss_rk5_05_20220318.h5 to /eos/home-k/kiwoznia/data/QR_models/vae_run_113/qr_run_4
predicting qcdSigAllTestReco
predicting GtoWW35naReco
training on 1534710 events, validating on 383678

training <class 'dadrah.selection.discriminator.QRDiscriminatorPoly_KerasAPI'> QR for quantile 0.99
Model: "functional_47"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_24 (InputLayer)           [(None, 1)]          0                                            
__________________________________________________________________________________________________
Std_Normalize (StdNormalization (None, 1)            0           input_24[0][0]                   
__________________________________________________________________________________________________
lambda_46 (Lambda)              (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
lambda_47 (Lambda)              (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
concatenate_23 (Concatenate)    (None, 3)            0           lambda_46[0][0]                  
                                                                 lambda_47[0][0]                  
                                                                 Std_Normalize[0][0]              
__________________________________________________________________________________________________
dense_23 (Dense)                (None, 1)            4           concatenate_23[0][0]             
==================================================================================================
Total params: 4
Trainable params: 4
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100
5995/5995 - 4s - loss: 0.2850 - val_loss: 0.0086
Epoch 2/100
5995/5995 - 4s - loss: 0.0058 - val_loss: 0.0043
Epoch 3/100
5995/5995 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 4/100
5995/5995 - 4s - loss: 0.0043 - val_loss: 0.0045
Epoch 5/100

Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
5995/5995 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 6/100
5995/5995 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 7/100
5995/5995 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 8/100

Epoch 00008: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
5995/5995 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 9/100
5995/5995 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 10/100
5995/5995 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 11/100

Epoch 00011: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
5995/5995 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 12/100
5995/5995 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 13/100
5995/5995 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 14/100

Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
5995/5995 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 15/100
5995/5995 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 16/100
5995/5995 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 17/100

Epoch 00017: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
5995/5995 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 18/100
5995/5995 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 19/100
5995/5995 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 20/100

Epoch 00020: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.
5995/5995 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 00020: early stopping
saving model QRmodel_run_4_vae_run_113_qnt_99_GtoWW35naReco_sigx_40_loss_rk5_05_20220318.h5 to /eos/home-k/kiwoznia/data/QR_models/vae_run_113/qr_run_4
predicting qcdSigAllTestReco
predicting GtoWW35naReco
writing selections to  /eos/user/k/kiwoznia/data/QR_results/events/vae_run_113/qr_run_4/sig_GtoWW35naReco/xsec_40/loss_rk5_05
written data sample to /eos/user/k/kiwoznia/data/QR_results/events/vae_run_113/qr_run_4/sig_GtoWW35naReco/xsec_40/loss_rk5_05/qcd_sqrtshatTeV_13TeV_PU40_NEW_ALL_Test_reco.h5
written data sample to /eos/user/k/kiwoznia/data/QR_results/events/vae_run_113/qr_run_4/sig_GtoWW35naReco/xsec_40/loss_rk5_05/RSGraviton_WW_NARROW_13TeV_PU40_3.5TeV_reco.h5
loaded model  <tensorflow.python.keras.engine.functional.Functional object at 0x7fbeec416d30>
loaded model  <tensorflow.python.keras.engine.functional.Functional object at 0x7fbeebb10e10>
loaded model  <tensorflow.python.keras.engine.functional.Functional object at 0x7fbee78b0198>
loaded model  <tensorflow.python.keras.engine.functional.Functional object at 0x7fbefa51fb70>
loaded model  <tensorflow.python.keras.engine.functional.Functional object at 0x7fbef58ddc88>
loaded model  <tensorflow.python.keras.engine.functional.Functional object at 0x7fbefa51f390>
'texgyreheros-regular.otf' can not be subsetted into a Type 3 font. The entire font will be embedded in the output.
training on 1534530 events, validating on 383633

training <class 'dadrah.selection.discriminator.QRDiscriminatorPoly_KerasAPI'> QR for quantile 0.1
Model: "functional_49"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_25 (InputLayer)           [(None, 1)]          0                                            
__________________________________________________________________________________________________
Std_Normalize (StdNormalization (None, 1)            0           input_25[0][0]                   
__________________________________________________________________________________________________
lambda_48 (Lambda)              (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
lambda_49 (Lambda)              (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
concatenate_24 (Concatenate)    (None, 3)            0           lambda_48[0][0]                  
                                                                 lambda_49[0][0]                  
                                                                 Std_Normalize[0][0]              
__________________________________________________________________________________________________
dense_24 (Dense)                (None, 1)            4           concatenate_24[0][0]             
==================================================================================================
Total params: 4
Trainable params: 4
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100
5995/5995 - 4s - loss: 0.1259 - val_loss: 0.0238
Epoch 2/100
5995/5995 - 4s - loss: 0.0239 - val_loss: 0.0237
Epoch 3/100
5995/5995 - 4s - loss: 0.0239 - val_loss: 0.0238
Epoch 4/100
5995/5995 - 4s - loss: 0.0239 - val_loss: 0.0237
Epoch 5/100

Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
5995/5995 - 4s - loss: 0.0239 - val_loss: 0.0239
Epoch 6/100
5995/5995 - 4s - loss: 0.0237 - val_loss: 0.0238
Epoch 7/100
5995/5995 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 8/100

Epoch 00008: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
5995/5995 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 9/100
5995/5995 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 10/100
5995/5995 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 11/100

Epoch 00011: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
5995/5995 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 12/100
5995/5995 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 13/100
5995/5995 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 14/100

Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
5995/5995 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 15/100
5995/5995 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 16/100
5995/5995 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 17/100

Epoch 00017: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
5995/5995 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 18/100
5995/5995 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 19/100
5995/5995 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 20/100

Epoch 00020: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.
5995/5995 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 21/100
5995/5995 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 22/100
5995/5995 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 23/100

Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.
5995/5995 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 24/100
5995/5995 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 25/100
5995/5995 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 26/100

Epoch 00026: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-09.
5995/5995 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 27/100
5995/5995 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 00027: early stopping
saving model QRmodel_run_4_vae_run_113_qnt_10_GtoWW35naReco_sigx_20_loss_rk5_05_20220318.h5 to /eos/home-k/kiwoznia/data/QR_models/vae_run_113/qr_run_4
predicting qcdSigAllTestReco
predicting GtoWW35naReco
training on 1534530 events, validating on 383633

training <class 'dadrah.selection.discriminator.QRDiscriminatorPoly_KerasAPI'> QR for quantile 0.3
Model: "functional_51"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_26 (InputLayer)           [(None, 1)]          0                                            
__________________________________________________________________________________________________
Std_Normalize (StdNormalization (None, 1)            0           input_26[0][0]                   
__________________________________________________________________________________________________
lambda_50 (Lambda)              (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
lambda_51 (Lambda)              (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
concatenate_25 (Concatenate)    (None, 3)            0           lambda_50[0][0]                  
                                                                 lambda_51[0][0]                  
                                                                 Std_Normalize[0][0]              
__________________________________________________________________________________________________
dense_25 (Dense)                (None, 1)            4           concatenate_25[0][0]             
==================================================================================================
Total params: 4
Trainable params: 4
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100
5995/5995 - 4s - loss: 0.2280 - val_loss: 0.0467
Epoch 2/100
5995/5995 - 4s - loss: 0.0469 - val_loss: 0.0467
Epoch 3/100
5995/5995 - 4s - loss: 0.0469 - val_loss: 0.0468
Epoch 4/100

Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
5995/5995 - 4s - loss: 0.0469 - val_loss: 0.0468
Epoch 5/100
5995/5995 - 4s - loss: 0.0467 - val_loss: 0.0466
Epoch 6/100
5995/5995 - 4s - loss: 0.0467 - val_loss: 0.0466
Epoch 7/100
5995/5995 - 4s - loss: 0.0467 - val_loss: 0.0467
Epoch 8/100
5995/5995 - 4s - loss: 0.0467 - val_loss: 0.0467
Epoch 9/100

Epoch 00009: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
5995/5995 - 4s - loss: 0.0467 - val_loss: 0.0466
Epoch 10/100
5995/5995 - 4s - loss: 0.0466 - val_loss: 0.0466
Epoch 11/100
5995/5995 - 4s - loss: 0.0466 - val_loss: 0.0466
Epoch 12/100

Epoch 00012: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
5995/5995 - 4s - loss: 0.0466 - val_loss: 0.0466
Epoch 13/100
5995/5995 - 4s - loss: 0.0466 - val_loss: 0.0466
Epoch 14/100
5995/5995 - 9s - loss: 0.0466 - val_loss: 0.0466
Epoch 15/100

Epoch 00015: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
5995/5995 - 4s - loss: 0.0466 - val_loss: 0.0466
Epoch 16/100
5995/5995 - 8s - loss: 0.0466 - val_loss: 0.0466
Epoch 17/100
5995/5995 - 5s - loss: 0.0466 - val_loss: 0.0466
Epoch 18/100

Epoch 00018: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
5995/5995 - 4s - loss: 0.0466 - val_loss: 0.0466
Epoch 19/100
5995/5995 - 4s - loss: 0.0466 - val_loss: 0.0466
Epoch 20/100
5995/5995 - 10s - loss: 0.0466 - val_loss: 0.0466
Epoch 21/100

Epoch 00021: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.
5995/5995 - 10s - loss: 0.0466 - val_loss: 0.0466
Epoch 22/100
5995/5995 - 4s - loss: 0.0466 - val_loss: 0.0466
Epoch 23/100
5995/5995 - 4s - loss: 0.0466 - val_loss: 0.0466
Epoch 24/100

Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.
5995/5995 - 6s - loss: 0.0466 - val_loss: 0.0466
Epoch 25/100
5995/5995 - 9s - loss: 0.0466 - val_loss: 0.0466
Epoch 26/100
5995/5995 - 9s - loss: 0.0466 - val_loss: 0.0466
Epoch 27/100

Epoch 00027: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-09.
5995/5995 - 7s - loss: 0.0466 - val_loss: 0.0466
Epoch 28/100
5995/5995 - 4s - loss: 0.0466 - val_loss: 0.0466
Epoch 29/100
5995/5995 - 13s - loss: 0.0466 - val_loss: 0.0466
Epoch 30/100

Epoch 00030: ReduceLROnPlateau reducing learning rate to 5.1200004236307e-10.
5995/5995 - 4s - loss: 0.0466 - val_loss: 0.0466
Epoch 31/100
5995/5995 - 9s - loss: 0.0466 - val_loss: 0.0466
Epoch 32/100
5995/5995 - 4s - loss: 0.0466 - val_loss: 0.0466
Epoch 33/100

Epoch 00033: ReduceLROnPlateau reducing learning rate to 1.0240001069306004e-10.
5995/5995 - 4s - loss: 0.0466 - val_loss: 0.0466
Epoch 00033: early stopping
saving model QRmodel_run_4_vae_run_113_qnt_30_GtoWW35naReco_sigx_20_loss_rk5_05_20220318.h5 to /eos/home-k/kiwoznia/data/QR_models/vae_run_113/qr_run_4
predicting qcdSigAllTestReco
predicting GtoWW35naReco
training on 1534530 events, validating on 383633

training <class 'dadrah.selection.discriminator.QRDiscriminatorPoly_KerasAPI'> QR for quantile 0.5
Model: "functional_53"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_27 (InputLayer)           [(None, 1)]          0                                            
__________________________________________________________________________________________________
Std_Normalize (StdNormalization (None, 1)            0           input_27[0][0]                   
__________________________________________________________________________________________________
lambda_52 (Lambda)              (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
lambda_53 (Lambda)              (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
concatenate_26 (Concatenate)    (None, 3)            0           lambda_52[0][0]                  
                                                                 lambda_53[0][0]                  
                                                                 Std_Normalize[0][0]              
__________________________________________________________________________________________________
dense_26 (Dense)                (None, 1)            4           concatenate_26[0][0]             
==================================================================================================
Total params: 4
Trainable params: 4
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100
5995/5995 - 4s - loss: 0.1829 - val_loss: 0.0539
Epoch 2/100
5995/5995 - 5s - loss: 0.0542 - val_loss: 0.0539
Epoch 3/100
5995/5995 - 4s - loss: 0.0542 - val_loss: 0.0540
Epoch 4/100

Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
5995/5995 - 4s - loss: 0.0542 - val_loss: 0.0539
Epoch 5/100
5995/5995 - 4s - loss: 0.0539 - val_loss: 0.0540
Epoch 6/100
5995/5995 - 4s - loss: 0.0539 - val_loss: 0.0540
Epoch 7/100

Epoch 00007: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
5995/5995 - 8s - loss: 0.0539 - val_loss: 0.0539
Epoch 8/100
5995/5995 - 4s - loss: 0.0539 - val_loss: 0.0539
Epoch 9/100
5995/5995 - 11s - loss: 0.0539 - val_loss: 0.0539
Epoch 10/100

Epoch 00010: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
5995/5995 - 4s - loss: 0.0539 - val_loss: 0.0539
Epoch 11/100
5995/5995 - 4s - loss: 0.0539 - val_loss: 0.0539
Epoch 12/100
5995/5995 - 4s - loss: 0.0539 - val_loss: 0.0539
Epoch 13/100

Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
5995/5995 - 4s - loss: 0.0539 - val_loss: 0.0539
Epoch 14/100
5995/5995 - 4s - loss: 0.0539 - val_loss: 0.0539
Epoch 15/100
5995/5995 - 4s - loss: 0.0539 - val_loss: 0.0539
Epoch 16/100

Epoch 00016: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
5995/5995 - 4s - loss: 0.0539 - val_loss: 0.0539
Epoch 17/100
5995/5995 - 4s - loss: 0.0539 - val_loss: 0.0539
Epoch 18/100
5995/5995 - 4s - loss: 0.0539 - val_loss: 0.0539
Epoch 19/100

Epoch 00019: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.
5995/5995 - 4s - loss: 0.0539 - val_loss: 0.0539
Epoch 20/100
5995/5995 - 4s - loss: 0.0539 - val_loss: 0.0539
Epoch 21/100
5995/5995 - 6s - loss: 0.0539 - val_loss: 0.0539
Epoch 22/100

Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.
5995/5995 - 4s - loss: 0.0539 - val_loss: 0.0539
Epoch 23/100
5995/5995 - 8s - loss: 0.0539 - val_loss: 0.0539
Epoch 24/100
5995/5995 - 4s - loss: 0.0539 - val_loss: 0.0539
Epoch 25/100

Epoch 00025: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-09.
5995/5995 - 4s - loss: 0.0539 - val_loss: 0.0539
Epoch 26/100
5995/5995 - 4s - loss: 0.0539 - val_loss: 0.0539
Epoch 27/100
5995/5995 - 4s - loss: 0.0539 - val_loss: 0.0539
Epoch 28/100

Epoch 00028: ReduceLROnPlateau reducing learning rate to 5.1200004236307e-10.
5995/5995 - 4s - loss: 0.0539 - val_loss: 0.0539
Epoch 29/100
5995/5995 - 10s - loss: 0.0539 - val_loss: 0.0539
Epoch 30/100
5995/5995 - 4s - loss: 0.0539 - val_loss: 0.0539
Epoch 31/100

Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.0240001069306004e-10.
5995/5995 - 4s - loss: 0.0539 - val_loss: 0.0539
Epoch 32/100
5995/5995 - 4s - loss: 0.0539 - val_loss: 0.0539
Epoch 33/100
5995/5995 - 4s - loss: 0.0539 - val_loss: 0.0539
Epoch 34/100

Epoch 00034: ReduceLROnPlateau reducing learning rate to 2.0480002416167767e-11.
5995/5995 - 4s - loss: 0.0539 - val_loss: 0.0539
Epoch 00034: early stopping
saving model QRmodel_run_4_vae_run_113_qnt_50_GtoWW35naReco_sigx_20_loss_rk5_05_20220318.h5 to /eos/home-k/kiwoznia/data/QR_models/vae_run_113/qr_run_4
predicting qcdSigAllTestReco
predicting GtoWW35naReco
training on 1534530 events, validating on 383633

training <class 'dadrah.selection.discriminator.QRDiscriminatorPoly_KerasAPI'> QR for quantile 0.7
Model: "functional_55"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_28 (InputLayer)           [(None, 1)]          0                                            
__________________________________________________________________________________________________
Std_Normalize (StdNormalization (None, 1)            0           input_28[0][0]                   
__________________________________________________________________________________________________
lambda_54 (Lambda)              (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
lambda_55 (Lambda)              (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
concatenate_27 (Concatenate)    (None, 3)            0           lambda_54[0][0]                  
                                                                 lambda_55[0][0]                  
                                                                 Std_Normalize[0][0]              
__________________________________________________________________________________________________
dense_27 (Dense)                (None, 1)            4           concatenate_27[0][0]             
==================================================================================================
Total params: 4
Trainable params: 4
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100
5995/5995 - 10s - loss: 0.2366 - val_loss: 0.0482
Epoch 2/100
5995/5995 - 4s - loss: 0.0481 - val_loss: 0.0478
Epoch 3/100
5995/5995 - 4s - loss: 0.0480 - val_loss: 0.0481
Epoch 4/100
5995/5995 - 4s - loss: 0.0481 - val_loss: 0.0482
Epoch 5/100

Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
5995/5995 - 4s - loss: 0.0481 - val_loss: 0.0482
Epoch 6/100
5995/5995 - 9s - loss: 0.0479 - val_loss: 0.0478
Epoch 7/100
5995/5995 - 10s - loss: 0.0479 - val_loss: 0.0478
Epoch 8/100

Epoch 00008: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
5995/5995 - 4s - loss: 0.0479 - val_loss: 0.0479
Epoch 9/100
5995/5995 - 9s - loss: 0.0478 - val_loss: 0.0478
Epoch 10/100
5995/5995 - 10s - loss: 0.0478 - val_loss: 0.0478
Epoch 11/100

Epoch 00011: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
5995/5995 - 4s - loss: 0.0478 - val_loss: 0.0478
Epoch 12/100
5995/5995 - 4s - loss: 0.0478 - val_loss: 0.0478
Epoch 13/100
5995/5995 - 9s - loss: 0.0478 - val_loss: 0.0478
Epoch 14/100

Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
5995/5995 - 9s - loss: 0.0478 - val_loss: 0.0478
Epoch 15/100
5995/5995 - 4s - loss: 0.0478 - val_loss: 0.0478
Epoch 16/100
5995/5995 - 4s - loss: 0.0478 - val_loss: 0.0478
Epoch 17/100

Epoch 00017: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
5995/5995 - 4s - loss: 0.0478 - val_loss: 0.0478
Epoch 18/100
5995/5995 - 4s - loss: 0.0478 - val_loss: 0.0478
Epoch 19/100
5995/5995 - 4s - loss: 0.0478 - val_loss: 0.0478
Epoch 20/100

Epoch 00020: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.
5995/5995 - 4s - loss: 0.0478 - val_loss: 0.0478
Epoch 21/100
5995/5995 - 4s - loss: 0.0478 - val_loss: 0.0478
Epoch 22/100
5995/5995 - 4s - loss: 0.0478 - val_loss: 0.0478
Epoch 23/100

Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.
5995/5995 - 4s - loss: 0.0478 - val_loss: 0.0478
Epoch 24/100
5995/5995 - 4s - loss: 0.0478 - val_loss: 0.0478
Epoch 25/100
5995/5995 - 6s - loss: 0.0478 - val_loss: 0.0478
Epoch 00025: early stopping
saving model QRmodel_run_4_vae_run_113_qnt_70_GtoWW35naReco_sigx_20_loss_rk5_05_20220318.h5 to /eos/home-k/kiwoznia/data/QR_models/vae_run_113/qr_run_4
predicting qcdSigAllTestReco
predicting GtoWW35naReco
training on 1534530 events, validating on 383633

training <class 'dadrah.selection.discriminator.QRDiscriminatorPoly_KerasAPI'> QR for quantile 0.9
Model: "functional_57"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_29 (InputLayer)           [(None, 1)]          0                                            
__________________________________________________________________________________________________
Std_Normalize (StdNormalization (None, 1)            0           input_29[0][0]                   
__________________________________________________________________________________________________
lambda_56 (Lambda)              (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
lambda_57 (Lambda)              (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
concatenate_28 (Concatenate)    (None, 3)            0           lambda_56[0][0]                  
                                                                 lambda_57[0][0]                  
                                                                 Std_Normalize[0][0]              
__________________________________________________________________________________________________
dense_28 (Dense)                (None, 1)            4           concatenate_28[0][0]             
==================================================================================================
Total params: 4
Trainable params: 4
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100
5995/5995 - 9s - loss: 0.4894 - val_loss: 0.0254
Epoch 2/100
5995/5995 - 4s - loss: 0.0255 - val_loss: 0.0253
Epoch 3/100
5995/5995 - 4s - loss: 0.0255 - val_loss: 0.0255
Epoch 4/100

Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
5995/5995 - 4s - loss: 0.0254 - val_loss: 0.0260
Epoch 5/100
5995/5995 - 4s - loss: 0.0253 - val_loss: 0.0253
Epoch 6/100
5995/5995 - 4s - loss: 0.0253 - val_loss: 0.0253
Epoch 7/100

Epoch 00007: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
5995/5995 - 4s - loss: 0.0253 - val_loss: 0.0253
Epoch 8/100
5995/5995 - 10s - loss: 0.0253 - val_loss: 0.0253
Epoch 9/100
5995/5995 - 4s - loss: 0.0253 - val_loss: 0.0253
Epoch 10/100

Epoch 00010: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
5995/5995 - 4s - loss: 0.0253 - val_loss: 0.0253
Epoch 11/100
5995/5995 - 5s - loss: 0.0253 - val_loss: 0.0253
Epoch 12/100
5995/5995 - 4s - loss: 0.0253 - val_loss: 0.0253
Epoch 13/100

Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
5995/5995 - 5s - loss: 0.0253 - val_loss: 0.0253
Epoch 14/100
5995/5995 - 7s - loss: 0.0253 - val_loss: 0.0253
Epoch 15/100
5995/5995 - 4s - loss: 0.0253 - val_loss: 0.0253
Epoch 16/100

Epoch 00016: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
5995/5995 - 5s - loss: 0.0253 - val_loss: 0.0253
Epoch 17/100
5995/5995 - 4s - loss: 0.0253 - val_loss: 0.0253
Epoch 18/100
5995/5995 - 4s - loss: 0.0253 - val_loss: 0.0253
Epoch 19/100

Epoch 00019: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.
5995/5995 - 4s - loss: 0.0253 - val_loss: 0.0253
Epoch 20/100
5995/5995 - 4s - loss: 0.0253 - val_loss: 0.0253
Epoch 21/100
5995/5995 - 4s - loss: 0.0253 - val_loss: 0.0253
Epoch 22/100

Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.
5995/5995 - 4s - loss: 0.0253 - val_loss: 0.0253
Epoch 23/100
5995/5995 - 4s - loss: 0.0253 - val_loss: 0.0253
Epoch 24/100
5995/5995 - 6s - loss: 0.0253 - val_loss: 0.0253
Epoch 00024: early stopping
saving model QRmodel_run_4_vae_run_113_qnt_90_GtoWW35naReco_sigx_20_loss_rk5_05_20220318.h5 to /eos/home-k/kiwoznia/data/QR_models/vae_run_113/qr_run_4
predicting qcdSigAllTestReco
predicting GtoWW35naReco
training on 1534530 events, validating on 383633

training <class 'dadrah.selection.discriminator.QRDiscriminatorPoly_KerasAPI'> QR for quantile 0.99
Model: "functional_59"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_30 (InputLayer)           [(None, 1)]          0                                            
__________________________________________________________________________________________________
Std_Normalize (StdNormalization (None, 1)            0           input_30[0][0]                   
__________________________________________________________________________________________________
lambda_58 (Lambda)              (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
lambda_59 (Lambda)              (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
concatenate_29 (Concatenate)    (None, 3)            0           lambda_58[0][0]                  
                                                                 lambda_59[0][0]                  
                                                                 Std_Normalize[0][0]              
__________________________________________________________________________________________________
dense_29 (Dense)                (None, 1)            4           concatenate_29[0][0]             
==================================================================================================
Total params: 4
Trainable params: 4
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100
5995/5995 - 10s - loss: 0.2292 - val_loss: 0.0126
Epoch 2/100
5995/5995 - 4s - loss: 0.0091 - val_loss: 0.0055
Epoch 3/100
5995/5995 - 4s - loss: 0.0045 - val_loss: 0.0044
Epoch 4/100
5995/5995 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 5/100
5995/5995 - 11s - loss: 0.0043 - val_loss: 0.0043
Epoch 6/100
5995/5995 - 4s - loss: 0.0043 - val_loss: 0.0044
Epoch 7/100

Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
5995/5995 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 8/100
5995/5995 - 8s - loss: 0.0043 - val_loss: 0.0043
Epoch 9/100
5995/5995 - 5s - loss: 0.0043 - val_loss: 0.0043
Epoch 10/100

Epoch 00010: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
5995/5995 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 11/100
5995/5995 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 12/100
5995/5995 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 13/100

Epoch 00013: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
5995/5995 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 14/100
5995/5995 - 10s - loss: 0.0043 - val_loss: 0.0043
Epoch 15/100
5995/5995 - 8s - loss: 0.0043 - val_loss: 0.0043
Epoch 16/100

Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
5995/5995 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 17/100
5995/5995 - 6s - loss: 0.0043 - val_loss: 0.0043
Epoch 18/100
5995/5995 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 19/100

Epoch 00019: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
5995/5995 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 20/100
5995/5995 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 21/100
5995/5995 - 9s - loss: 0.0043 - val_loss: 0.0043
Epoch 22/100

Epoch 00022: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.
5995/5995 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 23/100
5995/5995 - 11s - loss: 0.0043 - val_loss: 0.0043
Epoch 24/100
5995/5995 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 00024: early stopping
saving model QRmodel_run_4_vae_run_113_qnt_99_GtoWW35naReco_sigx_20_loss_rk5_05_20220318.h5 to /eos/home-k/kiwoznia/data/QR_models/vae_run_113/qr_run_4
predicting qcdSigAllTestReco
predicting GtoWW35naReco
writing selections to  /eos/user/k/kiwoznia/data/QR_results/events/vae_run_113/qr_run_4/sig_GtoWW35naReco/xsec_20/loss_rk5_05
written data sample to /eos/user/k/kiwoznia/data/QR_results/events/vae_run_113/qr_run_4/sig_GtoWW35naReco/xsec_20/loss_rk5_05/qcd_sqrtshatTeV_13TeV_PU40_NEW_ALL_Test_reco.h5
written data sample to /eos/user/k/kiwoznia/data/QR_results/events/vae_run_113/qr_run_4/sig_GtoWW35naReco/xsec_20/loss_rk5_05/RSGraviton_WW_NARROW_13TeV_PU40_3.5TeV_reco.h5
loaded model  <tensorflow.python.keras.engine.functional.Functional object at 0x7fbeec38d080>
loaded model  <tensorflow.python.keras.engine.functional.Functional object at 0x7fbeebb09fd0>
loaded model  <tensorflow.python.keras.engine.functional.Functional object at 0x7fbddaee66a0>
loaded model  <tensorflow.python.keras.engine.functional.Functional object at 0x7fbee7933f98>
loaded model  <tensorflow.python.keras.engine.functional.Functional object at 0x7fbeec3c9da0>
loaded model  <tensorflow.python.keras.engine.functional.Functional object at 0x7fbe44123048>
'texgyreheros-regular.otf' can not be subsetted into a Type 3 font. The entire font will be embedded in the output.
training on 1534351 events, validating on 383588

training <class 'dadrah.selection.discriminator.QRDiscriminatorPoly_KerasAPI'> QR for quantile 0.1
Model: "functional_61"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_31 (InputLayer)           [(None, 1)]          0                                            
__________________________________________________________________________________________________
Std_Normalize (StdNormalization (None, 1)            0           input_31[0][0]                   
__________________________________________________________________________________________________
lambda_60 (Lambda)              (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
lambda_61 (Lambda)              (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
concatenate_30 (Concatenate)    (None, 3)            0           lambda_60[0][0]                  
                                                                 lambda_61[0][0]                  
                                                                 Std_Normalize[0][0]              
__________________________________________________________________________________________________
dense_30 (Dense)                (None, 1)            4           concatenate_30[0][0]             
==================================================================================================
Total params: 4
Trainable params: 4
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100
5994/5994 - 4s - loss: 0.0520 - val_loss: 0.0239
Epoch 2/100
5994/5994 - 4s - loss: 0.0239 - val_loss: 0.0246
Epoch 3/100
5994/5994 - 4s - loss: 0.0239 - val_loss: 0.0237
Epoch 4/100
5994/5994 - 4s - loss: 0.0238 - val_loss: 0.0240
Epoch 5/100
5994/5994 - 4s - loss: 0.0239 - val_loss: 0.0237
Epoch 6/100

Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
5994/5994 - 4s - loss: 0.0239 - val_loss: 0.0238
Epoch 7/100
5994/5994 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 8/100
5994/5994 - 7s - loss: 0.0237 - val_loss: 0.0237
Epoch 9/100

Epoch 00009: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
5994/5994 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 10/100
5994/5994 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 11/100
5994/5994 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 12/100

Epoch 00012: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
5994/5994 - 4s - loss: 0.0237 - val_loss: 0.0237
Epoch 13/100
5994/5994 - 9s - loss: 0.0236 - val_loss: 0.0237
Epoch 14/100
5994/5994 - 4s - loss: 0.0236 - val_loss: 0.0237
Epoch 15/100

Epoch 00015: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
5994/5994 - 4s - loss: 0.0236 - val_loss: 0.0237
Epoch 16/100
5994/5994 - 4s - loss: 0.0236 - val_loss: 0.0237
Epoch 17/100
5994/5994 - 4s - loss: 0.0236 - val_loss: 0.0237
Epoch 18/100

Epoch 00018: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
5994/5994 - 11s - loss: 0.0236 - val_loss: 0.0237
Epoch 19/100
5994/5994 - 4s - loss: 0.0236 - val_loss: 0.0237
Epoch 20/100
5994/5994 - 4s - loss: 0.0236 - val_loss: 0.0237
Epoch 21/100

Epoch 00021: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.
5994/5994 - 9s - loss: 0.0236 - val_loss: 0.0237
Epoch 22/100
5994/5994 - 9s - loss: 0.0236 - val_loss: 0.0237
Epoch 23/100
5994/5994 - 5s - loss: 0.0236 - val_loss: 0.0237
Epoch 24/100

Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.
5994/5994 - 4s - loss: 0.0236 - val_loss: 0.0237
Epoch 25/100
5994/5994 - 5s - loss: 0.0236 - val_loss: 0.0237
Epoch 26/100
5994/5994 - 4s - loss: 0.0236 - val_loss: 0.0237
Epoch 27/100

Epoch 00027: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-09.
5994/5994 - 4s - loss: 0.0236 - val_loss: 0.0237
Epoch 28/100
5994/5994 - 4s - loss: 0.0236 - val_loss: 0.0237
Epoch 00028: early stopping
saving model QRmodel_run_4_vae_run_113_qnt_10_GtoWW35naReco_sigx_0_loss_rk5_05_20220318.h5 to /eos/home-k/kiwoznia/data/QR_models/vae_run_113/qr_run_4
predicting qcdSigAllTestReco
predicting GtoWW35naReco
training on 1534351 events, validating on 383588

training <class 'dadrah.selection.discriminator.QRDiscriminatorPoly_KerasAPI'> QR for quantile 0.3
Model: "functional_63"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_32 (InputLayer)           [(None, 1)]          0                                            
__________________________________________________________________________________________________
Std_Normalize (StdNormalization (None, 1)            0           input_32[0][0]                   
__________________________________________________________________________________________________
lambda_62 (Lambda)              (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
lambda_63 (Lambda)              (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
concatenate_31 (Concatenate)    (None, 3)            0           lambda_62[0][0]                  
                                                                 lambda_63[0][0]                  
                                                                 Std_Normalize[0][0]              
__________________________________________________________________________________________________
dense_31 (Dense)                (None, 1)            4           concatenate_31[0][0]             
==================================================================================================
Total params: 4
Trainable params: 4
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100
5994/5994 - 6s - loss: 0.1499 - val_loss: 0.0469
Epoch 2/100
5994/5994 - 4s - loss: 0.0469 - val_loss: 0.0467
Epoch 3/100
5994/5994 - 4s - loss: 0.0469 - val_loss: 0.0475
Epoch 4/100
5994/5994 - 4s - loss: 0.0469 - val_loss: 0.0466
Epoch 5/100
5994/5994 - 4s - loss: 0.0469 - val_loss: 0.0472
Epoch 6/100
5994/5994 - 9s - loss: 0.0469 - val_loss: 0.0467
Epoch 7/100

Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
5994/5994 - 4s - loss: 0.0469 - val_loss: 0.0470
Epoch 8/100
5994/5994 - 4s - loss: 0.0467 - val_loss: 0.0466
Epoch 9/100
5994/5994 - 7s - loss: 0.0466 - val_loss: 0.0466
Epoch 10/100

Epoch 00010: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
5994/5994 - 4s - loss: 0.0467 - val_loss: 0.0466
Epoch 11/100
5994/5994 - 4s - loss: 0.0466 - val_loss: 0.0466
Epoch 12/100
5994/5994 - 4s - loss: 0.0466 - val_loss: 0.0466
Epoch 13/100

Epoch 00013: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
5994/5994 - 4s - loss: 0.0466 - val_loss: 0.0466
Epoch 14/100
5994/5994 - 4s - loss: 0.0466 - val_loss: 0.0466
Epoch 15/100
5994/5994 - 4s - loss: 0.0466 - val_loss: 0.0466
Epoch 16/100

Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
5994/5994 - 4s - loss: 0.0466 - val_loss: 0.0466
Epoch 17/100
5994/5994 - 4s - loss: 0.0466 - val_loss: 0.0466
Epoch 18/100
5994/5994 - 4s - loss: 0.0466 - val_loss: 0.0466
Epoch 19/100

Epoch 00019: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
5994/5994 - 4s - loss: 0.0466 - val_loss: 0.0466
Epoch 20/100
5994/5994 - 4s - loss: 0.0466 - val_loss: 0.0466
Epoch 21/100
5994/5994 - 9s - loss: 0.0466 - val_loss: 0.0466
Epoch 22/100

Epoch 00022: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.
5994/5994 - 6s - loss: 0.0466 - val_loss: 0.0466
Epoch 23/100
5994/5994 - 8s - loss: 0.0466 - val_loss: 0.0466
Epoch 24/100
5994/5994 - 4s - loss: 0.0466 - val_loss: 0.0466
Epoch 25/100

Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.
5994/5994 - 4s - loss: 0.0466 - val_loss: 0.0466
Epoch 00025: early stopping
saving model QRmodel_run_4_vae_run_113_qnt_30_GtoWW35naReco_sigx_0_loss_rk5_05_20220318.h5 to /eos/home-k/kiwoznia/data/QR_models/vae_run_113/qr_run_4
predicting qcdSigAllTestReco
predicting GtoWW35naReco
training on 1534351 events, validating on 383588

training <class 'dadrah.selection.discriminator.QRDiscriminatorPoly_KerasAPI'> QR for quantile 0.5
Model: "functional_65"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_33 (InputLayer)           [(None, 1)]          0                                            
__________________________________________________________________________________________________
Std_Normalize (StdNormalization (None, 1)            0           input_33[0][0]                   
__________________________________________________________________________________________________
lambda_64 (Lambda)              (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
lambda_65 (Lambda)              (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
concatenate_32 (Concatenate)    (None, 3)            0           lambda_64[0][0]                  
                                                                 lambda_65[0][0]                  
                                                                 Std_Normalize[0][0]              
__________________________________________________________________________________________________
dense_32 (Dense)                (None, 1)            4           concatenate_32[0][0]             
==================================================================================================
Total params: 4
Trainable params: 4
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100
5994/5994 - 11s - loss: 0.2345 - val_loss: 0.0545
Epoch 2/100
5994/5994 - 4s - loss: 0.0541 - val_loss: 0.0539
Epoch 3/100
5994/5994 - 8s - loss: 0.0541 - val_loss: 0.0539
Epoch 4/100
5994/5994 - 4s - loss: 0.0541 - val_loss: 0.0539
Epoch 5/100

Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
5994/5994 - 4s - loss: 0.0541 - val_loss: 0.0539
Epoch 6/100
5994/5994 - 10s - loss: 0.0539 - val_loss: 0.0539
Epoch 7/100
5994/5994 - 4s - loss: 0.0539 - val_loss: 0.0539
Epoch 8/100

Epoch 00008: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
5994/5994 - 4s - loss: 0.0539 - val_loss: 0.0539
Epoch 9/100
5994/5994 - 6s - loss: 0.0539 - val_loss: 0.0539
Epoch 10/100
5994/5994 - 4s - loss: 0.0539 - val_loss: 0.0539
Epoch 11/100

Epoch 00011: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
5994/5994 - 4s - loss: 0.0539 - val_loss: 0.0539
Epoch 12/100
5994/5994 - 11s - loss: 0.0538 - val_loss: 0.0539
Epoch 13/100
5994/5994 - 4s - loss: 0.0539 - val_loss: 0.0539
Epoch 14/100

Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
5994/5994 - 4s - loss: 0.0539 - val_loss: 0.0539
Epoch 15/100
5994/5994 - 6s - loss: 0.0538 - val_loss: 0.0539
Epoch 16/100
5994/5994 - 4s - loss: 0.0538 - val_loss: 0.0539
Epoch 17/100

Epoch 00017: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
5994/5994 - 11s - loss: 0.0538 - val_loss: 0.0539
Epoch 18/100
5994/5994 - 4s - loss: 0.0538 - val_loss: 0.0539
Epoch 19/100
5994/5994 - 4s - loss: 0.0538 - val_loss: 0.0539
Epoch 20/100

Epoch 00020: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.
5994/5994 - 8s - loss: 0.0538 - val_loss: 0.0539
Epoch 21/100
5994/5994 - 4s - loss: 0.0538 - val_loss: 0.0539
Epoch 22/100
5994/5994 - 4s - loss: 0.0538 - val_loss: 0.0539
Epoch 23/100

Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.
5994/5994 - 8s - loss: 0.0538 - val_loss: 0.0539
Epoch 00023: early stopping
saving model QRmodel_run_4_vae_run_113_qnt_50_GtoWW35naReco_sigx_0_loss_rk5_05_20220318.h5 to /eos/home-k/kiwoznia/data/QR_models/vae_run_113/qr_run_4
predicting qcdSigAllTestReco
predicting GtoWW35naReco
training on 1534351 events, validating on 383588

training <class 'dadrah.selection.discriminator.QRDiscriminatorPoly_KerasAPI'> QR for quantile 0.7
Model: "functional_67"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_34 (InputLayer)           [(None, 1)]          0                                            
__________________________________________________________________________________________________
Std_Normalize (StdNormalization (None, 1)            0           input_34[0][0]                   
__________________________________________________________________________________________________
lambda_66 (Lambda)              (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
lambda_67 (Lambda)              (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
concatenate_33 (Concatenate)    (None, 3)            0           lambda_66[0][0]                  
                                                                 lambda_67[0][0]                  
                                                                 Std_Normalize[0][0]              
__________________________________________________________________________________________________
dense_33 (Dense)                (None, 1)            4           concatenate_33[0][0]             
==================================================================================================
Total params: 4
Trainable params: 4
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100
5994/5994 - 12s - loss: 0.3454 - val_loss: 0.0478
Epoch 2/100
5994/5994 - 4s - loss: 0.0480 - val_loss: 0.0480
Epoch 3/100
5994/5994 - 4s - loss: 0.0480 - val_loss: 0.0478
Epoch 4/100

Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
5994/5994 - 4s - loss: 0.0480 - val_loss: 0.0481
Epoch 5/100
5994/5994 - 4s - loss: 0.0478 - val_loss: 0.0478
Epoch 6/100
5994/5994 - 4s - loss: 0.0478 - val_loss: 0.0478
Epoch 7/100

Epoch 00007: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
5994/5994 - 4s - loss: 0.0478 - val_loss: 0.0478
Epoch 8/100
5994/5994 - 5s - loss: 0.0478 - val_loss: 0.0478
Epoch 9/100
5994/5994 - 4s - loss: 0.0478 - val_loss: 0.0478
Epoch 10/100

Epoch 00010: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
5994/5994 - 10s - loss: 0.0478 - val_loss: 0.0478
Epoch 11/100
5994/5994 - 6s - loss: 0.0478 - val_loss: 0.0478
Epoch 12/100
5994/5994 - 4s - loss: 0.0478 - val_loss: 0.0478
Epoch 13/100

Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
5994/5994 - 4s - loss: 0.0478 - val_loss: 0.0478
Epoch 14/100
5994/5994 - 11s - loss: 0.0478 - val_loss: 0.0478
Epoch 15/100
5994/5994 - 4s - loss: 0.0478 - val_loss: 0.0478
Epoch 16/100

Epoch 00016: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
5994/5994 - 4s - loss: 0.0478 - val_loss: 0.0478
Epoch 17/100
5994/5994 - 4s - loss: 0.0478 - val_loss: 0.0478
Epoch 18/100
5994/5994 - 6s - loss: 0.0478 - val_loss: 0.0478
Epoch 19/100

Epoch 00019: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.
5994/5994 - 4s - loss: 0.0478 - val_loss: 0.0478
Epoch 20/100
5994/5994 - 4s - loss: 0.0478 - val_loss: 0.0478
Epoch 21/100
5994/5994 - 11s - loss: 0.0478 - val_loss: 0.0478
Epoch 22/100

Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.
5994/5994 - 4s - loss: 0.0478 - val_loss: 0.0478
Epoch 23/100
5994/5994 - 4s - loss: 0.0478 - val_loss: 0.0478
Epoch 24/100
5994/5994 - 4s - loss: 0.0478 - val_loss: 0.0478
Epoch 00024: early stopping
saving model QRmodel_run_4_vae_run_113_qnt_70_GtoWW35naReco_sigx_0_loss_rk5_05_20220318.h5 to /eos/home-k/kiwoznia/data/QR_models/vae_run_113/qr_run_4
predicting qcdSigAllTestReco
predicting GtoWW35naReco
training on 1534351 events, validating on 383588

training <class 'dadrah.selection.discriminator.QRDiscriminatorPoly_KerasAPI'> QR for quantile 0.9
Model: "functional_69"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_35 (InputLayer)           [(None, 1)]          0                                            
__________________________________________________________________________________________________
Std_Normalize (StdNormalization (None, 1)            0           input_35[0][0]                   
__________________________________________________________________________________________________
lambda_68 (Lambda)              (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
lambda_69 (Lambda)              (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
concatenate_34 (Concatenate)    (None, 3)            0           lambda_68[0][0]                  
                                                                 lambda_69[0][0]                  
                                                                 Std_Normalize[0][0]              
__________________________________________________________________________________________________
dense_34 (Dense)                (None, 1)            4           concatenate_34[0][0]             
==================================================================================================
Total params: 4
Trainable params: 4
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100
5994/5994 - 4s - loss: 0.3232 - val_loss: 0.0254
Epoch 2/100
5994/5994 - 4s - loss: 0.0255 - val_loss: 0.0253
Epoch 3/100
5994/5994 - 4s - loss: 0.0254 - val_loss: 0.0253
Epoch 4/100

Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
5994/5994 - 4s - loss: 0.0255 - val_loss: 0.0256
Epoch 5/100
5994/5994 - 4s - loss: 0.0253 - val_loss: 0.0253
Epoch 6/100
5994/5994 - 4s - loss: 0.0253 - val_loss: 0.0253
Epoch 7/100

Epoch 00007: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
5994/5994 - 5s - loss: 0.0253 - val_loss: 0.0253
Epoch 8/100
5994/5994 - 8s - loss: 0.0253 - val_loss: 0.0253
Epoch 9/100
5994/5994 - 4s - loss: 0.0253 - val_loss: 0.0253
Epoch 10/100

Epoch 00010: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
5994/5994 - 9s - loss: 0.0253 - val_loss: 0.0253
Epoch 11/100
5994/5994 - 11s - loss: 0.0253 - val_loss: 0.0253
Epoch 12/100
5994/5994 - 6s - loss: 0.0253 - val_loss: 0.0253
Epoch 13/100

Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
5994/5994 - 4s - loss: 0.0253 - val_loss: 0.0253
Epoch 14/100
5994/5994 - 7s - loss: 0.0253 - val_loss: 0.0253
Epoch 15/100
5994/5994 - 4s - loss: 0.0253 - val_loss: 0.0253
Epoch 16/100

Epoch 00016: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
5994/5994 - 4s - loss: 0.0253 - val_loss: 0.0253
Epoch 17/100
5994/5994 - 12s - loss: 0.0253 - val_loss: 0.0253
Epoch 18/100
5994/5994 - 8s - loss: 0.0253 - val_loss: 0.0253
Epoch 19/100

Epoch 00019: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.
5994/5994 - 4s - loss: 0.0253 - val_loss: 0.0253
Epoch 20/100
5994/5994 - 4s - loss: 0.0253 - val_loss: 0.0253
Epoch 21/100
5994/5994 - 4s - loss: 0.0253 - val_loss: 0.0253
Epoch 22/100

Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.
5994/5994 - 4s - loss: 0.0253 - val_loss: 0.0253
Epoch 23/100
5994/5994 - 4s - loss: 0.0253 - val_loss: 0.0253
Epoch 24/100
5994/5994 - 4s - loss: 0.0253 - val_loss: 0.0253
Epoch 25/100

Epoch 00025: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-09.
5994/5994 - 10s - loss: 0.0253 - val_loss: 0.0253
Epoch 26/100
5994/5994 - 4s - loss: 0.0253 - val_loss: 0.0253
Epoch 27/100
5994/5994 - 4s - loss: 0.0253 - val_loss: 0.0253
Epoch 00027: early stopping
saving model QRmodel_run_4_vae_run_113_qnt_90_GtoWW35naReco_sigx_0_loss_rk5_05_20220318.h5 to /eos/home-k/kiwoznia/data/QR_models/vae_run_113/qr_run_4
predicting qcdSigAllTestReco
predicting GtoWW35naReco
training on 1534351 events, validating on 383588

training <class 'dadrah.selection.discriminator.QRDiscriminatorPoly_KerasAPI'> QR for quantile 0.99
Model: "functional_71"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_36 (InputLayer)           [(None, 1)]          0                                            
__________________________________________________________________________________________________
Std_Normalize (StdNormalization (None, 1)            0           input_36[0][0]                   
__________________________________________________________________________________________________
lambda_70 (Lambda)              (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
lambda_71 (Lambda)              (None, 1)            0           Std_Normalize[0][0]              
__________________________________________________________________________________________________
concatenate_35 (Concatenate)    (None, 3)            0           lambda_70[0][0]                  
                                                                 lambda_71[0][0]                  
                                                                 Std_Normalize[0][0]              
__________________________________________________________________________________________________
dense_35 (Dense)                (None, 1)            4           concatenate_35[0][0]             
==================================================================================================
Total params: 4
Trainable params: 4
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100
5994/5994 - 4s - loss: 0.2231 - val_loss: 0.0088
Epoch 2/100
5994/5994 - 4s - loss: 0.0056 - val_loss: 0.0049
Epoch 3/100
5994/5994 - 11s - loss: 0.0043 - val_loss: 0.0044
Epoch 4/100
5994/5994 - 11s - loss: 0.0044 - val_loss: 0.0045
Epoch 5/100
5994/5994 - 8s - loss: 0.0043 - val_loss: 0.0043
Epoch 6/100

Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
5994/5994 - 9s - loss: 0.0043 - val_loss: 0.0043
Epoch 7/100
5994/5994 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 8/100
5994/5994 - 8s - loss: 0.0043 - val_loss: 0.0043
Epoch 9/100

Epoch 00009: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
5994/5994 - 6s - loss: 0.0043 - val_loss: 0.0043
Epoch 10/100
5994/5994 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 11/100
5994/5994 - 7s - loss: 0.0043 - val_loss: 0.0043
Epoch 12/100

Epoch 00012: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
5994/5994 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 13/100
5994/5994 - 7s - loss: 0.0043 - val_loss: 0.0043
Epoch 14/100
5994/5994 - 9s - loss: 0.0043 - val_loss: 0.0043
Epoch 15/100

Epoch 00015: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
5994/5994 - 8s - loss: 0.0043 - val_loss: 0.0043
Epoch 16/100
5994/5994 - 5s - loss: 0.0043 - val_loss: 0.0043
Epoch 17/100
5994/5994 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 18/100

Epoch 00018: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
5994/5994 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 19/100
5994/5994 - 7s - loss: 0.0043 - val_loss: 0.0043
Epoch 20/100
5994/5994 - 11s - loss: 0.0043 - val_loss: 0.0043
Epoch 21/100

Epoch 00021: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.
5994/5994 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 22/100
5994/5994 - 10s - loss: 0.0043 - val_loss: 0.0043
Epoch 23/100
5994/5994 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 24/100

Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.
5994/5994 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 25/100
5994/5994 - 11s - loss: 0.0043 - val_loss: 0.0043
Epoch 26/100
5994/5994 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 27/100

Epoch 00027: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-09.
5994/5994 - 8s - loss: 0.0043 - val_loss: 0.0043
Epoch 28/100
5994/5994 - 5s - loss: 0.0043 - val_loss: 0.0043
Epoch 29/100
5994/5994 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 30/100

Epoch 00030: ReduceLROnPlateau reducing learning rate to 5.1200004236307e-10.
5994/5994 - 4s - loss: 0.0043 - val_loss: 0.0043
Epoch 00030: early stopping
saving model QRmodel_run_4_vae_run_113_qnt_99_GtoWW35naReco_sigx_0_loss_rk5_05_20220318.h5 to /eos/home-k/kiwoznia/data/QR_models/vae_run_113/qr_run_4
predicting qcdSigAllTestReco
predicting GtoWW35naReco
writing selections to  /eos/user/k/kiwoznia/data/QR_results/events/vae_run_113/qr_run_4/sig_GtoWW35naReco/xsec_0/loss_rk5_05
written data sample to /eos/user/k/kiwoznia/data/QR_results/events/vae_run_113/qr_run_4/sig_GtoWW35naReco/xsec_0/loss_rk5_05/qcd_sqrtshatTeV_13TeV_PU40_NEW_ALL_Test_reco.h5
written data sample to /eos/user/k/kiwoznia/data/QR_results/events/vae_run_113/qr_run_4/sig_GtoWW35naReco/xsec_0/loss_rk5_05/RSGraviton_WW_NARROW_13TeV_PU40_3.5TeV_reco.h5
loaded model  <tensorflow.python.keras.engine.functional.Functional object at 0x7fbeeb22f9e8>
loaded model  <tensorflow.python.keras.engine.functional.Functional object at 0x7fbde011bb70>
loaded model  <tensorflow.python.keras.engine.functional.Functional object at 0x7fbee78a3a90>
loaded model  <tensorflow.python.keras.engine.functional.Functional object at 0x7fbea81b6828>
loaded model  <tensorflow.python.keras.engine.functional.Functional object at 0x7fbe44476dd8>
loaded model  <tensorflow.python.keras.engine.functional.Functional object at 0x7fbeec40ef28>
'texgyreheros-regular.otf' can not be subsetted into a Type 3 font. The entire font will be embedded in the output.
