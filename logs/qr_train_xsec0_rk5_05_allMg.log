setGPU: Setting GPU to: 0
[DataReader] read_jet_features_from_dir(): reading all events from /eos/user/k/kiwoznia/data/VAE_results/events/run_113/qcd_sqrtshatTeV_13TeV_PU40_NEW_ALL_Train_signalregion_parts
1917939 events read in 1 files in dir /eos/user/k/kiwoznia/data/VAE_results/events/run_113/qcd_sqrtshatTeV_13TeV_PU40_NEW_ALL_Train_signalregion_parts
[DataReader] read_jet_features_from_dir(): reading all events from /eos/user/k/kiwoznia/data/VAE_results/events/run_113/qcd_sqrtshatTeV_13TeV_PU40_NEW_ALL_Test_signalregion_parts
7671759 events read in 1 files in dir /eos/user/k/kiwoznia/data/VAE_results/events/run_113/qcd_sqrtshatTeV_13TeV_PU40_NEW_ALL_Test_signalregion_parts
[DataReader] read_jet_features_from_dir(): reading all events from /eos/user/k/kiwoznia/data/VAE_results/events/run_113/RSGraviton_WW_NARROW_13TeV_PU40_1.5TeV_NEW_parts
397843 events read in 2 files in dir /eos/user/k/kiwoznia/data/VAE_results/events/run_113/RSGraviton_WW_NARROW_13TeV_PU40_1.5TeV_NEW_parts
training on 1534351 events, validating on 383588

training QR for quantile 0.1
Model: "functional_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 1)]               0         
_________________________________________________________________
Std_Normalize (StdNormalizat (None, 1)                 0         
_________________________________________________________________
dense (Dense)                (None, 60)                120       
_________________________________________________________________
dense_1 (Dense)              (None, 60)                3660      
_________________________________________________________________
dense_2 (Dense)              (None, 60)                3660      
_________________________________________________________________
dense_3 (Dense)              (None, 60)                3660      
_________________________________________________________________
dense_4 (Dense)              (None, 60)                3660      
_________________________________________________________________
dense_5 (Dense)              (None, 1)                 61        
=================================================================
Total params: 14,821
Trainable params: 14,821
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
5994/5994 - 22s - loss: 0.0252 - val_loss: 0.0238
Epoch 2/100
5994/5994 - 24s - loss: 0.0241 - val_loss: 0.0241
Epoch 3/100
5994/5994 - 23s - loss: 0.0240 - val_loss: 0.0238
Epoch 4/100

Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
5994/5994 - 22s - loss: 0.0239 - val_loss: 0.0239
Epoch 5/100
5994/5994 - 23s - loss: 0.0237 - val_loss: 0.0238
Epoch 6/100
5994/5994 - 21s - loss: 0.0237 - val_loss: 0.0237
Epoch 7/100

Epoch 00007: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
5994/5994 - 22s - loss: 0.0237 - val_loss: 0.0238
Epoch 8/100
5994/5994 - 22s - loss: 0.0237 - val_loss: 0.0237
Epoch 9/100
5994/5994 - 22s - loss: 0.0237 - val_loss: 0.0237
Epoch 10/100

Epoch 00010: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
5994/5994 - 23s - loss: 0.0237 - val_loss: 0.0237
Epoch 11/100
5994/5994 - 23s - loss: 0.0236 - val_loss: 0.0237
Epoch 12/100
5994/5994 - 21s - loss: 0.0236 - val_loss: 0.0237
Epoch 13/100

Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
5994/5994 - 22s - loss: 0.0236 - val_loss: 0.0237
Epoch 14/100
5994/5994 - 22s - loss: 0.0236 - val_loss: 0.0237
Epoch 15/100
5994/5994 - 22s - loss: 0.0236 - val_loss: 0.0237
Epoch 16/100

Epoch 00016: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
5994/5994 - 22s - loss: 0.0236 - val_loss: 0.0237
Epoch 17/100
5994/5994 - 20s - loss: 0.0236 - val_loss: 0.0237
Epoch 18/100
5994/5994 - 22s - loss: 0.0236 - val_loss: 0.0237
Epoch 19/100

Epoch 00019: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.
5994/5994 - 22s - loss: 0.0236 - val_loss: 0.0237
Epoch 20/100
5994/5994 - 21s - loss: 0.0236 - val_loss: 0.0237
Epoch 21/100
5994/5994 - 20s - loss: 0.0236 - val_loss: 0.0237
Epoch 22/100

Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.
5994/5994 - 20s - loss: 0.0236 - val_loss: 0.0237
Epoch 23/100
5994/5994 - 21s - loss: 0.0236 - val_loss: 0.0237
Epoch 24/100
5994/5994 - 21s - loss: 0.0236 - val_loss: 0.0237
Epoch 25/100

Epoch 00025: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-09.
5994/5994 - 20s - loss: 0.0236 - val_loss: 0.0237
Epoch 26/100
5994/5994 - 20s - loss: 0.0236 - val_loss: 0.0237
Epoch 27/100
5994/5994 - 20s - loss: 0.0236 - val_loss: 0.0237
Epoch 28/100

Epoch 00028: ReduceLROnPlateau reducing learning rate to 5.1200004236307e-10.
5994/5994 - 20s - loss: 0.0236 - val_loss: 0.0237
Epoch 29/100
5994/5994 - 19s - loss: 0.0236 - val_loss: 0.0237
Epoch 00029: early stopping
saving model QRmodel_run_113_qnt_10_GtoWW15naReco_sigx_0_loss_rk5_05_20210428.h5 to /eos/home-k/kiwoznia/data/QR_models/run_113
predicting qcdSigAllTestReco
predicting GtoWW15naReco
training on 1534351 events, validating on 383588

training QR for quantile 0.3
Model: "functional_3"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 1)]               0         
_________________________________________________________________
Std_Normalize (StdNormalizat (None, 1)                 0         
_________________________________________________________________
dense_6 (Dense)              (None, 60)                120       
_________________________________________________________________
dense_7 (Dense)              (None, 60)                3660      
_________________________________________________________________
dense_8 (Dense)              (None, 60)                3660      
_________________________________________________________________
dense_9 (Dense)              (None, 60)                3660      
_________________________________________________________________
dense_10 (Dense)             (None, 60)                3660      
_________________________________________________________________
dense_11 (Dense)             (None, 1)                 61        
=================================================================
Total params: 14,821
Trainable params: 14,821
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
5994/5994 - 19s - loss: 0.0494 - val_loss: 0.0470
Epoch 2/100
5994/5994 - 20s - loss: 0.0473 - val_loss: 0.0471
Epoch 3/100
5994/5994 - 19s - loss: 0.0470 - val_loss: 0.0468
Epoch 4/100
5994/5994 - 18s - loss: 0.0469 - val_loss: 0.0470
Epoch 5/100
5994/5994 - 17s - loss: 0.0469 - val_loss: 0.0473
Epoch 6/100
5994/5994 - 18s - loss: 0.0468 - val_loss: 0.0467
Epoch 7/100
5994/5994 - 19s - loss: 0.0468 - val_loss: 0.0468
Epoch 8/100
5994/5994 - 18s - loss: 0.0468 - val_loss: 0.0469
Epoch 9/100

Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
5994/5994 - 18s - loss: 0.0468 - val_loss: 0.0474
Epoch 10/100
5994/5994 - 17s - loss: 0.0466 - val_loss: 0.0467
Epoch 11/100
5994/5994 - 17s - loss: 0.0466 - val_loss: 0.0467
Epoch 12/100

Epoch 00012: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
5994/5994 - 18s - loss: 0.0466 - val_loss: 0.0467
Epoch 13/100
5994/5994 - 18s - loss: 0.0466 - val_loss: 0.0467
Epoch 14/100
5994/5994 - 17s - loss: 0.0466 - val_loss: 0.0467
Epoch 15/100

Epoch 00015: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
5994/5994 - 17s - loss: 0.0466 - val_loss: 0.0467
Epoch 16/100
5994/5994 - 16s - loss: 0.0466 - val_loss: 0.0467
Epoch 17/100
5994/5994 - 17s - loss: 0.0466 - val_loss: 0.0467
Epoch 18/100

Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
5994/5994 - 17s - loss: 0.0466 - val_loss: 0.0467
Epoch 19/100
5994/5994 - 18s - loss: 0.0466 - val_loss: 0.0467
Epoch 20/100
5994/5994 - 17s - loss: 0.0466 - val_loss: 0.0467
Epoch 21/100

Epoch 00021: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
5994/5994 - 17s - loss: 0.0466 - val_loss: 0.0467
Epoch 22/100
5994/5994 - 17s - loss: 0.0466 - val_loss: 0.0467
Epoch 23/100
5994/5994 - 17s - loss: 0.0466 - val_loss: 0.0467
Epoch 24/100

Epoch 00024: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.
5994/5994 - 16s - loss: 0.0466 - val_loss: 0.0467
Epoch 25/100
5994/5994 - 17s - loss: 0.0466 - val_loss: 0.0467
Epoch 26/100
5994/5994 - 17s - loss: 0.0466 - val_loss: 0.0467
Epoch 27/100

Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.
5994/5994 - 18s - loss: 0.0466 - val_loss: 0.0467
Epoch 28/100
5994/5994 - 18s - loss: 0.0466 - val_loss: 0.0467
Epoch 29/100
5994/5994 - 17s - loss: 0.0466 - val_loss: 0.0467
Epoch 30/100

Epoch 00030: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-09.
5994/5994 - 16s - loss: 0.0466 - val_loss: 0.0467
Epoch 31/100
5994/5994 - 16s - loss: 0.0466 - val_loss: 0.0467
Epoch 32/100
5994/5994 - 17s - loss: 0.0466 - val_loss: 0.0467
Epoch 33/100

Epoch 00033: ReduceLROnPlateau reducing learning rate to 5.1200004236307e-10.
5994/5994 - 16s - loss: 0.0466 - val_loss: 0.0467
Epoch 34/100
5994/5994 - 16s - loss: 0.0466 - val_loss: 0.0467
Epoch 35/100
5994/5994 - 17s - loss: 0.0466 - val_loss: 0.0467
Epoch 00035: early stopping
saving model QRmodel_run_113_qnt_30_GtoWW15naReco_sigx_0_loss_rk5_05_20210428.h5 to /eos/home-k/kiwoznia/data/QR_models/run_113
predicting qcdSigAllTestReco
predicting GtoWW15naReco
training on 1534351 events, validating on 383588

training QR for quantile 0.5
Model: "functional_5"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_3 (InputLayer)         [(None, 1)]               0         
_________________________________________________________________
Std_Normalize (StdNormalizat (None, 1)                 0         
_________________________________________________________________
dense_12 (Dense)             (None, 60)                120       
_________________________________________________________________
dense_13 (Dense)             (None, 60)                3660      
_________________________________________________________________
dense_14 (Dense)             (None, 60)                3660      
_________________________________________________________________
dense_15 (Dense)             (None, 60)                3660      
_________________________________________________________________
dense_16 (Dense)             (None, 60)                3660      
_________________________________________________________________
dense_17 (Dense)             (None, 1)                 61        
=================================================================
Total params: 14,821
Trainable params: 14,821
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
5994/5994 - 17s - loss: 0.0572 - val_loss: 0.0556
Epoch 2/100
5994/5994 - 17s - loss: 0.0546 - val_loss: 0.0545
Epoch 3/100
5994/5994 - 18s - loss: 0.0543 - val_loss: 0.0542
Epoch 4/100
5994/5994 - 18s - loss: 0.0542 - val_loss: 0.0541
Epoch 5/100
5994/5994 - 17s - loss: 0.0542 - val_loss: 0.0542
Epoch 6/100
5994/5994 - 16s - loss: 0.0541 - val_loss: 0.0540
Epoch 7/100
5994/5994 - 17s - loss: 0.0541 - val_loss: 0.0541
Epoch 8/100
5994/5994 - 17s - loss: 0.0541 - val_loss: 0.0541
Epoch 9/100

Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
5994/5994 - 17s - loss: 0.0541 - val_loss: 0.0540
Epoch 10/100
5994/5994 - 17s - loss: 0.0539 - val_loss: 0.0540
Epoch 11/100
5994/5994 - 18s - loss: 0.0539 - val_loss: 0.0539
Epoch 12/100

Epoch 00012: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
5994/5994 - 17s - loss: 0.0539 - val_loss: 0.0539
Epoch 13/100
5994/5994 - 17s - loss: 0.0538 - val_loss: 0.0539
Epoch 14/100
5994/5994 - 16s - loss: 0.0538 - val_loss: 0.0539
Epoch 15/100

Epoch 00015: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
5994/5994 - 16s - loss: 0.0538 - val_loss: 0.0539
Epoch 16/100
5994/5994 - 18s - loss: 0.0538 - val_loss: 0.0539
Epoch 17/100
5994/5994 - 16s - loss: 0.0538 - val_loss: 0.0539
Epoch 18/100

Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
5994/5994 - 17s - loss: 0.0538 - val_loss: 0.0539
Epoch 19/100
5994/5994 - 18s - loss: 0.0538 - val_loss: 0.0539
Epoch 20/100
5994/5994 - 17s - loss: 0.0538 - val_loss: 0.0539
Epoch 21/100

Epoch 00021: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
5994/5994 - 17s - loss: 0.0538 - val_loss: 0.0539
Epoch 22/100
5994/5994 - 17s - loss: 0.0538 - val_loss: 0.0539
Epoch 23/100
5994/5994 - 17s - loss: 0.0538 - val_loss: 0.0539
Epoch 24/100

Epoch 00024: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.
5994/5994 - 17s - loss: 0.0538 - val_loss: 0.0539
Epoch 25/100
5994/5994 - 18s - loss: 0.0538 - val_loss: 0.0539
Epoch 26/100
5994/5994 - 17s - loss: 0.0538 - val_loss: 0.0539
Epoch 27/100

Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.
5994/5994 - 17s - loss: 0.0538 - val_loss: 0.0539
Epoch 28/100
5994/5994 - 17s - loss: 0.0538 - val_loss: 0.0539
Epoch 29/100
5994/5994 - 17s - loss: 0.0538 - val_loss: 0.0539
Epoch 30/100

Epoch 00030: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-09.
5994/5994 - 16s - loss: 0.0538 - val_loss: 0.0539
Epoch 31/100
5994/5994 - 17s - loss: 0.0538 - val_loss: 0.0539
Epoch 32/100
5994/5994 - 17s - loss: 0.0538 - val_loss: 0.0539
Epoch 33/100

Epoch 00033: ReduceLROnPlateau reducing learning rate to 5.1200004236307e-10.
5994/5994 - 17s - loss: 0.0538 - val_loss: 0.0539
Epoch 34/100
5994/5994 - 17s - loss: 0.0538 - val_loss: 0.0539
Epoch 35/100
5994/5994 - 17s - loss: 0.0538 - val_loss: 0.0539
Epoch 00035: early stopping
saving model QRmodel_run_113_qnt_50_GtoWW15naReco_sigx_0_loss_rk5_05_20210428.h5 to /eos/home-k/kiwoznia/data/QR_models/run_113
predicting qcdSigAllTestReco
predicting GtoWW15naReco
training on 1534351 events, validating on 383588

training QR for quantile 0.7
Model: "functional_7"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_4 (InputLayer)         [(None, 1)]               0         
_________________________________________________________________
Std_Normalize (StdNormalizat (None, 1)                 0         
_________________________________________________________________
dense_18 (Dense)             (None, 60)                120       
_________________________________________________________________
dense_19 (Dense)             (None, 60)                3660      
_________________________________________________________________
dense_20 (Dense)             (None, 60)                3660      
_________________________________________________________________
dense_21 (Dense)             (None, 60)                3660      
_________________________________________________________________
dense_22 (Dense)             (None, 60)                3660      
_________________________________________________________________
dense_23 (Dense)             (None, 1)                 61        
=================================================================
Total params: 14,821
Trainable params: 14,821
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
5994/5994 - 16s - loss: 0.0512 - val_loss: 0.0487
Epoch 2/100
5994/5994 - 16s - loss: 0.0485 - val_loss: 0.0479
Epoch 3/100
5994/5994 - 16s - loss: 0.0483 - val_loss: 0.0492
Epoch 4/100
5994/5994 - 16s - loss: 0.0482 - val_loss: 0.0490
Epoch 5/100

Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
5994/5994 - 17s - loss: 0.0481 - val_loss: 0.0479
Epoch 6/100
5994/5994 - 16s - loss: 0.0478 - val_loss: 0.0479
Epoch 7/100
5994/5994 - 16s - loss: 0.0478 - val_loss: 0.0478
Epoch 8/100

Epoch 00008: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
5994/5994 - 17s - loss: 0.0478 - val_loss: 0.0480
Epoch 9/100
5994/5994 - 16s - loss: 0.0478 - val_loss: 0.0478
Epoch 10/100
5994/5994 - 16s - loss: 0.0478 - val_loss: 0.0478
Epoch 11/100

Epoch 00011: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
5994/5994 - 17s - loss: 0.0478 - val_loss: 0.0478
Epoch 12/100
5994/5994 - 16s - loss: 0.0478 - val_loss: 0.0478
Epoch 13/100
5994/5994 - 17s - loss: 0.0478 - val_loss: 0.0478
Epoch 14/100

Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
5994/5994 - 17s - loss: 0.0478 - val_loss: 0.0478
Epoch 15/100
5994/5994 - 16s - loss: 0.0478 - val_loss: 0.0478
Epoch 16/100
5994/5994 - 16s - loss: 0.0478 - val_loss: 0.0478
Epoch 17/100

Epoch 00017: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
5994/5994 - 17s - loss: 0.0478 - val_loss: 0.0478
Epoch 18/100
5994/5994 - 16s - loss: 0.0478 - val_loss: 0.0478
Epoch 19/100
5994/5994 - 17s - loss: 0.0478 - val_loss: 0.0478
Epoch 20/100

Epoch 00020: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.
5994/5994 - 17s - loss: 0.0478 - val_loss: 0.0478
Epoch 21/100
5994/5994 - 16s - loss: 0.0478 - val_loss: 0.0478
Epoch 22/100
5994/5994 - 16s - loss: 0.0478 - val_loss: 0.0478
Epoch 23/100

Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.
5994/5994 - 16s - loss: 0.0478 - val_loss: 0.0478
Epoch 24/100
5994/5994 - 16s - loss: 0.0478 - val_loss: 0.0478
Epoch 25/100
5994/5994 - 17s - loss: 0.0478 - val_loss: 0.0478
Epoch 00025: early stopping
saving model QRmodel_run_113_qnt_70_GtoWW15naReco_sigx_0_loss_rk5_05_20210428.h5 to /eos/home-k/kiwoznia/data/QR_models/run_113
predicting qcdSigAllTestReco
predicting GtoWW15naReco
training on 1534351 events, validating on 383588

training QR for quantile 0.9
Model: "functional_9"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_5 (InputLayer)         [(None, 1)]               0         
_________________________________________________________________
Std_Normalize (StdNormalizat (None, 1)                 0         
_________________________________________________________________
dense_24 (Dense)             (None, 60)                120       
_________________________________________________________________
dense_25 (Dense)             (None, 60)                3660      
_________________________________________________________________
dense_26 (Dense)             (None, 60)                3660      
_________________________________________________________________
dense_27 (Dense)             (None, 60)                3660      
_________________________________________________________________
dense_28 (Dense)             (None, 60)                3660      
_________________________________________________________________
dense_29 (Dense)             (None, 1)                 61        
=================================================================
Total params: 14,821
Trainable params: 14,821
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
5994/5994 - 18s - loss: 0.0274 - val_loss: 0.0260
Epoch 2/100
5994/5994 - 16s - loss: 0.0257 - val_loss: 0.0259
Epoch 3/100
5994/5994 - 16s - loss: 0.0256 - val_loss: 0.0258
Epoch 4/100
5994/5994 - 17s - loss: 0.0255 - val_loss: 0.0255
Epoch 5/100
5994/5994 - 17s - loss: 0.0255 - val_loss: 0.0254
Epoch 6/100
5994/5994 - 17s - loss: 0.0255 - val_loss: 0.0258
Epoch 7/100
5994/5994 - 17s - loss: 0.0254 - val_loss: 0.0254
Epoch 8/100

Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
5994/5994 - 16s - loss: 0.0254 - val_loss: 0.0254
Epoch 9/100
5994/5994 - 15s - loss: 0.0253 - val_loss: 0.0254
Epoch 10/100
5994/5994 - 16s - loss: 0.0253 - val_loss: 0.0254
Epoch 11/100

Epoch 00011: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
5994/5994 - 17s - loss: 0.0253 - val_loss: 0.0253
Epoch 12/100
5994/5994 - 16s - loss: 0.0253 - val_loss: 0.0253
Epoch 13/100
5994/5994 - 16s - loss: 0.0253 - val_loss: 0.0253
Epoch 14/100

Epoch 00014: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
5994/5994 - 17s - loss: 0.0253 - val_loss: 0.0253
Epoch 15/100
5994/5994 - 16s - loss: 0.0253 - val_loss: 0.0253
Epoch 16/100
5994/5994 - 16s - loss: 0.0253 - val_loss: 0.0253
Epoch 17/100

Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
5994/5994 - 16s - loss: 0.0253 - val_loss: 0.0253
Epoch 18/100
5994/5994 - 16s - loss: 0.0253 - val_loss: 0.0253
Epoch 19/100
5994/5994 - 16s - loss: 0.0253 - val_loss: 0.0253
Epoch 20/100

Epoch 00020: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
5994/5994 - 16s - loss: 0.0253 - val_loss: 0.0253
Epoch 21/100
5994/5994 - 16s - loss: 0.0253 - val_loss: 0.0253
Epoch 22/100
5994/5994 - 16s - loss: 0.0253 - val_loss: 0.0253
Epoch 23/100

Epoch 00023: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.
5994/5994 - 16s - loss: 0.0253 - val_loss: 0.0253
Epoch 24/100
5994/5994 - 16s - loss: 0.0253 - val_loss: 0.0253
Epoch 25/100
5994/5994 - 17s - loss: 0.0253 - val_loss: 0.0253
Epoch 00025: early stopping
saving model QRmodel_run_113_qnt_90_GtoWW15naReco_sigx_0_loss_rk5_05_20210428.h5 to /eos/home-k/kiwoznia/data/QR_models/run_113
predicting qcdSigAllTestReco
predicting GtoWW15naReco
training on 1534351 events, validating on 383588

training QR for quantile 0.99
Model: "functional_11"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_6 (InputLayer)         [(None, 1)]               0         
_________________________________________________________________
Std_Normalize (StdNormalizat (None, 1)                 0         
_________________________________________________________________
dense_30 (Dense)             (None, 60)                120       
_________________________________________________________________
dense_31 (Dense)             (None, 60)                3660      
_________________________________________________________________
dense_32 (Dense)             (None, 60)                3660      
_________________________________________________________________
dense_33 (Dense)             (None, 60)                3660      
_________________________________________________________________
dense_34 (Dense)             (None, 60)                3660      
_________________________________________________________________
dense_35 (Dense)             (None, 1)                 61        
=================================================================
Total params: 14,821
Trainable params: 14,821
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
5994/5994 - 16s - loss: 0.0058 - val_loss: 0.0044
Epoch 2/100
5994/5994 - 16s - loss: 0.0045 - val_loss: 0.0044
Epoch 3/100
5994/5994 - 16s - loss: 0.0044 - val_loss: 0.0043
Epoch 4/100

Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
5994/5994 - 16s - loss: 0.0044 - val_loss: 0.0045
Epoch 5/100
5994/5994 - 16s - loss: 0.0043 - val_loss: 0.0043
Epoch 6/100
5994/5994 - 16s - loss: 0.0043 - val_loss: 0.0043
Epoch 7/100

Epoch 00007: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
5994/5994 - 16s - loss: 0.0043 - val_loss: 0.0043
Epoch 8/100
5994/5994 - 17s - loss: 0.0043 - val_loss: 0.0043
Epoch 9/100
5994/5994 - 17s - loss: 0.0043 - val_loss: 0.0043
Epoch 10/100
5994/5994 - 17s - loss: 0.0043 - val_loss: 0.0043
Epoch 11/100

Epoch 00011: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
5994/5994 - 17s - loss: 0.0043 - val_loss: 0.0043
Epoch 12/100
5994/5994 - 16s - loss: 0.0043 - val_loss: 0.0043
Epoch 13/100
5994/5994 - 16s - loss: 0.0043 - val_loss: 0.0043
Epoch 14/100

Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
5994/5994 - 16s - loss: 0.0043 - val_loss: 0.0043
Epoch 15/100
5994/5994 - 16s - loss: 0.0043 - val_loss: 0.0043
Epoch 16/100
5994/5994 - 16s - loss: 0.0043 - val_loss: 0.0043
Epoch 17/100

Epoch 00017: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
5994/5994 - 16s - loss: 0.0043 - val_loss: 0.0043
Epoch 18/100
5994/5994 - 16s - loss: 0.0043 - val_loss: 0.0043
Epoch 00018: early stopping
saving model QRmodel_run_113_qnt_99_GtoWW15naReco_sigx_0_loss_rk5_05_20210428.h5 to /eos/home-k/kiwoznia/data/QR_models/run_113
predicting qcdSigAllTestReco
predicting GtoWW15naReco
writing selections to  /eos/user/k/kiwoznia/data/QR_results/events/run_113/sig_GtoWW15naReco/xsec_0/loss_rk5_05
written data sample to /eos/user/k/kiwoznia/data/QR_results/events/run_113/sig_GtoWW15naReco/xsec_0/loss_rk5_05/qcd_sqrtshatTeV_13TeV_PU40_NEW_ALL_Test_reco.h5
written data sample to /eos/user/k/kiwoznia/data/QR_results/events/run_113/sig_GtoWW15naReco/xsec_0/loss_rk5_05/RSGraviton_WW_NARROW_13TeV_PU40_1.5TeV_reco.h5
loaded model  <tensorflow.python.keras.engine.functional.Functional object at 0x7fe3ec13e4e0>
loaded model  <tensorflow.python.keras.engine.functional.Functional object at 0x7fe3ec192940>
loaded model  <tensorflow.python.keras.engine.functional.Functional object at 0x7fe3ec354b70>
loaded model  <tensorflow.python.keras.engine.functional.Functional object at 0x7fe3e6ed7ba8>
loaded model  <tensorflow.python.keras.engine.functional.Functional object at 0x7fe3e6f53f98>
loaded model  <tensorflow.python.keras.engine.functional.Functional object at 0x7fe3ec2c9e80>
/afs/cern.ch/user/k/kiwoznia/.local/lib/python3.6/site-packages/matplotlib/colors.py:1207: RuntimeWarning: invalid value encountered in less_equal
  mask |= resdat <= 0
findfont: Font family ['cursive'] not found. Falling back to DejaVu Sans.
'texgyreheros-regular.otf' can not be subsetted into a Type 3 font. The entire font will be embedded in the output.
[DataReader] read_jet_features_from_dir(): reading all events from /eos/user/k/kiwoznia/data/VAE_results/events/run_113/RSGraviton_WW_NARROW_13TeV_PU40_2.5TeV_NEW_parts
492361 events read in 2 files in dir /eos/user/k/kiwoznia/data/VAE_results/events/run_113/RSGraviton_WW_NARROW_13TeV_PU40_2.5TeV_NEW_parts
training on 1534351 events, validating on 383588

training QR for quantile 0.1
Model: "functional_13"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_7 (InputLayer)         [(None, 1)]               0         
_________________________________________________________________
Std_Normalize (StdNormalizat (None, 1)                 0         
_________________________________________________________________
dense_36 (Dense)             (None, 60)                120       
_________________________________________________________________
dense_37 (Dense)             (None, 60)                3660      
_________________________________________________________________
dense_38 (Dense)             (None, 60)                3660      
_________________________________________________________________
dense_39 (Dense)             (None, 60)                3660      
_________________________________________________________________
dense_40 (Dense)             (None, 60)                3660      
_________________________________________________________________
dense_41 (Dense)             (None, 1)                 61        
=================================================================
Total params: 14,821
Trainable params: 14,821
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
5994/5994 - 17s - loss: 0.0252 - val_loss: 0.0241
Epoch 2/100
5994/5994 - 16s - loss: 0.0240 - val_loss: 0.0241
Epoch 3/100
5994/5994 - 17s - loss: 0.0239 - val_loss: 0.0239
Epoch 4/100
5994/5994 - 16s - loss: 0.0239 - val_loss: 0.0241
Epoch 5/100
5994/5994 - 17s - loss: 0.0238 - val_loss: 0.0238
Epoch 6/100
5994/5994 - 17s - loss: 0.0238 - val_loss: 0.0240
Epoch 7/100
5994/5994 - 17s - loss: 0.0238 - val_loss: 0.0240
Epoch 8/100

Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
5994/5994 - 17s - loss: 0.0238 - val_loss: 0.0237
Epoch 9/100
5994/5994 - 17s - loss: 0.0237 - val_loss: 0.0237
Epoch 10/100
5994/5994 - 18s - loss: 0.0237 - val_loss: 0.0237
Epoch 11/100

Epoch 00011: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
5994/5994 - 18s - loss: 0.0237 - val_loss: 0.0237
Epoch 12/100
5994/5994 - 18s - loss: 0.0237 - val_loss: 0.0237
Epoch 13/100
5994/5994 - 18s - loss: 0.0237 - val_loss: 0.0237
Epoch 14/100

Epoch 00014: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
5994/5994 - 17s - loss: 0.0237 - val_loss: 0.0237
Epoch 15/100
5994/5994 - 17s - loss: 0.0236 - val_loss: 0.0237
Epoch 16/100
5994/5994 - 17s - loss: 0.0236 - val_loss: 0.0237
Epoch 17/100

Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
5994/5994 - 16s - loss: 0.0236 - val_loss: 0.0237
Epoch 18/100
5994/5994 - 16s - loss: 0.0236 - val_loss: 0.0237
Epoch 19/100
5994/5994 - 18s - loss: 0.0236 - val_loss: 0.0237
Epoch 20/100

Epoch 00020: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
5994/5994 - 17s - loss: 0.0236 - val_loss: 0.0237
Epoch 21/100
5994/5994 - 16s - loss: 0.0236 - val_loss: 0.0237
Epoch 22/100
5994/5994 - 16s - loss: 0.0236 - val_loss: 0.0237
Epoch 23/100

Epoch 00023: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.
5994/5994 - 17s - loss: 0.0236 - val_loss: 0.0237
Epoch 24/100
5994/5994 - 18s - loss: 0.0236 - val_loss: 0.0237
Epoch 25/100
5994/5994 - 18s - loss: 0.0236 - val_loss: 0.0237
Epoch 26/100

Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.
5994/5994 - 17s - loss: 0.0236 - val_loss: 0.0237
Epoch 27/100
5994/5994 - 16s - loss: 0.0236 - val_loss: 0.0237
Epoch 28/100
5994/5994 - 17s - loss: 0.0236 - val_loss: 0.0237
Epoch 00028: early stopping
saving model QRmodel_run_113_qnt_10_GtoWW25naReco_sigx_0_loss_rk5_05_20210428.h5 to /eos/home-k/kiwoznia/data/QR_models/run_113
predicting qcdSigAllTestReco
predicting GtoWW25naReco
training on 1534351 events, validating on 383588

training QR for quantile 0.3
Model: "functional_15"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_8 (InputLayer)         [(None, 1)]               0         
_________________________________________________________________
Std_Normalize (StdNormalizat (None, 1)                 0         
_________________________________________________________________
dense_42 (Dense)             (None, 60)                120       
_________________________________________________________________
dense_43 (Dense)             (None, 60)                3660      
_________________________________________________________________
dense_44 (Dense)             (None, 60)                3660      
_________________________________________________________________
dense_45 (Dense)             (None, 60)                3660      
_________________________________________________________________
dense_46 (Dense)             (None, 60)                3660      
_________________________________________________________________
dense_47 (Dense)             (None, 1)                 61        
=================================================================
Total params: 14,821
Trainable params: 14,821
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
5994/5994 - 17s - loss: 0.0485 - val_loss: 0.0471
Epoch 2/100
5994/5994 - 17s - loss: 0.0472 - val_loss: 0.0468
Epoch 3/100
5994/5994 - 17s - loss: 0.0470 - val_loss: 0.0475
Epoch 4/100
5994/5994 - 16s - loss: 0.0469 - val_loss: 0.0466
Epoch 5/100
5994/5994 - 16s - loss: 0.0469 - val_loss: 0.0466
Epoch 6/100
5994/5994 - 16s - loss: 0.0469 - val_loss: 0.0467
Epoch 7/100

Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
5994/5994 - 16s - loss: 0.0468 - val_loss: 0.0466
Epoch 8/100
5994/5994 - 16s - loss: 0.0467 - val_loss: 0.0466
Epoch 9/100
5994/5994 - 16s - loss: 0.0467 - val_loss: 0.0466
Epoch 10/100

Epoch 00010: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
5994/5994 - 17s - loss: 0.0467 - val_loss: 0.0466
Epoch 11/100
5994/5994 - 16s - loss: 0.0466 - val_loss: 0.0466
Epoch 12/100
5994/5994 - 16s - loss: 0.0466 - val_loss: 0.0466
Epoch 13/100

Epoch 00013: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
5994/5994 - 15s - loss: 0.0466 - val_loss: 0.0466
Epoch 14/100
5994/5994 - 16s - loss: 0.0466 - val_loss: 0.0466
Epoch 15/100
5994/5994 - 16s - loss: 0.0466 - val_loss: 0.0466
Epoch 16/100

Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
5994/5994 - 16s - loss: 0.0466 - val_loss: 0.0466
Epoch 17/100
5994/5994 - 17s - loss: 0.0466 - val_loss: 0.0466
Epoch 18/100
5994/5994 - 16s - loss: 0.0466 - val_loss: 0.0466
Epoch 19/100

Epoch 00019: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
5994/5994 - 16s - loss: 0.0466 - val_loss: 0.0466
Epoch 20/100
5994/5994 - 16s - loss: 0.0466 - val_loss: 0.0466
Epoch 21/100
5994/5994 - 17s - loss: 0.0466 - val_loss: 0.0466
Epoch 22/100

Epoch 00022: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.
5994/5994 - 17s - loss: 0.0466 - val_loss: 0.0466
Epoch 23/100
5994/5994 - 16s - loss: 0.0466 - val_loss: 0.0466
Epoch 24/100
5994/5994 - 15s - loss: 0.0466 - val_loss: 0.0466
Epoch 25/100

Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.
5994/5994 - 15s - loss: 0.0466 - val_loss: 0.0466
Epoch 26/100
5994/5994 - 16s - loss: 0.0466 - val_loss: 0.0466
Epoch 27/100
5994/5994 - 16s - loss: 0.0466 - val_loss: 0.0466
Epoch 00027: early stopping
saving model QRmodel_run_113_qnt_30_GtoWW25naReco_sigx_0_loss_rk5_05_20210428.h5 to /eos/home-k/kiwoznia/data/QR_models/run_113
predicting qcdSigAllTestReco
predicting GtoWW25naReco
training on 1534351 events, validating on 383588

training QR for quantile 0.5
Model: "functional_17"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_9 (InputLayer)         [(None, 1)]               0         
_________________________________________________________________
Std_Normalize (StdNormalizat (None, 1)                 0         
_________________________________________________________________
dense_48 (Dense)             (None, 60)                120       
_________________________________________________________________
dense_49 (Dense)             (None, 60)                3660      
_________________________________________________________________
dense_50 (Dense)             (None, 60)                3660      
_________________________________________________________________
dense_51 (Dense)             (None, 60)                3660      
_________________________________________________________________
dense_52 (Dense)             (None, 60)                3660      
_________________________________________________________________
dense_53 (Dense)             (None, 1)                 61        
=================================================================
Total params: 14,821
Trainable params: 14,821
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
5994/5994 - 16s - loss: 0.0575 - val_loss: 0.0546
Epoch 2/100
5994/5994 - 16s - loss: 0.0546 - val_loss: 0.0544
Epoch 3/100
5994/5994 - 16s - loss: 0.0544 - val_loss: 0.0544
Epoch 4/100
5994/5994 - 16s - loss: 0.0543 - val_loss: 0.0543
Epoch 5/100
5994/5994 - 16s - loss: 0.0542 - val_loss: 0.0539
Epoch 6/100
5994/5994 - 16s - loss: 0.0541 - val_loss: 0.0539
Epoch 7/100
5994/5994 - 17s - loss: 0.0541 - val_loss: 0.0539
Epoch 8/100

Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
5994/5994 - 17s - loss: 0.0541 - val_loss: 0.0539
Epoch 9/100
5994/5994 - 18s - loss: 0.0539 - val_loss: 0.0540
Epoch 10/100
5994/5994 - 16s - loss: 0.0539 - val_loss: 0.0539
Epoch 11/100

Epoch 00011: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
5994/5994 - 16s - loss: 0.0539 - val_loss: 0.0539
Epoch 12/100
5994/5994 - 17s - loss: 0.0539 - val_loss: 0.0538
Epoch 13/100
5994/5994 - 17s - loss: 0.0539 - val_loss: 0.0538
Epoch 14/100

Epoch 00014: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
5994/5994 - 16s - loss: 0.0539 - val_loss: 0.0538
Epoch 15/100
5994/5994 - 16s - loss: 0.0539 - val_loss: 0.0538
Epoch 16/100
5994/5994 - 16s - loss: 0.0539 - val_loss: 0.0538
Epoch 17/100

Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
5994/5994 - 16s - loss: 0.0539 - val_loss: 0.0538
Epoch 18/100
5994/5994 - 16s - loss: 0.0539 - val_loss: 0.0538
Epoch 19/100
5994/5994 - 16s - loss: 0.0539 - val_loss: 0.0538
Epoch 20/100

Epoch 00020: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
5994/5994 - 16s - loss: 0.0539 - val_loss: 0.0538
Epoch 21/100
5994/5994 - 17s - loss: 0.0539 - val_loss: 0.0538
Epoch 22/100
5994/5994 - 17s - loss: 0.0539 - val_loss: 0.0538
Epoch 23/100

Epoch 00023: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.
5994/5994 - 17s - loss: 0.0539 - val_loss: 0.0538
Epoch 24/100
5994/5994 - 20s - loss: 0.0539 - val_loss: 0.0538
Epoch 25/100
5994/5994 - 18s - loss: 0.0539 - val_loss: 0.0538
Epoch 26/100

Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.
5994/5994 - 17s - loss: 0.0539 - val_loss: 0.0538
Epoch 27/100
5994/5994 - 18s - loss: 0.0539 - val_loss: 0.0538
Epoch 00027: early stopping
saving model QRmodel_run_113_qnt_50_GtoWW25naReco_sigx_0_loss_rk5_05_20210428.h5 to /eos/home-k/kiwoznia/data/QR_models/run_113
predicting qcdSigAllTestReco
predicting GtoWW25naReco
training on 1534351 events, validating on 383588

training QR for quantile 0.7
Model: "functional_19"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_10 (InputLayer)        [(None, 1)]               0         
_________________________________________________________________
Std_Normalize (StdNormalizat (None, 1)                 0         
_________________________________________________________________
dense_54 (Dense)             (None, 60)                120       
_________________________________________________________________
dense_55 (Dense)             (None, 60)                3660      
_________________________________________________________________
dense_56 (Dense)             (None, 60)                3660      
_________________________________________________________________
dense_57 (Dense)             (None, 60)                3660      
_________________________________________________________________
dense_58 (Dense)             (None, 60)                3660      
_________________________________________________________________
dense_59 (Dense)             (None, 1)                 61        
=================================================================
Total params: 14,821
Trainable params: 14,821
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
5994/5994 - 20s - loss: 0.0513 - val_loss: 0.0504
Epoch 2/100
5994/5994 - 20s - loss: 0.0486 - val_loss: 0.0480
Epoch 3/100
5994/5994 - 20s - loss: 0.0483 - val_loss: 0.0480
Epoch 4/100
5994/5994 - 20s - loss: 0.0482 - val_loss: 0.0480
Epoch 5/100

Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
5994/5994 - 20s - loss: 0.0481 - val_loss: 0.0480
Epoch 6/100
5994/5994 - 21s - loss: 0.0478 - val_loss: 0.0478
Epoch 7/100
5994/5994 - 21s - loss: 0.0479 - val_loss: 0.0477
Epoch 8/100
5994/5994 - 20s - loss: 0.0478 - val_loss: 0.0479
Epoch 9/100

Epoch 00009: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
5994/5994 - 19s - loss: 0.0478 - val_loss: 0.0478
Epoch 10/100
5994/5994 - 20s - loss: 0.0478 - val_loss: 0.0477
Epoch 11/100
5994/5994 - 19s - loss: 0.0478 - val_loss: 0.0478
Epoch 12/100

Epoch 00012: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
5994/5994 - 20s - loss: 0.0478 - val_loss: 0.0478
Epoch 13/100
5994/5994 - 20s - loss: 0.0478 - val_loss: 0.0477
Epoch 14/100
5994/5994 - 20s - loss: 0.0478 - val_loss: 0.0477
Epoch 15/100

Epoch 00015: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
5994/5994 - 20s - loss: 0.0478 - val_loss: 0.0477
Epoch 16/100
5994/5994 - 21s - loss: 0.0478 - val_loss: 0.0477
Epoch 17/100
5994/5994 - 20s - loss: 0.0478 - val_loss: 0.0477
Epoch 18/100

Epoch 00018: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
5994/5994 - 20s - loss: 0.0478 - val_loss: 0.0477
Epoch 19/100
5994/5994 - 21s - loss: 0.0478 - val_loss: 0.0477
Epoch 20/100
5994/5994 - 20s - loss: 0.0478 - val_loss: 0.0477
Epoch 21/100

Epoch 00021: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.
5994/5994 - 22s - loss: 0.0478 - val_loss: 0.0477
Epoch 22/100
5994/5994 - 21s - loss: 0.0478 - val_loss: 0.0477
Epoch 23/100
5994/5994 - 21s - loss: 0.0478 - val_loss: 0.0477
Epoch 24/100

Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.
5994/5994 - 22s - loss: 0.0478 - val_loss: 0.0477
Epoch 25/100
5994/5994 - 21s - loss: 0.0478 - val_loss: 0.0477
Epoch 26/100
5994/5994 - 21s - loss: 0.0478 - val_loss: 0.0477
Epoch 27/100

Epoch 00027: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-09.
5994/5994 - 20s - loss: 0.0478 - val_loss: 0.0477
Epoch 28/100
5994/5994 - 19s - loss: 0.0478 - val_loss: 0.0477
Epoch 00028: early stopping
saving model QRmodel_run_113_qnt_70_GtoWW25naReco_sigx_0_loss_rk5_05_20210428.h5 to /eos/home-k/kiwoznia/data/QR_models/run_113
predicting qcdSigAllTestReco
predicting GtoWW25naReco
training on 1534351 events, validating on 383588

training QR for quantile 0.9
Model: "functional_21"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_11 (InputLayer)        [(None, 1)]               0         
_________________________________________________________________
Std_Normalize (StdNormalizat (None, 1)                 0         
_________________________________________________________________
dense_60 (Dense)             (None, 60)                120       
_________________________________________________________________
dense_61 (Dense)             (None, 60)                3660      
_________________________________________________________________
dense_62 (Dense)             (None, 60)                3660      
_________________________________________________________________
dense_63 (Dense)             (None, 60)                3660      
_________________________________________________________________
dense_64 (Dense)             (None, 60)                3660      
_________________________________________________________________
dense_65 (Dense)             (None, 1)                 61        
=================================================================
Total params: 14,821
Trainable params: 14,821
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
5994/5994 - 17s - loss: 0.0280 - val_loss: 0.0261
Epoch 2/100
5994/5994 - 16s - loss: 0.0258 - val_loss: 0.0253
Epoch 3/100
5994/5994 - 16s - loss: 0.0256 - val_loss: 0.0254
Epoch 4/100
5994/5994 - 16s - loss: 0.0255 - val_loss: 0.0254
Epoch 5/100

Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
5994/5994 - 16s - loss: 0.0255 - val_loss: 0.0253
Epoch 6/100
5994/5994 - 17s - loss: 0.0253 - val_loss: 0.0253
Epoch 7/100
5994/5994 - 16s - loss: 0.0253 - val_loss: 0.0253
Epoch 8/100

Epoch 00008: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
5994/5994 - 16s - loss: 0.0253 - val_loss: 0.0253
Epoch 9/100
5994/5994 - 16s - loss: 0.0253 - val_loss: 0.0253
Epoch 10/100
5994/5994 - 17s - loss: 0.0253 - val_loss: 0.0253
Epoch 11/100

Epoch 00011: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
5994/5994 - 16s - loss: 0.0253 - val_loss: 0.0253
Epoch 12/100
5994/5994 - 17s - loss: 0.0253 - val_loss: 0.0253
Epoch 13/100
5994/5994 - 16s - loss: 0.0253 - val_loss: 0.0253
Epoch 14/100

Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
5994/5994 - 17s - loss: 0.0253 - val_loss: 0.0253
Epoch 15/100
5994/5994 - 16s - loss: 0.0253 - val_loss: 0.0253
Epoch 16/100
5994/5994 - 16s - loss: 0.0253 - val_loss: 0.0253
Epoch 17/100

Epoch 00017: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
5994/5994 - 16s - loss: 0.0253 - val_loss: 0.0253
Epoch 18/100
5994/5994 - 16s - loss: 0.0253 - val_loss: 0.0253
Epoch 19/100
5994/5994 - 16s - loss: 0.0253 - val_loss: 0.0253
Epoch 20/100

Epoch 00020: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.
5994/5994 - 17s - loss: 0.0253 - val_loss: 0.0253
Epoch 21/100
5994/5994 - 16s - loss: 0.0253 - val_loss: 0.0253
Epoch 22/100
5994/5994 - 16s - loss: 0.0253 - val_loss: 0.0253
Epoch 23/100

Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.
5994/5994 - 16s - loss: 0.0253 - val_loss: 0.0253
Epoch 24/100
5994/5994 - 16s - loss: 0.0253 - val_loss: 0.0253
Epoch 25/100
5994/5994 - 16s - loss: 0.0253 - val_loss: 0.0253
Epoch 00025: early stopping
saving model QRmodel_run_113_qnt_90_GtoWW25naReco_sigx_0_loss_rk5_05_20210428.h5 to /eos/home-k/kiwoznia/data/QR_models/run_113
predicting qcdSigAllTestReco
predicting GtoWW25naReco
training on 1534351 events, validating on 383588

training QR for quantile 0.99
Model: "functional_23"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_12 (InputLayer)        [(None, 1)]               0         
_________________________________________________________________
Std_Normalize (StdNormalizat (None, 1)                 0         
_________________________________________________________________
dense_66 (Dense)             (None, 60)                120       
_________________________________________________________________
dense_67 (Dense)             (None, 60)                3660      
_________________________________________________________________
dense_68 (Dense)             (None, 60)                3660      
_________________________________________________________________
dense_69 (Dense)             (None, 60)                3660      
_________________________________________________________________
dense_70 (Dense)             (None, 60)                3660      
_________________________________________________________________
dense_71 (Dense)             (None, 1)                 61        
=================================================================
Total params: 14,821
Trainable params: 14,821
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
5994/5994 - 16s - loss: 0.0062 - val_loss: 0.0046
Epoch 2/100
5994/5994 - 16s - loss: 0.0045 - val_loss: 0.0047
Epoch 3/100
5994/5994 - 16s - loss: 0.0044 - val_loss: 0.0043
Epoch 4/100
5994/5994 - 16s - loss: 0.0044 - val_loss: 0.0044
Epoch 5/100
5994/5994 - 17s - loss: 0.0044 - val_loss: 0.0045
Epoch 6/100

Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
5994/5994 - 19s - loss: 0.0044 - val_loss: 0.0044
Epoch 7/100
5994/5994 - 18s - loss: 0.0043 - val_loss: 0.0043
Epoch 8/100
5994/5994 - 18s - loss: 0.0043 - val_loss: 0.0043
Epoch 9/100

Epoch 00009: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
5994/5994 - 18s - loss: 0.0043 - val_loss: 0.0043
Epoch 10/100
5994/5994 - 18s - loss: 0.0043 - val_loss: 0.0043
Epoch 11/100
5994/5994 - 19s - loss: 0.0043 - val_loss: 0.0043
Epoch 12/100

Epoch 00012: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
5994/5994 - 18s - loss: 0.0043 - val_loss: 0.0043
Epoch 13/100
5994/5994 - 19s - loss: 0.0043 - val_loss: 0.0043
Epoch 14/100
5994/5994 - 18s - loss: 0.0043 - val_loss: 0.0043
Epoch 15/100

Epoch 00015: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
5994/5994 - 19s - loss: 0.0043 - val_loss: 0.0043
Epoch 16/100
5994/5994 - 19s - loss: 0.0043 - val_loss: 0.0043
Epoch 17/100
5994/5994 - 19s - loss: 0.0043 - val_loss: 0.0043
Epoch 18/100

Epoch 00018: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
5994/5994 - 19s - loss: 0.0043 - val_loss: 0.0043
Epoch 19/100
5994/5994 - 18s - loss: 0.0043 - val_loss: 0.0043
Epoch 20/100
5994/5994 - 18s - loss: 0.0043 - val_loss: 0.0043
Epoch 21/100

Epoch 00021: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.
5994/5994 - 19s - loss: 0.0043 - val_loss: 0.0043
Epoch 22/100
5994/5994 - 19s - loss: 0.0043 - val_loss: 0.0043
Epoch 23/100
5994/5994 - 21s - loss: 0.0043 - val_loss: 0.0043
Epoch 00023: early stopping
saving model QRmodel_run_113_qnt_99_GtoWW25naReco_sigx_0_loss_rk5_05_20210428.h5 to /eos/home-k/kiwoznia/data/QR_models/run_113
predicting qcdSigAllTestReco
predicting GtoWW25naReco
writing selections to  /eos/user/k/kiwoznia/data/QR_results/events/run_113/sig_GtoWW25naReco/xsec_0/loss_rk5_05
written data sample to /eos/user/k/kiwoznia/data/QR_results/events/run_113/sig_GtoWW25naReco/xsec_0/loss_rk5_05/qcd_sqrtshatTeV_13TeV_PU40_NEW_ALL_Test_reco.h5
written data sample to /eos/user/k/kiwoznia/data/QR_results/events/run_113/sig_GtoWW25naReco/xsec_0/loss_rk5_05/RSGraviton_WW_NARROW_13TeV_PU40_2.5TeV_reco.h5
loaded model  <tensorflow.python.keras.engine.functional.Functional object at 0x7fe3ec227710>
loaded model  <tensorflow.python.keras.engine.functional.Functional object at 0x7fe3e6f1d208>
loaded model  <tensorflow.python.keras.engine.functional.Functional object at 0x7fe3e6db82e8>
loaded model  <tensorflow.python.keras.engine.functional.Functional object at 0x7fe30c3aa048>
loaded model  <tensorflow.python.keras.engine.functional.Functional object at 0x7fe3340d7be0>
loaded model  <tensorflow.python.keras.engine.functional.Functional object at 0x7fe3340e4eb8>
/afs/cern.ch/user/k/kiwoznia/.local/lib/python3.6/site-packages/matplotlib/colors.py:1207: RuntimeWarning: invalid value encountered in less_equal
  mask |= resdat <= 0
'texgyreheros-regular.otf' can not be subsetted into a Type 3 font. The entire font will be embedded in the output.
[DataReader] read_jet_features_from_dir(): reading all events from /eos/user/k/kiwoznia/data/VAE_results/events/run_113/RSGraviton_WW_NARROW_13TeV_PU40_3.5TeV_NEW_parts
531825 events read in 2 files in dir /eos/user/k/kiwoznia/data/VAE_results/events/run_113/RSGraviton_WW_NARROW_13TeV_PU40_3.5TeV_NEW_parts
training on 1534351 events, validating on 383588

training QR for quantile 0.1
Model: "functional_25"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_13 (InputLayer)        [(None, 1)]               0         
_________________________________________________________________
Std_Normalize (StdNormalizat (None, 1)                 0         
_________________________________________________________________
dense_72 (Dense)             (None, 60)                120       
_________________________________________________________________
dense_73 (Dense)             (None, 60)                3660      
_________________________________________________________________
dense_74 (Dense)             (None, 60)                3660      
_________________________________________________________________
dense_75 (Dense)             (None, 60)                3660      
_________________________________________________________________
dense_76 (Dense)             (None, 60)                3660      
_________________________________________________________________
dense_77 (Dense)             (None, 1)                 61        
=================================================================
Total params: 14,821
Trainable params: 14,821
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
5994/5994 - 21s - loss: 0.0252 - val_loss: 0.0239
Epoch 2/100
5994/5994 - 21s - loss: 0.0240 - val_loss: 0.0239
Epoch 3/100
5994/5994 - 21s - loss: 0.0239 - val_loss: 0.0238
Epoch 4/100
5994/5994 - 21s - loss: 0.0238 - val_loss: 0.0240
Epoch 5/100
5994/5994 - 21s - loss: 0.0238 - val_loss: 0.0238
Epoch 6/100

Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
5994/5994 - 23s - loss: 0.0237 - val_loss: 0.0238
Epoch 7/100
5994/5994 - 23s - loss: 0.0237 - val_loss: 0.0237
Epoch 8/100
5994/5994 - 22s - loss: 0.0237 - val_loss: 0.0237
Epoch 9/100
5994/5994 - 22s - loss: 0.0237 - val_loss: 0.0237
Epoch 10/100
5994/5994 - 22s - loss: 0.0237 - val_loss: 0.0237
Epoch 11/100

Epoch 00011: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
5994/5994 - 21s - loss: 0.0237 - val_loss: 0.0237
Epoch 12/100
5994/5994 - 22s - loss: 0.0236 - val_loss: 0.0237
Epoch 13/100
5994/5994 - 21s - loss: 0.0236 - val_loss: 0.0237
Epoch 14/100

Epoch 00014: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
5994/5994 - 21s - loss: 0.0236 - val_loss: 0.0237
Epoch 15/100
5994/5994 - 21s - loss: 0.0236 - val_loss: 0.0237
Epoch 16/100
5994/5994 - 21s - loss: 0.0236 - val_loss: 0.0237
Epoch 17/100

Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
5994/5994 - 21s - loss: 0.0236 - val_loss: 0.0237
Epoch 18/100
5994/5994 - 20s - loss: 0.0236 - val_loss: 0.0237
Epoch 19/100
5994/5994 - 21s - loss: 0.0236 - val_loss: 0.0237
Epoch 20/100

Epoch 00020: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
5994/5994 - 20s - loss: 0.0236 - val_loss: 0.0237
Epoch 21/100
5994/5994 - 21s - loss: 0.0236 - val_loss: 0.0237
Epoch 22/100
5994/5994 - 20s - loss: 0.0236 - val_loss: 0.0237
Epoch 23/100

Epoch 00023: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.
5994/5994 - 20s - loss: 0.0236 - val_loss: 0.0237
Epoch 24/100
5994/5994 - 20s - loss: 0.0236 - val_loss: 0.0237
Epoch 25/100
5994/5994 - 20s - loss: 0.0236 - val_loss: 0.0237
Epoch 26/100

Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.
5994/5994 - 21s - loss: 0.0236 - val_loss: 0.0237
Epoch 27/100
5994/5994 - 20s - loss: 0.0236 - val_loss: 0.0237
Epoch 28/100
5994/5994 - 19s - loss: 0.0236 - val_loss: 0.0237
Epoch 29/100

Epoch 00029: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-09.
5994/5994 - 19s - loss: 0.0236 - val_loss: 0.0237
Epoch 30/100
5994/5994 - 18s - loss: 0.0236 - val_loss: 0.0237
Epoch 31/100
5994/5994 - 17s - loss: 0.0236 - val_loss: 0.0237
Epoch 32/100

Epoch 00032: ReduceLROnPlateau reducing learning rate to 5.1200004236307e-10.
5994/5994 - 18s - loss: 0.0236 - val_loss: 0.0237
Epoch 33/100
5994/5994 - 17s - loss: 0.0236 - val_loss: 0.0237
Epoch 34/100
5994/5994 - 17s - loss: 0.0236 - val_loss: 0.0237
Epoch 35/100

Epoch 00035: ReduceLROnPlateau reducing learning rate to 1.0240001069306004e-10.
5994/5994 - 16s - loss: 0.0236 - val_loss: 0.0237
Epoch 36/100
5994/5994 - 17s - loss: 0.0236 - val_loss: 0.0237
Epoch 37/100
5994/5994 - 17s - loss: 0.0236 - val_loss: 0.0237
Epoch 38/100

Epoch 00038: ReduceLROnPlateau reducing learning rate to 2.0480002416167767e-11.
5994/5994 - 17s - loss: 0.0236 - val_loss: 0.0237
Epoch 39/100
5994/5994 - 16s - loss: 0.0236 - val_loss: 0.0237
Epoch 40/100
5994/5994 - 17s - loss: 0.0236 - val_loss: 0.0237
Epoch 41/100

Epoch 00041: ReduceLROnPlateau reducing learning rate to 4.096000622011431e-12.
5994/5994 - 16s - loss: 0.0236 - val_loss: 0.0237
Epoch 00041: early stopping
saving model QRmodel_run_113_qnt_10_GtoWW35naReco_sigx_0_loss_rk5_05_20210428.h5 to /eos/home-k/kiwoznia/data/QR_models/run_113
predicting qcdSigAllTestReco
predicting GtoWW35naReco
training on 1534351 events, validating on 383588

training QR for quantile 0.3
Model: "functional_27"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_14 (InputLayer)        [(None, 1)]               0         
_________________________________________________________________
Std_Normalize (StdNormalizat (None, 1)                 0         
_________________________________________________________________
dense_78 (Dense)             (None, 60)                120       
_________________________________________________________________
dense_79 (Dense)             (None, 60)                3660      
_________________________________________________________________
dense_80 (Dense)             (None, 60)                3660      
_________________________________________________________________
dense_81 (Dense)             (None, 60)                3660      
_________________________________________________________________
dense_82 (Dense)             (None, 60)                3660      
_________________________________________________________________
dense_83 (Dense)             (None, 1)                 61        
=================================================================
Total params: 14,821
Trainable params: 14,821
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
5994/5994 - 17s - loss: 0.0488 - val_loss: 0.0476
Epoch 2/100
5994/5994 - 17s - loss: 0.0472 - val_loss: 0.0468
Epoch 3/100
5994/5994 - 17s - loss: 0.0470 - val_loss: 0.0471
Epoch 4/100
5994/5994 - 17s - loss: 0.0469 - val_loss: 0.0471
Epoch 5/100

Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
5994/5994 - 17s - loss: 0.0468 - val_loss: 0.0467
Epoch 6/100
5994/5994 - 16s - loss: 0.0466 - val_loss: 0.0467
Epoch 7/100
5994/5994 - 18s - loss: 0.0466 - val_loss: 0.0467
Epoch 8/100
5994/5994 - 18s - loss: 0.0466 - val_loss: 0.0467
Epoch 9/100
5994/5994 - 18s - loss: 0.0466 - val_loss: 0.0467
Epoch 10/100

Epoch 00010: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
5994/5994 - 17s - loss: 0.0466 - val_loss: 0.0467
Epoch 11/100
5994/5994 - 18s - loss: 0.0466 - val_loss: 0.0467
Epoch 12/100
5994/5994 - 16s - loss: 0.0466 - val_loss: 0.0467
Epoch 13/100

Epoch 00013: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
5994/5994 - 18s - loss: 0.0466 - val_loss: 0.0467
Epoch 14/100
5994/5994 - 17s - loss: 0.0466 - val_loss: 0.0467
Epoch 15/100
5994/5994 - 16s - loss: 0.0466 - val_loss: 0.0467
Epoch 16/100

Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
5994/5994 - 17s - loss: 0.0466 - val_loss: 0.0467
Epoch 17/100
5994/5994 - 16s - loss: 0.0466 - val_loss: 0.0467
Epoch 18/100
5994/5994 - 17s - loss: 0.0466 - val_loss: 0.0467
Epoch 19/100

Epoch 00019: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
5994/5994 - 17s - loss: 0.0466 - val_loss: 0.0467
Epoch 20/100
5994/5994 - 16s - loss: 0.0466 - val_loss: 0.0467
Epoch 21/100
5994/5994 - 16s - loss: 0.0466 - val_loss: 0.0467
Epoch 22/100

Epoch 00022: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.
5994/5994 - 16s - loss: 0.0466 - val_loss: 0.0467
Epoch 23/100
5994/5994 - 17s - loss: 0.0466 - val_loss: 0.0467
Epoch 24/100
5994/5994 - 17s - loss: 0.0466 - val_loss: 0.0467
Epoch 25/100

Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.
5994/5994 - 17s - loss: 0.0466 - val_loss: 0.0467
Epoch 26/100
5994/5994 - 18s - loss: 0.0466 - val_loss: 0.0467
Epoch 27/100
5994/5994 - 18s - loss: 0.0466 - val_loss: 0.0467
Epoch 28/100

Epoch 00028: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-09.
5994/5994 - 18s - loss: 0.0466 - val_loss: 0.0467
Epoch 29/100
5994/5994 - 17s - loss: 0.0466 - val_loss: 0.0467
Epoch 00029: early stopping
saving model QRmodel_run_113_qnt_30_GtoWW35naReco_sigx_0_loss_rk5_05_20210428.h5 to /eos/home-k/kiwoznia/data/QR_models/run_113
predicting qcdSigAllTestReco
predicting GtoWW35naReco
training on 1534351 events, validating on 383588

training QR for quantile 0.5
Model: "functional_29"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_15 (InputLayer)        [(None, 1)]               0         
_________________________________________________________________
Std_Normalize (StdNormalizat (None, 1)                 0         
_________________________________________________________________
dense_84 (Dense)             (None, 60)                120       
_________________________________________________________________
dense_85 (Dense)             (None, 60)                3660      
_________________________________________________________________
dense_86 (Dense)             (None, 60)                3660      
_________________________________________________________________
dense_87 (Dense)             (None, 60)                3660      
_________________________________________________________________
dense_88 (Dense)             (None, 60)                3660      
_________________________________________________________________
dense_89 (Dense)             (None, 1)                 61        
=================================================================
Total params: 14,821
Trainable params: 14,821
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
5994/5994 - 16s - loss: 0.0572 - val_loss: 0.0545
Epoch 2/100
5994/5994 - 16s - loss: 0.0546 - val_loss: 0.0541
Epoch 3/100
5994/5994 - 16s - loss: 0.0544 - val_loss: 0.0544
Epoch 4/100
5994/5994 - 17s - loss: 0.0542 - val_loss: 0.0542
Epoch 5/100

Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
5994/5994 - 17s - loss: 0.0542 - val_loss: 0.0542
Epoch 6/100
5994/5994 - 17s - loss: 0.0539 - val_loss: 0.0540
Epoch 7/100
5994/5994 - 17s - loss: 0.0539 - val_loss: 0.0540
Epoch 8/100
5994/5994 - 16s - loss: 0.0539 - val_loss: 0.0540
Epoch 9/100

Epoch 00009: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
5994/5994 - 16s - loss: 0.0539 - val_loss: 0.0539
Epoch 10/100
5994/5994 - 16s - loss: 0.0538 - val_loss: 0.0539
Epoch 11/100
5994/5994 - 17s - loss: 0.0538 - val_loss: 0.0539
Epoch 12/100

Epoch 00012: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
5994/5994 - 17s - loss: 0.0538 - val_loss: 0.0539
Epoch 13/100
5994/5994 - 17s - loss: 0.0538 - val_loss: 0.0539
Epoch 14/100
5994/5994 - 17s - loss: 0.0538 - val_loss: 0.0539
Epoch 15/100

Epoch 00015: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
5994/5994 - 16s - loss: 0.0538 - val_loss: 0.0539
Epoch 16/100
5994/5994 - 16s - loss: 0.0538 - val_loss: 0.0539
Epoch 17/100
5994/5994 - 20s - loss: 0.0538 - val_loss: 0.0539
Epoch 18/100

Epoch 00018: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
5994/5994 - 17s - loss: 0.0538 - val_loss: 0.0539
Epoch 19/100
5994/5994 - 18s - loss: 0.0538 - val_loss: 0.0539
Epoch 20/100
5994/5994 - 18s - loss: 0.0538 - val_loss: 0.0539
Epoch 21/100

Epoch 00021: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.
5994/5994 - 18s - loss: 0.0538 - val_loss: 0.0539
Epoch 22/100
5994/5994 - 18s - loss: 0.0538 - val_loss: 0.0539
Epoch 23/100
5994/5994 - 18s - loss: 0.0538 - val_loss: 0.0539
Epoch 24/100

Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.
5994/5994 - 19s - loss: 0.0538 - val_loss: 0.0539
Epoch 25/100
5994/5994 - 19s - loss: 0.0538 - val_loss: 0.0539
Epoch 26/100
5994/5994 - 19s - loss: 0.0538 - val_loss: 0.0539
Epoch 27/100

Epoch 00027: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-09.
5994/5994 - 20s - loss: 0.0538 - val_loss: 0.0539
Epoch 28/100
5994/5994 - 21s - loss: 0.0538 - val_loss: 0.0539
Epoch 00028: early stopping
saving model QRmodel_run_113_qnt_50_GtoWW35naReco_sigx_0_loss_rk5_05_20210428.h5 to /eos/home-k/kiwoznia/data/QR_models/run_113
predicting qcdSigAllTestReco
predicting GtoWW35naReco
training on 1534351 events, validating on 383588

training QR for quantile 0.7
Model: "functional_31"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_16 (InputLayer)        [(None, 1)]               0         
_________________________________________________________________
Std_Normalize (StdNormalizat (None, 1)                 0         
_________________________________________________________________
dense_90 (Dense)             (None, 60)                120       
_________________________________________________________________
dense_91 (Dense)             (None, 60)                3660      
_________________________________________________________________
dense_92 (Dense)             (None, 60)                3660      
_________________________________________________________________
dense_93 (Dense)             (None, 60)                3660      
_________________________________________________________________
dense_94 (Dense)             (None, 60)                3660      
_________________________________________________________________
dense_95 (Dense)             (None, 1)                 61        
=================================================================
Total params: 14,821
Trainable params: 14,821
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
5994/5994 - 18s - loss: 0.0520 - val_loss: 0.0482
Epoch 2/100
5994/5994 - 17s - loss: 0.0485 - val_loss: 0.0480
Epoch 3/100
5994/5994 - 20s - loss: 0.0483 - val_loss: 0.0480
Epoch 4/100
5994/5994 - 20s - loss: 0.0481 - val_loss: 0.0480
Epoch 5/100

Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
5994/5994 - 20s - loss: 0.0481 - val_loss: 0.0482
Epoch 6/100
5994/5994 - 19s - loss: 0.0478 - val_loss: 0.0479
Epoch 7/100
5994/5994 - 20s - loss: 0.0478 - val_loss: 0.0480
Epoch 8/100
5994/5994 - 21s - loss: 0.0478 - val_loss: 0.0478
Epoch 9/100

Epoch 00009: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
5994/5994 - 22s - loss: 0.0478 - val_loss: 0.0479
Epoch 10/100
5994/5994 - 22s - loss: 0.0478 - val_loss: 0.0479
Epoch 11/100
5994/5994 - 21s - loss: 0.0478 - val_loss: 0.0479
Epoch 12/100

Epoch 00012: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
5994/5994 - 21s - loss: 0.0478 - val_loss: 0.0479
Epoch 13/100
5994/5994 - 21s - loss: 0.0478 - val_loss: 0.0478
Epoch 14/100
5994/5994 - 21s - loss: 0.0478 - val_loss: 0.0478
Epoch 15/100

Epoch 00015: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
5994/5994 - 21s - loss: 0.0478 - val_loss: 0.0478
Epoch 16/100
5994/5994 - 22s - loss: 0.0478 - val_loss: 0.0478
Epoch 17/100
5994/5994 - 22s - loss: 0.0478 - val_loss: 0.0478
Epoch 18/100

Epoch 00018: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
5994/5994 - 22s - loss: 0.0478 - val_loss: 0.0478
Epoch 19/100
5994/5994 - 22s - loss: 0.0478 - val_loss: 0.0478
Epoch 20/100
5994/5994 - 22s - loss: 0.0478 - val_loss: 0.0478
Epoch 21/100

Epoch 00021: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.
5994/5994 - 21s - loss: 0.0478 - val_loss: 0.0478
Epoch 22/100
5994/5994 - 21s - loss: 0.0478 - val_loss: 0.0478
Epoch 23/100
5994/5994 - 19s - loss: 0.0478 - val_loss: 0.0478
Epoch 24/100

Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.
5994/5994 - 19s - loss: 0.0478 - val_loss: 0.0478
Epoch 00024: early stopping
saving model QRmodel_run_113_qnt_70_GtoWW35naReco_sigx_0_loss_rk5_05_20210428.h5 to /eos/home-k/kiwoznia/data/QR_models/run_113
predicting qcdSigAllTestReco
predicting GtoWW35naReco
training on 1534351 events, validating on 383588

training QR for quantile 0.9
Model: "functional_33"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_17 (InputLayer)        [(None, 1)]               0         
_________________________________________________________________
Std_Normalize (StdNormalizat (None, 1)                 0         
_________________________________________________________________
dense_96 (Dense)             (None, 60)                120       
_________________________________________________________________
dense_97 (Dense)             (None, 60)                3660      
_________________________________________________________________
dense_98 (Dense)             (None, 60)                3660      
_________________________________________________________________
dense_99 (Dense)             (None, 60)                3660      
_________________________________________________________________
dense_100 (Dense)            (None, 60)                3660      
_________________________________________________________________
dense_101 (Dense)            (None, 1)                 61        
=================================================================
Total params: 14,821
Trainable params: 14,821
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
5994/5994 - 16s - loss: 0.0281 - val_loss: 0.0268
Epoch 2/100
5994/5994 - 16s - loss: 0.0258 - val_loss: 0.0263
Epoch 3/100
5994/5994 - 17s - loss: 0.0256 - val_loss: 0.0258
Epoch 4/100
5994/5994 - 16s - loss: 0.0255 - val_loss: 0.0264
Epoch 5/100
5994/5994 - 16s - loss: 0.0255 - val_loss: 0.0254
Epoch 6/100
5994/5994 - 17s - loss: 0.0254 - val_loss: 0.0256
Epoch 7/100
5994/5994 - 16s - loss: 0.0254 - val_loss: 0.0254
Epoch 8/100

Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
5994/5994 - 16s - loss: 0.0254 - val_loss: 0.0256
Epoch 9/100
5994/5994 - 16s - loss: 0.0253 - val_loss: 0.0253
Epoch 10/100
5994/5994 - 15s - loss: 0.0253 - val_loss: 0.0253
Epoch 11/100

Epoch 00011: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
5994/5994 - 16s - loss: 0.0253 - val_loss: 0.0255
Epoch 12/100
5994/5994 - 16s - loss: 0.0253 - val_loss: 0.0253
Epoch 13/100
5994/5994 - 16s - loss: 0.0253 - val_loss: 0.0253
Epoch 14/100
5994/5994 - 17s - loss: 0.0253 - val_loss: 0.0253
Epoch 15/100

Epoch 00015: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
5994/5994 - 16s - loss: 0.0253 - val_loss: 0.0253
Epoch 16/100
5994/5994 - 16s - loss: 0.0253 - val_loss: 0.0253
Epoch 17/100
5994/5994 - 17s - loss: 0.0253 - val_loss: 0.0253
Epoch 18/100

Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
5994/5994 - 17s - loss: 0.0253 - val_loss: 0.0253
Epoch 19/100
5994/5994 - 16s - loss: 0.0253 - val_loss: 0.0253
Epoch 20/100
5994/5994 - 16s - loss: 0.0253 - val_loss: 0.0253
Epoch 21/100

Epoch 00021: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
5994/5994 - 16s - loss: 0.0253 - val_loss: 0.0253
Epoch 22/100
5994/5994 - 16s - loss: 0.0253 - val_loss: 0.0253
Epoch 23/100
5994/5994 - 16s - loss: 0.0253 - val_loss: 0.0253
Epoch 24/100

Epoch 00024: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.
5994/5994 - 17s - loss: 0.0253 - val_loss: 0.0253
Epoch 25/100
5994/5994 - 16s - loss: 0.0253 - val_loss: 0.0253
Epoch 26/100
5994/5994 - 18s - loss: 0.0253 - val_loss: 0.0253
Epoch 27/100

Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.
5994/5994 - 17s - loss: 0.0253 - val_loss: 0.0253
Epoch 28/100
5994/5994 - 17s - loss: 0.0253 - val_loss: 0.0253
Epoch 29/100
5994/5994 - 16s - loss: 0.0253 - val_loss: 0.0253
Epoch 30/100

Epoch 00030: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-09.
5994/5994 - 16s - loss: 0.0253 - val_loss: 0.0253
Epoch 31/100
5994/5994 - 16s - loss: 0.0253 - val_loss: 0.0253
Epoch 32/100
5994/5994 - 16s - loss: 0.0253 - val_loss: 0.0253
Epoch 00032: early stopping
saving model QRmodel_run_113_qnt_90_GtoWW35naReco_sigx_0_loss_rk5_05_20210428.h5 to /eos/home-k/kiwoznia/data/QR_models/run_113
predicting qcdSigAllTestReco
predicting GtoWW35naReco
training on 1534351 events, validating on 383588

training QR for quantile 0.99
Model: "functional_35"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_18 (InputLayer)        [(None, 1)]               0         
_________________________________________________________________
Std_Normalize (StdNormalizat (None, 1)                 0         
_________________________________________________________________
dense_102 (Dense)            (None, 60)                120       
_________________________________________________________________
dense_103 (Dense)            (None, 60)                3660      
_________________________________________________________________
dense_104 (Dense)            (None, 60)                3660      
_________________________________________________________________
dense_105 (Dense)            (None, 60)                3660      
_________________________________________________________________
dense_106 (Dense)            (None, 60)                3660      
_________________________________________________________________
dense_107 (Dense)            (None, 1)                 61        
=================================================================
Total params: 14,821
Trainable params: 14,821
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
5994/5994 - 18s - loss: 0.0062 - val_loss: 0.0044
Epoch 2/100
5994/5994 - 18s - loss: 0.0045 - val_loss: 0.0048
Epoch 3/100
5994/5994 - 17s - loss: 0.0044 - val_loss: 0.0044
Epoch 4/100

Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
5994/5994 - 16s - loss: 0.0044 - val_loss: 0.0044
Epoch 5/100
5994/5994 - 16s - loss: 0.0043 - val_loss: 0.0043
Epoch 6/100
5994/5994 - 17s - loss: 0.0043 - val_loss: 0.0043
Epoch 7/100
5994/5994 - 17s - loss: 0.0043 - val_loss: 0.0043
Epoch 8/100

Epoch 00008: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
5994/5994 - 17s - loss: 0.0043 - val_loss: 0.0043
Epoch 9/100
5994/5994 - 17s - loss: 0.0043 - val_loss: 0.0043
Epoch 10/100
5994/5994 - 17s - loss: 0.0043 - val_loss: 0.0043
Epoch 11/100

Epoch 00011: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
5994/5994 - 16s - loss: 0.0043 - val_loss: 0.0043
Epoch 12/100
5994/5994 - 16s - loss: 0.0043 - val_loss: 0.0043
Epoch 13/100
5994/5994 - 17s - loss: 0.0043 - val_loss: 0.0043
Epoch 14/100

Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
5994/5994 - 16s - loss: 0.0043 - val_loss: 0.0043
Epoch 15/100
5994/5994 - 17s - loss: 0.0043 - val_loss: 0.0043
Epoch 16/100
5994/5994 - 17s - loss: 0.0043 - val_loss: 0.0043
Epoch 17/100

Epoch 00017: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
5994/5994 - 16s - loss: 0.0043 - val_loss: 0.0043
Epoch 18/100
5994/5994 - 16s - loss: 0.0043 - val_loss: 0.0043
Epoch 19/100
5994/5994 - 18s - loss: 0.0043 - val_loss: 0.0043
Epoch 20/100

Epoch 00020: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.
5994/5994 - 17s - loss: 0.0043 - val_loss: 0.0043
Epoch 21/100
5994/5994 - 18s - loss: 0.0043 - val_loss: 0.0043
Epoch 22/100
5994/5994 - 17s - loss: 0.0043 - val_loss: 0.0043
Epoch 23/100

Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.
5994/5994 - 17s - loss: 0.0043 - val_loss: 0.0043
Epoch 24/100
5994/5994 - 17s - loss: 0.0043 - val_loss: 0.0043
Epoch 25/100
5994/5994 - 17s - loss: 0.0043 - val_loss: 0.0043
Epoch 26/100

Epoch 00026: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-09.
5994/5994 - 17s - loss: 0.0043 - val_loss: 0.0043
Epoch 00026: early stopping
saving model QRmodel_run_113_qnt_99_GtoWW35naReco_sigx_0_loss_rk5_05_20210428.h5 to /eos/home-k/kiwoznia/data/QR_models/run_113
predicting qcdSigAllTestReco
predicting GtoWW35naReco
writing selections to  /eos/user/k/kiwoznia/data/QR_results/events/run_113/sig_GtoWW35naReco/xsec_0/loss_rk5_05
written data sample to /eos/user/k/kiwoznia/data/QR_results/events/run_113/sig_GtoWW35naReco/xsec_0/loss_rk5_05/qcd_sqrtshatTeV_13TeV_PU40_NEW_ALL_Test_reco.h5
written data sample to /eos/user/k/kiwoznia/data/QR_results/events/run_113/sig_GtoWW35naReco/xsec_0/loss_rk5_05/RSGraviton_WW_NARROW_13TeV_PU40_3.5TeV_reco.h5
loaded model  <tensorflow.python.keras.engine.functional.Functional object at 0x7fe3ecfdb3c8>
loaded model  <tensorflow.python.keras.engine.functional.Functional object at 0x7fe3ed030e48>
loaded model  <tensorflow.python.keras.engine.functional.Functional object at 0x7fe30c036860>
loaded model  <tensorflow.python.keras.engine.functional.Functional object at 0x7fe3ec1eaeb8>
loaded model  <tensorflow.python.keras.engine.functional.Functional object at 0x7fe3ec11b438>
loaded model  <tensorflow.python.keras.engine.functional.Functional object at 0x7fe3e6ceaeb8>
/afs/cern.ch/user/k/kiwoznia/.local/lib/python3.6/site-packages/matplotlib/colors.py:1207: RuntimeWarning: invalid value encountered in less_equal
  mask |= resdat <= 0
'texgyreheros-regular.otf' can not be subsetted into a Type 3 font. The entire font will be embedded in the output.
[DataReader] read_jet_features_from_dir(): reading all events from /eos/user/k/kiwoznia/data/VAE_results/events/run_113/RSGraviton_WW_NARROW_13TeV_PU40_4.5TeV_NEW_parts
561735 events read in 2 files in dir /eos/user/k/kiwoznia/data/VAE_results/events/run_113/RSGraviton_WW_NARROW_13TeV_PU40_4.5TeV_NEW_parts
training on 1534351 events, validating on 383588

training QR for quantile 0.1
Model: "functional_37"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_19 (InputLayer)        [(None, 1)]               0         
_________________________________________________________________
Std_Normalize (StdNormalizat (None, 1)                 0         
_________________________________________________________________
dense_108 (Dense)            (None, 60)                120       
_________________________________________________________________
dense_109 (Dense)            (None, 60)                3660      
_________________________________________________________________
dense_110 (Dense)            (None, 60)                3660      
_________________________________________________________________
dense_111 (Dense)            (None, 60)                3660      
_________________________________________________________________
dense_112 (Dense)            (None, 60)                3660      
_________________________________________________________________
dense_113 (Dense)            (None, 1)                 61        
=================================================================
Total params: 14,821
Trainable params: 14,821
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
5994/5994 - 17s - loss: 0.0248 - val_loss: 0.0238
Epoch 2/100
5994/5994 - 17s - loss: 0.0240 - val_loss: 0.0238
Epoch 3/100
5994/5994 - 17s - loss: 0.0239 - val_loss: 0.0242
Epoch 4/100

Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
5994/5994 - 17s - loss: 0.0239 - val_loss: 0.0239
Epoch 5/100
5994/5994 - 17s - loss: 0.0237 - val_loss: 0.0238
Epoch 6/100
5994/5994 - 17s - loss: 0.0237 - val_loss: 0.0237
Epoch 7/100
5994/5994 - 16s - loss: 0.0237 - val_loss: 0.0237
Epoch 8/100
5994/5994 - 16s - loss: 0.0237 - val_loss: 0.0237
Epoch 9/100

Epoch 00009: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
5994/5994 - 17s - loss: 0.0237 - val_loss: 0.0237
Epoch 10/100
5994/5994 - 16s - loss: 0.0237 - val_loss: 0.0237
Epoch 11/100
5994/5994 - 16s - loss: 0.0237 - val_loss: 0.0237
Epoch 12/100

Epoch 00012: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
5994/5994 - 16s - loss: 0.0237 - val_loss: 0.0237
Epoch 13/100
5994/5994 - 16s - loss: 0.0236 - val_loss: 0.0237
Epoch 14/100
5994/5994 - 16s - loss: 0.0236 - val_loss: 0.0237
Epoch 15/100

Epoch 00015: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
5994/5994 - 16s - loss: 0.0236 - val_loss: 0.0237
Epoch 16/100
5994/5994 - 16s - loss: 0.0236 - val_loss: 0.0237
Epoch 17/100
5994/5994 - 16s - loss: 0.0236 - val_loss: 0.0237
Epoch 18/100

Epoch 00018: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
5994/5994 - 16s - loss: 0.0236 - val_loss: 0.0237
Epoch 19/100
5994/5994 - 16s - loss: 0.0236 - val_loss: 0.0237
Epoch 20/100
5994/5994 - 16s - loss: 0.0236 - val_loss: 0.0237
Epoch 21/100

Epoch 00021: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.
5994/5994 - 16s - loss: 0.0236 - val_loss: 0.0237
Epoch 22/100
5994/5994 - 16s - loss: 0.0236 - val_loss: 0.0237
Epoch 23/100
5994/5994 - 16s - loss: 0.0236 - val_loss: 0.0237
Epoch 00023: early stopping
saving model QRmodel_run_113_qnt_10_GtoWW45naReco_sigx_0_loss_rk5_05_20210428.h5 to /eos/home-k/kiwoznia/data/QR_models/run_113
predicting qcdSigAllTestReco
predicting GtoWW45naReco
training on 1534351 events, validating on 383588

training QR for quantile 0.3
Model: "functional_39"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_20 (InputLayer)        [(None, 1)]               0         
_________________________________________________________________
Std_Normalize (StdNormalizat (None, 1)                 0         
_________________________________________________________________
dense_114 (Dense)            (None, 60)                120       
_________________________________________________________________
dense_115 (Dense)            (None, 60)                3660      
_________________________________________________________________
dense_116 (Dense)            (None, 60)                3660      
_________________________________________________________________
dense_117 (Dense)            (None, 60)                3660      
_________________________________________________________________
dense_118 (Dense)            (None, 60)                3660      
_________________________________________________________________
dense_119 (Dense)            (None, 1)                 61        
=================================================================
Total params: 14,821
Trainable params: 14,821
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
5994/5994 - 16s - loss: 0.0489 - val_loss: 0.0472
Epoch 2/100
5994/5994 - 15s - loss: 0.0472 - val_loss: 0.0476
Epoch 3/100
5994/5994 - 16s - loss: 0.0470 - val_loss: 0.0471
Epoch 4/100
5994/5994 - 16s - loss: 0.0469 - val_loss: 0.0469
Epoch 5/100
5994/5994 - 16s - loss: 0.0468 - val_loss: 0.0467
Epoch 6/100
5994/5994 - 15s - loss: 0.0468 - val_loss: 0.0467
Epoch 7/100
5994/5994 - 16s - loss: 0.0468 - val_loss: 0.0467
Epoch 8/100

Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
5994/5994 - 16s - loss: 0.0468 - val_loss: 0.0469
Epoch 9/100
5994/5994 - 16s - loss: 0.0466 - val_loss: 0.0466
Epoch 10/100
5994/5994 - 16s - loss: 0.0466 - val_loss: 0.0466
Epoch 11/100

Epoch 00011: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
5994/5994 - 16s - loss: 0.0466 - val_loss: 0.0466
Epoch 12/100
5994/5994 - 17s - loss: 0.0466 - val_loss: 0.0466
Epoch 13/100
5994/5994 - 17s - loss: 0.0466 - val_loss: 0.0466
Epoch 14/100
5994/5994 - 18s - loss: 0.0466 - val_loss: 0.0466
Epoch 15/100

Epoch 00015: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
5994/5994 - 16s - loss: 0.0466 - val_loss: 0.0466
Epoch 16/100
5994/5994 - 17s - loss: 0.0466 - val_loss: 0.0466
Epoch 17/100
5994/5994 - 17s - loss: 0.0466 - val_loss: 0.0466
Epoch 18/100

Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
5994/5994 - 16s - loss: 0.0466 - val_loss: 0.0466
Epoch 19/100
5994/5994 - 17s - loss: 0.0466 - val_loss: 0.0466
Epoch 20/100
5994/5994 - 16s - loss: 0.0466 - val_loss: 0.0466
Epoch 21/100

Epoch 00021: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
5994/5994 - 18s - loss: 0.0466 - val_loss: 0.0466
Epoch 22/100
5994/5994 - 17s - loss: 0.0466 - val_loss: 0.0466
Epoch 23/100
5994/5994 - 17s - loss: 0.0466 - val_loss: 0.0466
Epoch 24/100

Epoch 00024: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.
5994/5994 - 17s - loss: 0.0466 - val_loss: 0.0466
Epoch 25/100
5994/5994 - 17s - loss: 0.0466 - val_loss: 0.0466
Epoch 26/100
5994/5994 - 17s - loss: 0.0466 - val_loss: 0.0466
Epoch 27/100

Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.
5994/5994 - 17s - loss: 0.0466 - val_loss: 0.0466
Epoch 00027: early stopping
saving model QRmodel_run_113_qnt_30_GtoWW45naReco_sigx_0_loss_rk5_05_20210428.h5 to /eos/home-k/kiwoznia/data/QR_models/run_113
predicting qcdSigAllTestReco
predicting GtoWW45naReco
training on 1534351 events, validating on 383588

training QR for quantile 0.5
Model: "functional_41"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_21 (InputLayer)        [(None, 1)]               0         
_________________________________________________________________
Std_Normalize (StdNormalizat (None, 1)                 0         
_________________________________________________________________
dense_120 (Dense)            (None, 60)                120       
_________________________________________________________________
dense_121 (Dense)            (None, 60)                3660      
_________________________________________________________________
dense_122 (Dense)            (None, 60)                3660      
_________________________________________________________________
dense_123 (Dense)            (None, 60)                3660      
_________________________________________________________________
dense_124 (Dense)            (None, 60)                3660      
_________________________________________________________________
dense_125 (Dense)            (None, 1)                 61        
=================================================================
Total params: 14,821
Trainable params: 14,821
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
5994/5994 - 18s - loss: 0.0569 - val_loss: 0.0544
Epoch 2/100
5994/5994 - 17s - loss: 0.0546 - val_loss: 0.0543
Epoch 3/100
5994/5994 - 19s - loss: 0.0543 - val_loss: 0.0542
Epoch 4/100
5994/5994 - 19s - loss: 0.0542 - val_loss: 0.0543
Epoch 5/100
5994/5994 - 18s - loss: 0.0541 - val_loss: 0.0541
Epoch 6/100
5994/5994 - 17s - loss: 0.0541 - val_loss: 0.0542
Epoch 7/100
5994/5994 - 18s - loss: 0.0541 - val_loss: 0.0540
Epoch 8/100

Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
5994/5994 - 19s - loss: 0.0541 - val_loss: 0.0542
Epoch 9/100
5994/5994 - 20s - loss: 0.0539 - val_loss: 0.0539
Epoch 10/100
5994/5994 - 19s - loss: 0.0539 - val_loss: 0.0539
Epoch 11/100
5994/5994 - 19s - loss: 0.0539 - val_loss: 0.0539
Epoch 12/100

Epoch 00012: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
5994/5994 - 19s - loss: 0.0539 - val_loss: 0.0539
Epoch 13/100
5994/5994 - 20s - loss: 0.0538 - val_loss: 0.0539
Epoch 14/100
5994/5994 - 19s - loss: 0.0538 - val_loss: 0.0539
Epoch 15/100

Epoch 00015: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
5994/5994 - 19s - loss: 0.0538 - val_loss: 0.0539
Epoch 16/100
5994/5994 - 18s - loss: 0.0538 - val_loss: 0.0539
Epoch 17/100
5994/5994 - 19s - loss: 0.0538 - val_loss: 0.0539
Epoch 18/100

Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
5994/5994 - 19s - loss: 0.0538 - val_loss: 0.0539
Epoch 19/100
5994/5994 - 19s - loss: 0.0538 - val_loss: 0.0539
Epoch 20/100
5994/5994 - 19s - loss: 0.0538 - val_loss: 0.0539
Epoch 21/100

Epoch 00021: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
5994/5994 - 17s - loss: 0.0538 - val_loss: 0.0539
Epoch 22/100
5994/5994 - 18s - loss: 0.0538 - val_loss: 0.0539
Epoch 23/100
5994/5994 - 18s - loss: 0.0538 - val_loss: 0.0539
Epoch 24/100

Epoch 00024: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.
5994/5994 - 17s - loss: 0.0538 - val_loss: 0.0539
Epoch 25/100
5994/5994 - 18s - loss: 0.0538 - val_loss: 0.0539
Epoch 26/100
5994/5994 - 16s - loss: 0.0538 - val_loss: 0.0539
Epoch 27/100

Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.
5994/5994 - 16s - loss: 0.0538 - val_loss: 0.0539
Epoch 28/100
5994/5994 - 16s - loss: 0.0538 - val_loss: 0.0539
Epoch 29/100
5994/5994 - 15s - loss: 0.0538 - val_loss: 0.0539
Epoch 30/100

Epoch 00030: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-09.
5994/5994 - 16s - loss: 0.0538 - val_loss: 0.0539
Epoch 00030: early stopping
saving model QRmodel_run_113_qnt_50_GtoWW45naReco_sigx_0_loss_rk5_05_20210428.h5 to /eos/home-k/kiwoznia/data/QR_models/run_113
predicting qcdSigAllTestReco
predicting GtoWW45naReco
training on 1534351 events, validating on 383588

training QR for quantile 0.7
Model: "functional_43"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_22 (InputLayer)        [(None, 1)]               0         
_________________________________________________________________
Std_Normalize (StdNormalizat (None, 1)                 0         
_________________________________________________________________
dense_126 (Dense)            (None, 60)                120       
_________________________________________________________________
dense_127 (Dense)            (None, 60)                3660      
_________________________________________________________________
dense_128 (Dense)            (None, 60)                3660      
_________________________________________________________________
dense_129 (Dense)            (None, 60)                3660      
_________________________________________________________________
dense_130 (Dense)            (None, 60)                3660      
_________________________________________________________________
dense_131 (Dense)            (None, 1)                 61        
=================================================================
Total params: 14,821
Trainable params: 14,821
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
5994/5994 - 16s - loss: 0.0516 - val_loss: 0.0506
Epoch 2/100
5994/5994 - 16s - loss: 0.0485 - val_loss: 0.0486
Epoch 3/100
5994/5994 - 16s - loss: 0.0483 - val_loss: 0.0482
Epoch 4/100
5994/5994 - 15s - loss: 0.0482 - val_loss: 0.0484
Epoch 5/100
5994/5994 - 16s - loss: 0.0481 - val_loss: 0.0479
Epoch 6/100
5994/5994 - 16s - loss: 0.0480 - val_loss: 0.0480
Epoch 7/100
5994/5994 - 16s - loss: 0.0480 - val_loss: 0.0479
Epoch 8/100

Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
5994/5994 - 16s - loss: 0.0480 - val_loss: 0.0481
Epoch 9/100
5994/5994 - 15s - loss: 0.0478 - val_loss: 0.0479
Epoch 10/100
5994/5994 - 15s - loss: 0.0478 - val_loss: 0.0479
Epoch 11/100

Epoch 00011: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
5994/5994 - 15s - loss: 0.0478 - val_loss: 0.0478
Epoch 12/100
5994/5994 - 15s - loss: 0.0478 - val_loss: 0.0478
Epoch 13/100
5994/5994 - 15s - loss: 0.0478 - val_loss: 0.0478
Epoch 14/100

Epoch 00014: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
5994/5994 - 15s - loss: 0.0478 - val_loss: 0.0478
Epoch 15/100
5994/5994 - 16s - loss: 0.0478 - val_loss: 0.0478
Epoch 16/100
5994/5994 - 16s - loss: 0.0478 - val_loss: 0.0478
Epoch 17/100

Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
5994/5994 - 16s - loss: 0.0478 - val_loss: 0.0478
Epoch 18/100
5994/5994 - 16s - loss: 0.0478 - val_loss: 0.0478
Epoch 19/100
5994/5994 - 16s - loss: 0.0478 - val_loss: 0.0478
Epoch 20/100

Epoch 00020: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
5994/5994 - 16s - loss: 0.0478 - val_loss: 0.0478
Epoch 21/100
5994/5994 - 16s - loss: 0.0478 - val_loss: 0.0478
Epoch 22/100
5994/5994 - 17s - loss: 0.0478 - val_loss: 0.0478
Epoch 23/100

Epoch 00023: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.
5994/5994 - 16s - loss: 0.0478 - val_loss: 0.0478
Epoch 00023: early stopping
saving model QRmodel_run_113_qnt_70_GtoWW45naReco_sigx_0_loss_rk5_05_20210428.h5 to /eos/home-k/kiwoznia/data/QR_models/run_113
predicting qcdSigAllTestReco
predicting GtoWW45naReco
training on 1534351 events, validating on 383588

training QR for quantile 0.9
Model: "functional_45"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_23 (InputLayer)        [(None, 1)]               0         
_________________________________________________________________
Std_Normalize (StdNormalizat (None, 1)                 0         
_________________________________________________________________
dense_132 (Dense)            (None, 60)                120       
_________________________________________________________________
dense_133 (Dense)            (None, 60)                3660      
_________________________________________________________________
dense_134 (Dense)            (None, 60)                3660      
_________________________________________________________________
dense_135 (Dense)            (None, 60)                3660      
_________________________________________________________________
dense_136 (Dense)            (None, 60)                3660      
_________________________________________________________________
dense_137 (Dense)            (None, 1)                 61        
=================================================================
Total params: 14,821
Trainable params: 14,821
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
5994/5994 - 17s - loss: 0.0277 - val_loss: 0.0256
Epoch 2/100
5994/5994 - 16s - loss: 0.0258 - val_loss: 0.0254
Epoch 3/100
5994/5994 - 16s - loss: 0.0256 - val_loss: 0.0255
Epoch 4/100
5994/5994 - 17s - loss: 0.0255 - val_loss: 0.0254
Epoch 5/100

Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
5994/5994 - 17s - loss: 0.0255 - val_loss: 0.0255
Epoch 6/100
5994/5994 - 16s - loss: 0.0253 - val_loss: 0.0253
Epoch 7/100
5994/5994 - 16s - loss: 0.0253 - val_loss: 0.0253
Epoch 8/100

Epoch 00008: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
5994/5994 - 16s - loss: 0.0253 - val_loss: 0.0254
Epoch 9/100
5994/5994 - 17s - loss: 0.0253 - val_loss: 0.0253
Epoch 10/100
5994/5994 - 17s - loss: 0.0253 - val_loss: 0.0253
Epoch 11/100

Epoch 00011: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
5994/5994 - 17s - loss: 0.0253 - val_loss: 0.0253
Epoch 12/100
5994/5994 - 16s - loss: 0.0253 - val_loss: 0.0253
Epoch 13/100
5994/5994 - 16s - loss: 0.0253 - val_loss: 0.0253
Epoch 14/100
5994/5994 - 17s - loss: 0.0253 - val_loss: 0.0253
Epoch 15/100

Epoch 00015: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
5994/5994 - 16s - loss: 0.0253 - val_loss: 0.0253
Epoch 16/100
5994/5994 - 16s - loss: 0.0253 - val_loss: 0.0253
Epoch 17/100
5994/5994 - 16s - loss: 0.0253 - val_loss: 0.0253
Epoch 18/100

Epoch 00018: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
5994/5994 - 17s - loss: 0.0253 - val_loss: 0.0253
Epoch 19/100
5994/5994 - 17s - loss: 0.0253 - val_loss: 0.0253
Epoch 20/100
5994/5994 - 16s - loss: 0.0253 - val_loss: 0.0253
Epoch 21/100

Epoch 00021: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.
5994/5994 - 17s - loss: 0.0253 - val_loss: 0.0253
Epoch 22/100
5994/5994 - 16s - loss: 0.0253 - val_loss: 0.0253
Epoch 00022: early stopping
saving model QRmodel_run_113_qnt_90_GtoWW45naReco_sigx_0_loss_rk5_05_20210428.h5 to /eos/home-k/kiwoznia/data/QR_models/run_113
predicting qcdSigAllTestReco
predicting GtoWW45naReco
training on 1534351 events, validating on 383588

training QR for quantile 0.99
Model: "functional_47"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_24 (InputLayer)        [(None, 1)]               0         
_________________________________________________________________
Std_Normalize (StdNormalizat (None, 1)                 0         
_________________________________________________________________
dense_138 (Dense)            (None, 60)                120       
_________________________________________________________________
dense_139 (Dense)            (None, 60)                3660      
_________________________________________________________________
dense_140 (Dense)            (None, 60)                3660      
_________________________________________________________________
dense_141 (Dense)            (None, 60)                3660      
_________________________________________________________________
dense_142 (Dense)            (None, 60)                3660      
_________________________________________________________________
dense_143 (Dense)            (None, 1)                 61        
=================================================================
Total params: 14,821
Trainable params: 14,821
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
5994/5994 - 17s - loss: 0.0060 - val_loss: 0.0044
Epoch 2/100
5994/5994 - 16s - loss: 0.0045 - val_loss: 0.0044
Epoch 3/100
5994/5994 - 16s - loss: 0.0044 - val_loss: 0.0043
Epoch 4/100

Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
5994/5994 - 17s - loss: 0.0044 - val_loss: 0.0045
Epoch 5/100
5994/5994 - 17s - loss: 0.0043 - val_loss: 0.0043
Epoch 6/100
5994/5994 - 17s - loss: 0.0043 - val_loss: 0.0043
Epoch 7/100
5994/5994 - 17s - loss: 0.0043 - val_loss: 0.0043
Epoch 8/100

Epoch 00008: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
5994/5994 - 17s - loss: 0.0043 - val_loss: 0.0043
Epoch 9/100
5994/5994 - 17s - loss: 0.0043 - val_loss: 0.0043
Epoch 10/100
5994/5994 - 16s - loss: 0.0043 - val_loss: 0.0043
Epoch 11/100

Epoch 00011: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
5994/5994 - 16s - loss: 0.0043 - val_loss: 0.0043
Epoch 12/100
5994/5994 - 17s - loss: 0.0043 - val_loss: 0.0043
Epoch 13/100
5994/5994 - 16s - loss: 0.0043 - val_loss: 0.0043
Epoch 14/100

Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
5994/5994 - 17s - loss: 0.0043 - val_loss: 0.0043
Epoch 15/100
5994/5994 - 16s - loss: 0.0043 - val_loss: 0.0043
Epoch 16/100
5994/5994 - 16s - loss: 0.0043 - val_loss: 0.0043
Epoch 17/100

Epoch 00017: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.
5994/5994 - 16s - loss: 0.0043 - val_loss: 0.0043
Epoch 18/100
5994/5994 - 16s - loss: 0.0043 - val_loss: 0.0043
Epoch 19/100
5994/5994 - 17s - loss: 0.0043 - val_loss: 0.0043
Epoch 20/100

Epoch 00020: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.
5994/5994 - 16s - loss: 0.0043 - val_loss: 0.0043
Epoch 21/100
5994/5994 - 17s - loss: 0.0043 - val_loss: 0.0043
Epoch 22/100
5994/5994 - 17s - loss: 0.0043 - val_loss: 0.0043
Epoch 23/100

Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.
5994/5994 - 17s - loss: 0.0043 - val_loss: 0.0043
Epoch 24/100
5994/5994 - 17s - loss: 0.0043 - val_loss: 0.0043
Epoch 25/100
5994/5994 - 17s - loss: 0.0043 - val_loss: 0.0043
Epoch 26/100

Epoch 00026: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-09.
5994/5994 - 17s - loss: 0.0043 - val_loss: 0.0043
Epoch 27/100
5994/5994 - 17s - loss: 0.0043 - val_loss: 0.0043
Epoch 28/100
5994/5994 - 17s - loss: 0.0043 - val_loss: 0.0043
Epoch 00028: early stopping
saving model QRmodel_run_113_qnt_99_GtoWW45naReco_sigx_0_loss_rk5_05_20210428.h5 to /eos/home-k/kiwoznia/data/QR_models/run_113
predicting qcdSigAllTestReco
predicting GtoWW45naReco
writing selections to  /eos/user/k/kiwoznia/data/QR_results/events/run_113/sig_GtoWW45naReco/xsec_0/loss_rk5_05
written data sample to /eos/user/k/kiwoznia/data/QR_results/events/run_113/sig_GtoWW45naReco/xsec_0/loss_rk5_05/qcd_sqrtshatTeV_13TeV_PU40_NEW_ALL_Test_reco.h5
written data sample to /eos/user/k/kiwoznia/data/QR_results/events/run_113/sig_GtoWW45naReco/xsec_0/loss_rk5_05/RSGraviton_WW_NARROW_13TeV_PU40_4.5TeV_reco.h5
loaded model  <tensorflow.python.keras.engine.functional.Functional object at 0x7fe3ecf8e518>
loaded model  <tensorflow.python.keras.engine.functional.Functional object at 0x7fe3ea12cb00>
loaded model  <tensorflow.python.keras.engine.functional.Functional object at 0x7fe3ea23d908>
loaded model  <tensorflow.python.keras.engine.functional.Functional object at 0x7fe3ea1d1198>
loaded model  <tensorflow.python.keras.engine.functional.Functional object at 0x7fe3ec1987b8>
loaded model  <tensorflow.python.keras.engine.functional.Functional object at 0x7fe30c3aafd0>
/afs/cern.ch/user/k/kiwoznia/.local/lib/python3.6/site-packages/matplotlib/colors.py:1207: RuntimeWarning: invalid value encountered in less_equal
  mask |= resdat <= 0
'texgyreheros-regular.otf' can not be subsetted into a Type 3 font. The entire font will be embedded in the output.
